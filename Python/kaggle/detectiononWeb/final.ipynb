{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# загрузим библиотеки и установим опции\n",
    "\n",
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import re\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21668</th>\n",
       "      <td>21669</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54842</th>\n",
       "      <td>54843</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77291</th>\n",
       "      <td>77292</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114020</th>\n",
       "      <td>114021</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146669</th>\n",
       "      <td>146670</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  site1               time1  site2               time2  \\\n",
       "21668        21669     56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57   \n",
       "54842        54843     56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   \n",
       "77291        77292    946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14   \n",
       "114020      114021    945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17   \n",
       "146669      146670    947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20   \n",
       "\n",
       "        site3               time3  site4               time4  site5   ...    \\\n",
       "21668     NaN                 NaT    NaN                 NaT    NaN   ...     \n",
       "54842    56.0 2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   ...     \n",
       "77291   951.0 2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   ...     \n",
       "114020  949.0 2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   ...     \n",
       "146669  948.0 2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   ...     \n",
       "\n",
       "                     time6  site7               time7  site8  \\\n",
       "21668                  NaT    NaN                 NaT    NaN   \n",
       "54842                  NaT    NaN                 NaT    NaN   \n",
       "77291  2013-01-12 08:50:16  948.0 2013-01-12 08:50:16  784.0   \n",
       "114020 2013-01-12 08:50:18  947.0 2013-01-12 08:50:19  945.0   \n",
       "146669 2013-01-12 08:50:21  946.0 2013-01-12 08:50:21  951.0   \n",
       "\n",
       "                     time8  site9               time9  site10  \\\n",
       "21668                  NaT    NaN                 NaT     NaN   \n",
       "54842                  NaT    NaN                 NaT     NaN   \n",
       "77291  2013-01-12 08:50:16  949.0 2013-01-12 08:50:17   946.0   \n",
       "114020 2013-01-12 08:50:19  946.0 2013-01-12 08:50:19   946.0   \n",
       "146669 2013-01-12 08:50:22  946.0 2013-01-12 08:50:22   947.0   \n",
       "\n",
       "                    time10  target  \n",
       "21668                  NaT       0  \n",
       "54842                  NaT       0  \n",
       "77291  2013-01-12 08:50:17       0  \n",
       "114020 2013-01-12 08:50:20       0  \n",
       "146669 2013-01-12 08:50:22       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('data/train_sessions.csv')#,index_col='session_id')\n",
    "test_df = pd.read_csv('data/test_sessions.csv')#, index_col='session_id')\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# посмотрим на заголовок обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int').astype('str')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int').astype('str')\n",
    "\n",
    "train_df['list'] = train_df['site1']\n",
    "test_df['list'] = test_df['site1']\n",
    "for s in sites[1:]:\n",
    "    train_df['list'] = train_df['list']+\",\"+train_df[s]\n",
    "    test_df['list'] = test_df['list']+\",\"+test_df[s]\n",
    "    \n",
    "train_df['list_w'] = train_df['list'].apply(lambda x: x.split(','))\n",
    "test_df['list_w'] = test_df['list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Подключаем модуль \n",
    "import os \n",
    "import json\n",
    "#Каталог из которого будем брать файлы \n",
    "directory = '/home/dz/kaggle/detectiononWeb/data/other_user_logs' \n",
    "#Получаем список файлов в переменную files \n",
    "files = os.listdir(directory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим словарик сайтов\n",
    "with open(r\"data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'всего сайтов:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_dict['facebook.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site    vk.com\n",
       "Name: 3000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_dict.ix[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.42 s, sys: 140 ms, total: 6.56 s\n",
      "Wall time: 7.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_ = []\n",
    "for i in range(len(files)):\n",
    "    with open('data/other_user_logs/'+files[i]) as data_file:    \n",
    "        data = pd.read_csv(data_file)\n",
    "        list_.append(list(data['site'].apply(lambda x: site_dict[x]).apply(str)))\n",
    "data = pd.read_csv('data/Alice_log.csv')\n",
    "list_.append(list(data['site'].apply(lambda x: site_dict[x]).apply(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['site'] = np.zeros(len(list_))\n",
    "data['site'] = list_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['site'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(data['site'], size=400, window=30, workers=4)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['3000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sites_dict.ix[7033],sites_dict.ix[7022],sites_dict.ix[31578],sites_dict.ix[12619],sites_dict.ix[31579],sites_dict.ix[7013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sites_dict.ix[2997],sites_dict.ix[7015],sites_dict.ix[19132],sites_dict.ix[7033],sites_dict.ix[31441],sites_dict.ix[31564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(train_df['list_w'], size=300, window=3, workers=4)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['3000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sites_dict.ix[5302],sites_dict.ix[31578],sites_dict.ix[8666],sites_dict.ix[26385],sites_dict.ix[7033],sites_dict.ix[27228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mean_vectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(next(iter(w2v.values())))\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_mean = mean_vectorizer(w2v).fit(train_df['list_w']).transform(train_df['list_w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split(train,y,ratio):\n",
    "    idx = round(train.shape[0] * ratio)\n",
    "    return train[:idx, :], train[idx:, :], y[:idx], y[idx:]\n",
    "Xtr, Xval, ytr, yval = split(train_df_mean, y,0.8)\n",
    "Xtr.shape,Xval.shape,ytr.mean(),yval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "253561-82797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1, seed=7):\n",
    "    # разделим выборку на обучающую и валидационную\n",
    "    idx = 170764\n",
    "    # обучение классификатора\n",
    "    lr = LogisticRegression(C=C, random_state=seed, n_jobs=4).fit(X[:idx, :], y[:idx])\n",
    "    # прогноз для валидационной выборки\n",
    "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
    "    # считаем качество\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_mean_ = mean_vectorizer(w2v).fit(train_df['list_w']).transform(train_df['list_w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def CV(train_df_mean,y,estimator):\n",
    "    r = []\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    TimeSeriesSplit(n_splits=3)\n",
    "    for train, test in tscv.split(train_df_mean):\n",
    "        Xtr = train_df_mean[train]\n",
    "        ytr = y[train]\n",
    "        Xval = train_df_mean[test]\n",
    "        yval = y[test]\n",
    "        print(Xtr.shape,Xval.shape,ytr.shape,yval.shape)\n",
    "        est = estimator.fit(Xtr,ytr)\n",
    "        z = roc_auc_score(yval, est.predict_proba(Xval)[:, 1])\n",
    "        print(z)\n",
    "        r.append(z)\n",
    "    print(np.mean(r),np.std(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_ = np.concatenate((train_df_mean_, train_df_mean), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CV(train_df_,y,LogisticRegression(C=1, random_state=7, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "920\n",
    "914\n",
    "904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_auc_lr_valid(train_df_,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_auc_lr_valid(train_df_mean,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_auc_lr_valid(train_df_mean_,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "class tfidf_vectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(next(iter(w2v.values())))\n",
    "\n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_mean = tfidf_vectorizer(w2v).fit(train_df['list_w']).transform(train_df['list_w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_auc_lr_valid(data_mean,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_mean = tfidf_vectorizer(w2v).fit(train_df['list_w']).transform(train_df['list_w'])\n",
    "get_auc_lr_valid(data_mean,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(site_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "max_features = 48371\n",
    "maxlen = 10\n",
    "batch_size = 32\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df[sites][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_val(train,y):\n",
    "    idx = 170764\n",
    "    Xtr = train[:idx]\n",
    "    Xval = train[idx:]\n",
    "    ytr = y[:idx]\n",
    "    yval = y[idx:]\n",
    "    return Xtr,Xval,ytr,yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr,Xval,ytr,yval = get_val(train_df[sites],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(Xtr.as_matrix(), ytr,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          validation_data=(Xval.as_matrix(), yval),verbose=2)\n",
    "score, acc = model.evaluate(Xval.as_matrix(), yval,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(Xtr.as_matrix(), ytr,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          validation_data=(Xval.as_matrix(), yval),class_weight='auto',verbose=2)\n",
    "score, acc = model.evaluate(Xval.as_matrix(), yval,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              class_mode=\"binary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    batch_size=batch_size, \n",
    "    nb_epoch=5,\n",
    "    show_accuracy=True\n",
    ")\n",
    "\n",
    "result = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(data['site'], size=300, window=30, workers=4)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers\n",
    "model3.add(Embedding(20000,128))\n",
    "model3.add(LSTM(128,dropout = 0.2,recurent_dropout=0.2))\n",
    "model3.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df[sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = train_df['time3'][0]\n",
    "def isnan(x):\n",
    "    if x==c:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "is_nan = train_df['time1'].apply(isnan)\n",
    "for i in range(2,11):\n",
    "    is_nan = is_nan + train_df['time'+str(i)].apply(isnan )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# создадим отдельный датафрейм, где будем работать со временем\n",
    "time_df = pd.DataFrame(train_df[times]).reset_index()\n",
    "test_df = pd.DataFrame(test_df[times]).reset_index()\n",
    "#time_df['index'] = np.array(train_df['session_id'])\n",
    "time_df['target'] = train_df['target']\n",
    "# найдем время начала и окончания сессии\n",
    "#time_df['min'] = train_df[times].min(axis=1)\n",
    "#time_df['max'] = train_df[times].max(axis=1)\n",
    "test_df['target'] = -1\n",
    "time_df = pd.concat([time_df,test_df],axis=0)\n",
    "# вычислим длительность сессии и переведем в секунды\n",
    "#time_df['seconds'] = (time_df['max'] - time_df['min']) / np.timedelta64(1, 's')\n",
    "\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(time_df['time1'])\n",
    "time_df['Hour'] = dates.apply(lambda x: x.hour)\n",
    "time_df['day'] = dates.apply(lambda x: x.day)\n",
    "time_df['month'] = dates.apply(lambda x: x.month)\n",
    "time_df['year'] = dates.apply(lambda x: x.year)\n",
    "time_df['sec_in_week'+'time1'] = dates.apply(lambda x: 24*60*60*x.day+ 60*60*x.hour + 60*x.minute+x.second)\n",
    "time_df['sec_in_day'+'time1'] = dates.apply(lambda x: 60*60*x.hour + 60*x.minute+x.second)\n",
    "time_df['sec_in_hour'+\"time1\"] = dates.apply(lambda x: 60*x.minute+x.second)\n",
    "time_df.drop(['time1'],axis=1,inplace = True)\n",
    "for t in times[1:]:\n",
    "    dates = pd.to_datetime(time_df[t])\n",
    "    time_df['sec_in_week'+t] = dates.apply(lambda x: 24*60*60*x.day+ 60*60*x.hour + 60*x.minute+x.second)\n",
    "    time_df['sec_in_day'+t] = dates.apply(lambda x: 60*60*x.hour + 60*x.minute+x.second)\n",
    "    time_df['sec_in_hour'+t] = dates.apply(lambda x: 60*x.minute+x.second)\n",
    "    time_df.drop([t],axis=1,inplace = True)\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(times)-1):\n",
    "    t1 = times[i]\n",
    "    t2 = times[i+1]\n",
    "    time_df['delta_sec'+t2] = (time_df['sec_in_hour'+t2]-time_df['sec_in_hour'+t1])%3600\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_delta = ['delta_sectime%s'% i for i in range(2,11)]\n",
    "times_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis,skew, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_df['max-min'] = time_df[times_delta].max(axis=1) - time_df[times_delta].min(axis=1)\n",
    "time_df['std'] = time_df[times_delta].std(axis=1)\n",
    "time_df['mean'] = time_df[times_delta].mean(axis=1)\n",
    "time_df['median'] = time_df[times_delta].median(axis=1)\n",
    "time_df['max'] = time_df[times_delta].max(axis=1)\n",
    "time_df['min'] = time_df[times_delta].min(axis=1)\n",
    "time_df['sem'] = time_df[times_delta].sem(axis=1)\n",
    "time_df['sum'] = time_df[times_delta].sum(axis=1)\n",
    "time_df['kurtosis'] = time_df[times_delta].kurtosis(axis=1)\n",
    "time_df['skew'] = time_df[times_delta].skew(axis=1)\n",
    "#time_df['mode'] = time_df[times_delta].mode(axis=1)#error\n",
    "time_df['max+min'] = (time_df['max'] + time_df['min'])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "    if b>0:\n",
    "        return a/b\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_df['mean-med'] = time_df['mean'] - time_df['median']\n",
    "time_df['razmah_75_25'] = time_df['perc_75'] - time_df['perc_25']\n",
    "time_df['koef_oscil'] = time_df.apply(lambda row: divide(row['max-min'], row['mean']), axis=1)\n",
    "time_df['koef_oscil_med'] = time_df.apply(lambda row: divide(row['max-min'], row['median']), axis=1)\n",
    "time_df['koef_var_'] = time_df.apply(lambda row: divide(row['std'], row['mean']), axis=1)\n",
    "time_df['koef_var_med'] = time_df.apply(lambda row: divide(row['std'], row['median']), axis=1)\n",
    "time_df['koef_quant_'] = time_df.apply(lambda row: divide(row['razmah_75_25'], row['mean']), axis=1)\n",
    "time_df['koef_quant_med'] = time_df.apply(lambda row: divide(row['razmah_75_25'], row['median']), axis=1)\n",
    "time_df['mean/med'] = time_df.apply(lambda row: divide(row['mean'], row['median']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = np.concatenate((time_df, train_df_mean), axis=1)\n",
    "test_df = np.concatenate((time_df_t, test_df_mean), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 50000) (82797, 50000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True,ngram_range=(1, 5),max_features = 50000)\n",
    "vectorizer.fit(train_df['list'])\n",
    "\n",
    "X_train = vectorizer.transform(train_df['list'])\n",
    "Xtest = vectorizer.transform(test_df['list'])\n",
    "print(X_train.shape,Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89603896283978868"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1, seed=7):\n",
    "    # разделим выборку на обучающую и валидационную\n",
    "    idx = 170764\n",
    "    # обучение классификатора\n",
    "    lr = LogisticRegression(C=C, random_state=seed, n_jobs=4).fit(X[:idx, :], y[:idx])\n",
    "    # прогноз для валидационной выборки\n",
    "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
    "    # считаем качество\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89554681954754056"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df['target']\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_new_feat = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "# добавим признак start_month\n",
    "#full_new_feat['start'] = full_df['time1'].apply(lambda ts: 1000000 * ts.year +ts.month*10000+ ts.day*100+ts.hour)\n",
    "full_new_feat['start_day_y'] = full_df['time1'].apply(lambda ts: 10000 * ts.year +ts.month*100+ ts.day)\n",
    "#full_new_feat['start_month'] = full_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)\n",
    "#full_new_feat['start_moth_mh'] = full_df['time1'].apply(lambda ts: ts.month*10000+ ts.day*100+ts.hour)\n",
    "full_new_feat['start_moth_dh'] = full_df['time1'].apply(lambda ts: ts.day*100+ts.hour)\n",
    "#full_new_feat['day'] = full_df['time1'].apply(lambda ts: ts.day)\n",
    "#full_new_feat['minut'] = full_df['time1'].apply(lambda x: x.minute)\n",
    "full_new_feat['weekday'] = full_df['time1'].apply(lambda x: x.dayofweek)\n",
    "#full_new_feat['dayofyear'] = full_df['time1'].apply(lambda x: x.dayofyear)\n",
    "#full_new_feat['weekand'] = full_new_feat['weekday'].apply(weekand)\n",
    "full_new_feat['start_week'] = 100*full_new_feat['weekday']+full_df['time1'].apply(lambda ts:  ts.hour)\n",
    "full_new_feat['long'] = (full_df['time2'].apply(lambda ts:  ts.minute)-full_df['time1'].apply(lambda ts:  ts.minute))%3600\n",
    "full_new_feat['start_hour'] = full_df['time1'].apply(lambda ts: ts.hour)\n",
    "full_new_feat['morning'] = full_new_feat['start_hour'].apply(lambda hour: int(hour <= 10))\n",
    "full_new_feat['sec_in_day'+\"time1\"] = full_df['time1'].apply(lambda x: 60*x.minute+x.second)\n",
    "for t in times[1:]:\n",
    "    full_new_feat['sec_in_day'+t] = full_df[t].apply(lambda x: 60*60*x.hour + 60*x.minute+x.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_day_y</th>\n",
       "      <th>start_moth_dh</th>\n",
       "      <th>weekday</th>\n",
       "      <th>start_week</th>\n",
       "      <th>long</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>sec_in_daytime1</th>\n",
       "      <th>sec_in_daytime2</th>\n",
       "      <th>sec_in_daytime3</th>\n",
       "      <th>...</th>\n",
       "      <th>sec_in_daytime10</th>\n",
       "      <th>delta_sectime2</th>\n",
       "      <th>delta_sectime3</th>\n",
       "      <th>delta_sectime4</th>\n",
       "      <th>delta_sectime5</th>\n",
       "      <th>delta_sectime6</th>\n",
       "      <th>delta_sectime7</th>\n",
       "      <th>delta_sectime8</th>\n",
       "      <th>delta_sectime9</th>\n",
       "      <th>delta_sectime10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21668</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>357</td>\n",
       "      <td>29157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54842</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2243</td>\n",
       "      <td>31043.0</td>\n",
       "      <td>32827.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77291</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3013</td>\n",
       "      <td>31814.0</td>\n",
       "      <td>31815.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31817.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114020</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3017</td>\n",
       "      <td>31817.0</td>\n",
       "      <td>31818.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146669</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3020</td>\n",
       "      <td>31820.0</td>\n",
       "      <td>31820.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31822.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_day_y  start_moth_dh  weekday  start_week  long  start_hour  \\\n",
       "21668      20130112           1208        5         508   0.0           8   \n",
       "54842      20130112           1208        5         508   0.0           8   \n",
       "77291      20130112           1208        5         508   0.0           8   \n",
       "114020     20130112           1208        5         508   0.0           8   \n",
       "146669     20130112           1208        5         508   0.0           8   \n",
       "\n",
       "        morning  sec_in_daytime1  sec_in_daytime2  sec_in_daytime3  \\\n",
       "21668         1              357          29157.0              NaN   \n",
       "54842         1             2243          31043.0          32827.0   \n",
       "77291         1             3013          31814.0          31815.0   \n",
       "114020        1             3017          31817.0          31818.0   \n",
       "146669        1             3020          31820.0          31820.0   \n",
       "\n",
       "             ...         sec_in_daytime10  delta_sectime2  delta_sectime3  \\\n",
       "21668        ...                      NaN             0.0             NaN   \n",
       "54842        ...                      NaN             0.0          1784.0   \n",
       "77291        ...                  31817.0             1.0             1.0   \n",
       "114020       ...                  31820.0             0.0             1.0   \n",
       "146669       ...                  31822.0             0.0             0.0   \n",
       "\n",
       "        delta_sectime4  delta_sectime5  delta_sectime6  delta_sectime7  \\\n",
       "21668              NaN             NaN             NaN             NaN   \n",
       "54842              2.0             NaN             NaN             NaN   \n",
       "77291              0.0             1.0             0.0             0.0   \n",
       "114020             0.0             0.0             0.0             1.0   \n",
       "146669             1.0             0.0             0.0             0.0   \n",
       "\n",
       "        delta_sectime8  delta_sectime9  delta_sectime10  \n",
       "21668              NaN             NaN              NaN  \n",
       "54842              NaN             NaN              NaN  \n",
       "77291              0.0             1.0              0.0  \n",
       "114020             0.0             0.0              1.0  \n",
       "146669             1.0             0.0              0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(times)-1):\n",
    "    t1 = times[i]\n",
    "    t2 = times[i+1]\n",
    "    full_new_feat['delta_sec'+t2] = (full_new_feat['sec_in_day'+t2]-full_new_feat['sec_in_day'+t1])%3600\n",
    "full_new_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_delta = ['delta_sectime%s'% i for i in range(2,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis,skew, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_day_y</th>\n",
       "      <th>start_moth_dh</th>\n",
       "      <th>weekday</th>\n",
       "      <th>start_week</th>\n",
       "      <th>long</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>sec_in_daytime1</th>\n",
       "      <th>sec_in_daytime2</th>\n",
       "      <th>sec_in_daytime3</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>sem</th>\n",
       "      <th>sum</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>skew</th>\n",
       "      <th>max+min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21668</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>357</td>\n",
       "      <td>29157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54842</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2243</td>\n",
       "      <td>31043.0</td>\n",
       "      <td>32827.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1029.416016</td>\n",
       "      <td>595.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.333614</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.732043</td>\n",
       "      <td>892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77291</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3013</td>\n",
       "      <td>31814.0</td>\n",
       "      <td>31815.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175682</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.571429</td>\n",
       "      <td>0.271052</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114020</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3017</td>\n",
       "      <td>31817.0</td>\n",
       "      <td>31818.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146669</th>\n",
       "      <td>20130112</td>\n",
       "      <td>1208</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3020</td>\n",
       "      <td>31820.0</td>\n",
       "      <td>31820.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440959</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146986</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>1.619848</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_day_y  start_moth_dh  weekday  start_week  long  start_hour  \\\n",
       "21668      20130112           1208        5         508   0.0           8   \n",
       "54842      20130112           1208        5         508   0.0           8   \n",
       "77291      20130112           1208        5         508   0.0           8   \n",
       "114020     20130112           1208        5         508   0.0           8   \n",
       "146669     20130112           1208        5         508   0.0           8   \n",
       "\n",
       "        morning  sec_in_daytime1  sec_in_daytime2  sec_in_daytime3   ...     \\\n",
       "21668         1              357          29157.0              NaN   ...      \n",
       "54842         1             2243          31043.0          32827.0   ...      \n",
       "77291         1             3013          31814.0          31815.0   ...      \n",
       "114020        1             3017          31817.0          31818.0   ...      \n",
       "146669        1             3020          31820.0          31820.0   ...      \n",
       "\n",
       "                std        mean  median     max  min         sem     sum  \\\n",
       "21668           NaN    0.000000     0.0     0.0  0.0         NaN     0.0   \n",
       "54842   1029.416016  595.333333     2.0  1784.0  0.0  594.333614  1786.0   \n",
       "77291      0.527046    0.444444     0.0     1.0  0.0    0.175682     4.0   \n",
       "114020     0.500000    0.333333     0.0     1.0  0.0    0.166667     3.0   \n",
       "146669     0.440959    0.222222     0.0     1.0  0.0    0.146986     2.0   \n",
       "\n",
       "        kurtosis      skew  max+min  \n",
       "21668        NaN       NaN      0.0  \n",
       "54842        NaN  1.732043    892.0  \n",
       "77291  -2.571429  0.271052      0.5  \n",
       "114020 -1.714286  0.857143      0.5  \n",
       "146669  0.734694  1.619848      0.5  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_new_feat['max-min'] = full_new_feat[times_delta].max(axis=1) - full_new_feat[times_delta].min(axis=1)\n",
    "full_new_feat['std'] = full_new_feat[times_delta].std(axis=1)\n",
    "full_new_feat['mean'] = full_new_feat[times_delta].mean(axis=1)\n",
    "full_new_feat['median'] = full_new_feat[times_delta].median(axis=1)\n",
    "full_new_feat['max'] = full_new_feat[times_delta].max(axis=1)\n",
    "full_new_feat['min'] = full_new_feat[times_delta].min(axis=1)\n",
    "full_new_feat['sem'] = full_new_feat[times_delta].sem(axis=1)\n",
    "full_new_feat['sum'] = full_new_feat[times_delta].sum(axis=1)\n",
    "full_new_feat['kurtosis'] = full_new_feat[times_delta].kurtosis(axis=1)\n",
    "full_new_feat['skew'] = full_new_feat[times_delta].skew(axis=1)\n",
    "#time_df['mode'] = time_df[times_delta].mode(axis=1)#error\n",
    "full_new_feat['max+min'] = (full_new_feat['max'] + full_new_feat['min'])*0.5\n",
    "full_new_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_new_feat = full_new_feat.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_moth_dh', 'start_hour','start_day_y',\\\n",
    "                                                          'start_week','long','max-min','sec_in_daytime10','delta_sectime10',\\\n",
    "                                                          'std','kurtosis']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_moth_dh', 'start_hour','start_day_y',\\\n",
    "                                                          'start_week','long','max-min','sec_in_daytime10','delta_sectime10',\\\n",
    "                                                          'std','kurtosis']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csr_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c0f381c7bec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_auc_lr_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csr_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "X_tr = csr_matrix(hstack([StandardScaler().fit_transform(X_train),StandardScaler().fit_transform(data_mean)]))\n",
    "print(get_auc_lr_valid(X_tr, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_mean = mean_vectorizer(w2v).fit(train_df['list_w']).transform(train_df['list_w'])\n",
    "test_df_mean = mean_vectorizer(w2v).fit(test_df['list_w']).transform(test_df['list_w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 50000), (253561, 400), (336358, 10))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,train_df_mean.shape,tmp_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_moth_dh', 'start_hour','start_day_y',\\\n",
    "                                                          'start_week','long','max-min','sec_in_daytime10','delta_sectime10',\\\n",
    "                                                          'std','kurtosis']])\n",
    "X_tr = csr_matrix(hstack([train_df_mean,X_train,tmp_scaled[:idx_split,:]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_te = csr_matrix(hstack([test_df_mean,Xtest,tmp_scaled[idx_split:,:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr = csr_matrix(hstack([X_train,train_df_mean]))\n",
    "X_te = csr_matrix(hstack([Xtest,test_df_mean]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 50410), (82797, 50410))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape,X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88938028885705211"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_tr, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89687165764807963"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_tr, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1, random_state=7, n_jobs=4).fit(X_tr, y)\n",
    "y_pred = lr.predict_proba(X_te)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(y_pred, 'pred/w2vandtf_idf_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21668</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54842</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77291</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114020</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146669</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index               time1               time2               time3  \\\n",
       "0   21668 2013-01-12 08:05:57 2013-01-12 08:05:57                 NaT   \n",
       "1   54842 2013-01-12 08:37:23 2013-01-12 08:37:23 2013-01-12 09:07:07   \n",
       "2   77291 2013-01-12 08:50:13 2013-01-12 08:50:14 2013-01-12 08:50:15   \n",
       "3  114020 2013-01-12 08:50:17 2013-01-12 08:50:17 2013-01-12 08:50:18   \n",
       "4  146669 2013-01-12 08:50:20 2013-01-12 08:50:20 2013-01-12 08:50:20   \n",
       "\n",
       "                time4               time5               time6  \\\n",
       "0                 NaT                 NaT                 NaT   \n",
       "1 2013-01-12 09:07:09                 NaT                 NaT   \n",
       "2 2013-01-12 08:50:15 2013-01-12 08:50:16 2013-01-12 08:50:16   \n",
       "3 2013-01-12 08:50:18 2013-01-12 08:50:18 2013-01-12 08:50:18   \n",
       "4 2013-01-12 08:50:21 2013-01-12 08:50:21 2013-01-12 08:50:21   \n",
       "\n",
       "                time7               time8               time9  \\\n",
       "0                 NaT                 NaT                 NaT   \n",
       "1                 NaT                 NaT                 NaT   \n",
       "2 2013-01-12 08:50:16 2013-01-12 08:50:16 2013-01-12 08:50:17   \n",
       "3 2013-01-12 08:50:19 2013-01-12 08:50:19 2013-01-12 08:50:19   \n",
       "4 2013-01-12 08:50:21 2013-01-12 08:50:22 2013-01-12 08:50:22   \n",
       "\n",
       "               time10  target  \n",
       "0                 NaT       0  \n",
       "1                 NaT       0  \n",
       "2 2013-01-12 08:50:17       0  \n",
       "3 2013-01-12 08:50:20       0  \n",
       "4 2013-01-12 08:50:22       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим отдельный датафрейм, где будем работать со временем\n",
    "time_df = pd.DataFrame(train_df[times]).reset_index()\n",
    "test_df = pd.DataFrame(test_df[times]).reset_index()\n",
    "#time_df['index'] = np.array(train_df['session_id'])\n",
    "time_df['target'] = train_df['target']\n",
    "# найдем время начала и окончания сессии\n",
    "#time_df['min'] = train_df[times].min(axis=1)\n",
    "#time_df['max'] = train_df[times].max(axis=1)\n",
    "\n",
    "# вычислим длительность сессии и переведем в секунды\n",
    "#time_df['seconds'] = (time_df['max'] - time_df['min']) / np.timedelta64(1, 's')\n",
    "\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['target'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336358, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df = pd.concat([time_df,test_df],axis=0)\n",
    "time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_moth_dh', 'start_hour','start_day_y',\\\n",
    "                                            'start_week','long','max-min','sec_in_daytime10','delta_sectime10',\\\n",
    "                                                          'std','kurtosis']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(time_df['time1'])\n",
    "time_df['Hour'] = dates.apply(lambda x: x.hour)\n",
    "time_df['day'] = dates.apply(lambda x: x.day)\n",
    "time_df['month'] = dates.apply(lambda x: x.month)\n",
    "time_df['year'] = dates.apply(lambda x: x.year)\n",
    "time_df['sec_in_week'+'time1'] = dates.apply(lambda x: 24*60*60*x.day+ 60*60*x.hour + 60*x.minute+x.second)\n",
    "time_df['sec_in_day'+'time1'] = dates.apply(lambda x: 60*60*x.hour + 60*x.minute+x.second)\n",
    "time_df['sec_in_hour'+\"time1\"] = dates.apply(lambda x: 60*x.minute+x.second)\n",
    "time_df.drop(['time1'],axis=1,inplace = True)\n",
    "for t in times[1:]:\n",
    "    dates = pd.to_datetime(time_df[t])\n",
    "    time_df['sec_in_week'+t] = dates.apply(lambda x: 24*60*60*x.day+ 60*60*x.hour + 60*x.minute+x.second)\n",
    "    time_df['sec_in_day'+t] = dates.apply(lambda x: 60*60*x.hour + 60*x.minute+x.second)\n",
    "    time_df['sec_in_hour'+t] = dates.apply(lambda x: 60*x.minute+x.second)\n",
    "    time_df.drop([t],axis=1,inplace = True)\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(times)-1):\n",
    "    t1 = times[i]\n",
    "    t2 = times[i+1]\n",
    "    time_df['delta_sec'+t2] = (time_df['sec_in_hour'+t2]-time_df['sec_in_hour'+t1])%3600\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_delta = ['delta_sectime%s'% i for i in range(2,11)]\n",
    "times_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis,skew, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_df['max-min'] = time_df[times_delta].max(axis=1) - time_df[times_delta].min(axis=1)\n",
    "time_df['std'] = time_df[times_delta].std(axis=1)\n",
    "time_df['mean'] = time_df[times_delta].mean(axis=1)\n",
    "time_df['median'] = time_df[times_delta].median(axis=1)\n",
    "time_df['max'] = time_df[times_delta].max(axis=1)\n",
    "time_df['min'] = time_df[times_delta].min(axis=1)\n",
    "time_df['sem'] = time_df[times_delta].sem(axis=1)\n",
    "time_df['sum'] = time_df[times_delta].sum(axis=1)\n",
    "time_df['kurtosis'] = time_df[times_delta].kurtosis(axis=1)\n",
    "time_df['skew'] = time_df[times_delta].skew(axis=1)\n",
    "#time_df['mode'] = time_df[times_delta].mode(axis=1)#error\n",
    "time_df['max+min'] = (time_df['max'] + time_df['min'])*0.5\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

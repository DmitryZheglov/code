{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import time\n",
    "pd.set_option(\"display.max_columns\",1000)\n",
    "pd.set_option('display.max_rows',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.027"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    con = 2\n",
    "    x = preds - labels\n",
    "    grad = con * x / (np.abs(x) + con)\n",
    "    hess = con ** 2 / (np.abs(x) + con) ** 2\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y),\n",
    "                                      np.exp(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))\n",
    "def dif_feat(data,feat):\n",
    "    new_data = pd.DateFrame()\n",
    "    for i in range(len(feat)):\n",
    "        for j in range(i+1,len(feat)):\n",
    "            new_data[feat[i]+\"-\"+feat[j]] = data[feat[i]] - data[feat[j]]\n",
    "        print(feat[i])\n",
    "    return new_data\n",
    "    del new_data\n",
    "def transf_cat(train,test,feat_cat,feat_cont,fold):\n",
    "    test['Proba'] = 0\n",
    "    train['Proba'] = 0\n",
    "    n_folds = fold\n",
    "    kf = KFold(train.shape[0],n_folds)#,shuffle=True\n",
    "    for train_index, val_index in kf:\n",
    "        print(\"new_fold\")\n",
    "        training_data, validation_data = train.loc[train_index], train.loc[val_index]\n",
    "        training_data['new_feat'] = training_data.groupby(feat_cat)[feat_cont].transform(\"mean\")\n",
    "        dat = training_data.groupby(feat_cat,as_index=False).mean()\n",
    "        d={}\n",
    "        for i in range(len(dat)):\n",
    "            d[dat[feat_cat][i]] = dat['new_feat'][i]\n",
    "        m=np.mean(training_data[feat_cont])\n",
    "        def gr(x):\n",
    "            try:\n",
    "                return d[x]\n",
    "            except:\n",
    "                return m  \n",
    "        train['Proba'].loc[val_index] = train[feat_cat].loc[val_index].apply(gr)\n",
    "        test_new = test[feat_cat].apply(gr)\n",
    "        test['Proba'] += np.array(test_new)\n",
    "    return train['Proba'],test['Proba']*(1/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob_xgb(train,test,feat,fold,y,method,i):\n",
    "    h = []\n",
    "    proba = 0\n",
    "    params = {\n",
    "        'max_depth': 4,\n",
    "        'eta': 0.1,\n",
    "        'nthread': 4,\n",
    "        'subsample': 0.8,\n",
    "        'eval_metric': ['mae'],\n",
    "        'objective': 'reg:linear',\n",
    "        'colsample_bytree': 0.6,\n",
    "        'min_child_weight': 0,\n",
    "        #'scale_pos_weight':(1-train.Label.mean())/train.Label.mean(),\n",
    "        'seed':7\n",
    "    }\n",
    "    train['pred'+method+str(i)]=0\n",
    "    test['pred'+method+str(i)] =0 \n",
    "    kf = KFold(train.shape[0], n_folds=fold,shuffle=True)\n",
    "    for train_index, val_index in kf:\n",
    "        training_data, validation_data = train.loc[train_index], train.loc[val_index]\n",
    "        dtr = xgb.DMatrix(training_data[feat], label=training_data[y])\n",
    "        dval = xgb.DMatrix(validation_data[feat], label=validation_data[y])\n",
    "        watchlist = [(dtr, 'train'), (dval, 'eval')]\n",
    "        history = dict()\n",
    "        model0 = xgb.train(params, dtr, num_boost_round=1000, evals=watchlist,evals_result=history, verbose_eval=10)\n",
    "        train['pred'+method].loc[val_index] = model0.predict_proba(dval)\n",
    "        dtest = xgb.DMatrix(test[feat])\n",
    "        proba = proba+model0.predict(dtest)\n",
    "        imps = pd.Series(model0.get_fscore()).sort_values()\n",
    "        h.append(imps)\n",
    "    return proba*(1/fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 200\n",
    "def get_prob_lin(train,test,feat,fold,y,method,i):\n",
    "    model0 = linear_model.LinearRegression()\n",
    "    train['pred'+method+str(i)]=0\n",
    "    test['pred'+method+str(i)] =0 \n",
    "    er = []\n",
    "    proba = 0\n",
    "    kf = KFold(train.shape[0], n_folds=fold,shuffle=True)\n",
    "    for train_index, val_index in kf:\n",
    "        training_data, validation_data = train.loc[train_index], train.loc[val_index]\n",
    "        model0.fit(np.log(training_data[feat]+shift),np.log(training_data[y]+shift))\n",
    "        pred = model0.predict(np.log(validation_data[feat]+shift))\n",
    "        pred = np.exp(pred)-shift\n",
    "        er.append(mean_absolute_error(pred,validation_data[y]))\n",
    "        print(\"mae\",mean_absolute_error(pred,validation_data[y]))\n",
    "        train['pred'+method+str(i)].loc[val_index] = pred\n",
    "        proba = proba+model0.predict(np.log(test[feat]+shift))\n",
    "    print(\"mean\",np.mean(er))\n",
    "    test['pred'+method+str(i)]=(np.exp(proba)-shift)*(1/fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "      <th>cat19</th>\n",
       "      <th>cat20</th>\n",
       "      <th>cat21</th>\n",
       "      <th>cat22</th>\n",
       "      <th>cat23</th>\n",
       "      <th>cat24</th>\n",
       "      <th>cat25</th>\n",
       "      <th>cat26</th>\n",
       "      <th>cat27</th>\n",
       "      <th>cat28</th>\n",
       "      <th>cat29</th>\n",
       "      <th>cat30</th>\n",
       "      <th>cat31</th>\n",
       "      <th>cat32</th>\n",
       "      <th>cat33</th>\n",
       "      <th>cat34</th>\n",
       "      <th>cat35</th>\n",
       "      <th>cat36</th>\n",
       "      <th>cat37</th>\n",
       "      <th>cat38</th>\n",
       "      <th>cat39</th>\n",
       "      <th>cat40</th>\n",
       "      <th>cat41</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat43</th>\n",
       "      <th>cat44</th>\n",
       "      <th>cat45</th>\n",
       "      <th>cat46</th>\n",
       "      <th>cat47</th>\n",
       "      <th>cat48</th>\n",
       "      <th>cat49</th>\n",
       "      <th>cat50</th>\n",
       "      <th>cat51</th>\n",
       "      <th>cat52</th>\n",
       "      <th>cat53</th>\n",
       "      <th>cat54</th>\n",
       "      <th>cat55</th>\n",
       "      <th>cat56</th>\n",
       "      <th>cat57</th>\n",
       "      <th>cat58</th>\n",
       "      <th>cat59</th>\n",
       "      <th>cat60</th>\n",
       "      <th>cat61</th>\n",
       "      <th>cat62</th>\n",
       "      <th>cat63</th>\n",
       "      <th>cat64</th>\n",
       "      <th>cat65</th>\n",
       "      <th>cat66</th>\n",
       "      <th>cat67</th>\n",
       "      <th>cat68</th>\n",
       "      <th>cat69</th>\n",
       "      <th>cat70</th>\n",
       "      <th>cat71</th>\n",
       "      <th>cat72</th>\n",
       "      <th>cat73</th>\n",
       "      <th>cat74</th>\n",
       "      <th>cat75</th>\n",
       "      <th>cat76</th>\n",
       "      <th>cat77</th>\n",
       "      <th>cat78</th>\n",
       "      <th>cat79</th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat81</th>\n",
       "      <th>cat82</th>\n",
       "      <th>cat83</th>\n",
       "      <th>cat84</th>\n",
       "      <th>cat85</th>\n",
       "      <th>cat86</th>\n",
       "      <th>cat87</th>\n",
       "      <th>cat88</th>\n",
       "      <th>cat89</th>\n",
       "      <th>cat90</th>\n",
       "      <th>cat91</th>\n",
       "      <th>cat92</th>\n",
       "      <th>cat93</th>\n",
       "      <th>cat94</th>\n",
       "      <th>cat95</th>\n",
       "      <th>cat96</th>\n",
       "      <th>cat97</th>\n",
       "      <th>cat98</th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat102</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>B</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>BU</td>\n",
       "      <td>BC</td>\n",
       "      <td>C</td>\n",
       "      <td>AS</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>LB</td>\n",
       "      <td>0.726300</td>\n",
       "      <td>0.245921</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CQ</td>\n",
       "      <td>A</td>\n",
       "      <td>AV</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DP</td>\n",
       "      <td>0.330514</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>O</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>AB</td>\n",
       "      <td>DK</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>AF</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>GK</td>\n",
       "      <td>0.261841</td>\n",
       "      <td>0.358319</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>AE</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DJ</td>\n",
       "      <td>0.321594</td>\n",
       "      <td>0.555782</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>K</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>CK</td>\n",
       "      <td>0.273204</td>\n",
       "      <td>0.159990</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10 cat11 cat12 cat13  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B     A     B     A     A   \n",
       "1   2    A    B    A    A    A    A    A    A    B     B     A     A     A   \n",
       "2   5    A    B    A    A    B    A    A    A    B     B     B     B     B   \n",
       "3  10    B    B    A    B    A    A    A    A    B     A     A     A     A   \n",
       "4  11    A    B    A    B    A    A    A    A    B     B     A     B     A   \n",
       "\n",
       "  cat14 cat15 cat16 cat17 cat18 cat19 cat20 cat21 cat22 cat23 cat24 cat25  \\\n",
       "0     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "\n",
       "  cat26 cat27 cat28 cat29 cat30 cat31 cat32 cat33 cat34 cat35 cat36 cat37  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat38 cat39 cat40 cat41 cat42 cat43 cat44 cat45 cat46 cat47 cat48 cat49  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat50 cat51 cat52 cat53 cat54 cat55 cat56 cat57 cat58 cat59 cat60 cat61  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat62 cat63 cat64 cat65 cat66 cat67 cat68 cat69 cat70 cat71 cat72 cat73  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     B   \n",
       "4     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "\n",
       "  cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81 cat82 cat83 cat84 cat85  \\\n",
       "0     A     B     A     D     B     B     D     D     B     D     C     B   \n",
       "1     A     A     A     D     B     B     D     D     A     B     C     B   \n",
       "2     A     A     A     D     B     B     B     D     B     D     C     B   \n",
       "3     A     A     A     D     B     B     D     D     D     B     C     B   \n",
       "4     A     A     A     D     B     D     B     D     B     B     C     B   \n",
       "\n",
       "  cat86 cat87 cat88 cat89 cat90 cat91 cat92 cat93 cat94 cat95 cat96 cat97  \\\n",
       "0     D     B     A     A     A     A     A     D     B     C     E     A   \n",
       "1     D     B     A     A     A     A     A     D     D     C     E     E   \n",
       "2     B     B     A     A     A     A     A     D     D     C     E     E   \n",
       "3     D     B     A     A     A     A     A     D     D     C     E     E   \n",
       "4     B     C     A     A     A     B     H     D     B     D     E     E   \n",
       "\n",
       "  cat98 cat99 cat100 cat101 cat102 cat103 cat104 cat105 cat106 cat107 cat108  \\\n",
       "0     C     T      B      G      A      A      I      E      G      J      G   \n",
       "1     D     T      L      F      A      A      E      E      I      K      K   \n",
       "2     A     D      L      O      A      B      E      F      H      F      A   \n",
       "3     D     T      I      D      A      A      E      E      I      K      K   \n",
       "4     A     P      F      J      A      A      D      E      K      G      B   \n",
       "\n",
       "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116     cont1     cont2  \\\n",
       "0     BU     BC      C     AS      S      A      O     LB  0.726300  0.245921   \n",
       "1     BI     CQ      A     AV     BM      A      O     DP  0.330514  0.737068   \n",
       "2     AB     DK      A      C     AF      A      I     GK  0.261841  0.358319   \n",
       "3     BI     CS      C      N     AE      A      O     DJ  0.321594  0.555782   \n",
       "4      H      C      C      Y     BM      A      K     CK  0.273204  0.159990   \n",
       "\n",
       "      cont3     cont4     cont5     cont6     cont7    cont8    cont9  \\\n",
       "0  0.187583  0.789639  0.310061  0.718367  0.335060  0.30260  0.67135   \n",
       "1  0.592681  0.614134  0.885834  0.438917  0.436585  0.60087  0.35127   \n",
       "2  0.484196  0.236924  0.397069  0.289648  0.315545  0.27320  0.26076   \n",
       "3  0.527991  0.373816  0.422268  0.440945  0.391128  0.31796  0.32128   \n",
       "4  0.527991  0.473202  0.704268  0.178193  0.247408  0.24564  0.22089   \n",
       "\n",
       "    cont10    cont11    cont12    cont13    cont14     loss  \n",
       "0  0.83510  0.569745  0.594646  0.822493  0.714843  2213.18  \n",
       "1  0.43919  0.338312  0.366307  0.611431  0.304496  1283.60  \n",
       "2  0.32446  0.381398  0.373424  0.195709  0.774425  3005.09  \n",
       "3  0.44467  0.327915  0.321570  0.605077  0.602642   939.85  \n",
       "4  0.21230  0.204687  0.202213  0.246011  0.432606  2763.85  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "      <th>cat19</th>\n",
       "      <th>cat20</th>\n",
       "      <th>cat21</th>\n",
       "      <th>cat22</th>\n",
       "      <th>cat23</th>\n",
       "      <th>cat24</th>\n",
       "      <th>cat25</th>\n",
       "      <th>cat26</th>\n",
       "      <th>cat27</th>\n",
       "      <th>cat28</th>\n",
       "      <th>cat29</th>\n",
       "      <th>cat30</th>\n",
       "      <th>cat31</th>\n",
       "      <th>cat32</th>\n",
       "      <th>cat33</th>\n",
       "      <th>cat34</th>\n",
       "      <th>cat35</th>\n",
       "      <th>cat36</th>\n",
       "      <th>cat37</th>\n",
       "      <th>cat38</th>\n",
       "      <th>cat39</th>\n",
       "      <th>cat40</th>\n",
       "      <th>cat41</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat43</th>\n",
       "      <th>cat44</th>\n",
       "      <th>cat45</th>\n",
       "      <th>cat46</th>\n",
       "      <th>cat47</th>\n",
       "      <th>cat48</th>\n",
       "      <th>cat49</th>\n",
       "      <th>cat50</th>\n",
       "      <th>cat51</th>\n",
       "      <th>cat52</th>\n",
       "      <th>cat53</th>\n",
       "      <th>cat54</th>\n",
       "      <th>cat55</th>\n",
       "      <th>cat56</th>\n",
       "      <th>cat57</th>\n",
       "      <th>cat58</th>\n",
       "      <th>cat59</th>\n",
       "      <th>cat60</th>\n",
       "      <th>cat61</th>\n",
       "      <th>cat62</th>\n",
       "      <th>cat63</th>\n",
       "      <th>cat64</th>\n",
       "      <th>cat65</th>\n",
       "      <th>cat66</th>\n",
       "      <th>cat67</th>\n",
       "      <th>cat68</th>\n",
       "      <th>cat69</th>\n",
       "      <th>cat70</th>\n",
       "      <th>cat71</th>\n",
       "      <th>cat72</th>\n",
       "      <th>cat73</th>\n",
       "      <th>cat74</th>\n",
       "      <th>cat75</th>\n",
       "      <th>cat76</th>\n",
       "      <th>cat77</th>\n",
       "      <th>cat78</th>\n",
       "      <th>cat79</th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat81</th>\n",
       "      <th>cat82</th>\n",
       "      <th>cat83</th>\n",
       "      <th>cat84</th>\n",
       "      <th>cat85</th>\n",
       "      <th>cat86</th>\n",
       "      <th>cat87</th>\n",
       "      <th>cat88</th>\n",
       "      <th>cat89</th>\n",
       "      <th>cat90</th>\n",
       "      <th>cat91</th>\n",
       "      <th>cat92</th>\n",
       "      <th>cat93</th>\n",
       "      <th>cat94</th>\n",
       "      <th>cat95</th>\n",
       "      <th>cat96</th>\n",
       "      <th>cat97</th>\n",
       "      <th>cat98</th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat102</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>BC</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>AX</td>\n",
       "      <td>A</td>\n",
       "      <td>Q</td>\n",
       "      <td>HG</td>\n",
       "      <td>0.321594</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.246911</td>\n",
       "      <td>0.402922</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.377724</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>CO</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>HK</td>\n",
       "      <td>0.634734</td>\n",
       "      <td>0.620805</td>\n",
       "      <td>0.654310</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.689039</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>C</td>\n",
       "      <td>U</td>\n",
       "      <td>AE</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>CK</td>\n",
       "      <td>0.290813</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.711159</td>\n",
       "      <td>0.412789</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CR</td>\n",
       "      <td>A</td>\n",
       "      <td>AY</td>\n",
       "      <td>AJ</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>DJ</td>\n",
       "      <td>0.268622</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>0.348867</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>AB</td>\n",
       "      <td>EG</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>C</td>\n",
       "      <td>J</td>\n",
       "      <td>HA</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.263570</td>\n",
       "      <td>0.696873</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.359572</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10 cat11 cat12 cat13  \\\n",
       "0   4    A    B    A    A    A    A    A    A    B     A     B     A     A   \n",
       "1   6    A    B    A    B    A    A    A    A    B     A     A     A     A   \n",
       "2   9    A    B    A    B    B    A    B    A    B     B     A     B     B   \n",
       "3  12    A    A    A    A    B    A    A    A    A     A     A     A     A   \n",
       "4  15    B    A    A    A    A    B    A    A    A     A     A     A     A   \n",
       "\n",
       "  cat14 cat15 cat16 cat17 cat18 cat19 cat20 cat21 cat22 cat23 cat24 cat25  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     B     B     A   \n",
       "2     B     A     A     A     A     A     A     A     A     B     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat26 cat27 cat28 cat29 cat30 cat31 cat32 cat33 cat34 cat35 cat36 cat37  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat38 cat39 cat40 cat41 cat42 cat43 cat44 cat45 cat46 cat47 cat48 cat49  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     B     B     A     A     A     A     A     A     A     A     A     A   \n",
       "3     B     A     A     B     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat50 cat51 cat52 cat53 cat54 cat55 cat56 cat57 cat58 cat59 cat60 cat61  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     B     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     B     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat62 cat63 cat64 cat65 cat66 cat67 cat68 cat69 cat70 cat71 cat72 cat73  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81 cat82 cat83 cat84 cat85  \\\n",
       "0     A     A     A     D     B     B     D     D     B     B     C     B   \n",
       "1     A     B     A     D     B     B     D     D     B     B     C     B   \n",
       "2     A     A     B     D     B     B     B     B     B     D     C     B   \n",
       "3     A     A     A     D     B     D     B     D     B     B     A     B   \n",
       "4     A     A     A     D     B     B     D     D     B     B     C     B   \n",
       "\n",
       "  cat86 cat87 cat88 cat89 cat90 cat91 cat92 cat93 cat94 cat95 cat96 cat97  \\\n",
       "0     D     B     A     A     A     A     A     D     C     C     E     C   \n",
       "1     B     B     A     A     A     A     A     D     D     D     E     A   \n",
       "2     B     B     A     B     A     A     A     D     D     C     E     E   \n",
       "3     D     D     A     A     A     G     H     D     D     C     E     E   \n",
       "4     B     B     A     A     A     A     A     D     B     D     E     A   \n",
       "\n",
       "  cat98 cat99 cat100 cat101 cat102 cat103 cat104 cat105 cat106 cat107 cat108  \\\n",
       "0     D     T      H      G      A      A      G      E      I      L      K   \n",
       "1     A     P      B      D      A      A      G      G      G      F      B   \n",
       "2     A     D      G      Q      A      D      D      E      J      G      A   \n",
       "3     D     T      G      A      A      D      E      E      I      K      K   \n",
       "4     A     P      A      A      A      A      F      E      G      E      B   \n",
       "\n",
       "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116     cont1     cont2  \\\n",
       "0     BI     BC      A      J     AX      A      Q     HG  0.321594  0.299102   \n",
       "1     BI     CO      E      G      X      A      L     HK  0.634734  0.620805   \n",
       "2     BI     CS      C      U     AE      A      K     CK  0.290813  0.737068   \n",
       "3     BI     CR      A     AY     AJ      A      P     DJ  0.268622  0.681761   \n",
       "4     AB     EG      A      E      I      C      J     HA  0.553846  0.299102   \n",
       "\n",
       "      cont3     cont4     cont5     cont6     cont7    cont8    cont9  \\\n",
       "0  0.246911  0.402922  0.281143  0.466591  0.317681  0.61229  0.34365   \n",
       "1  0.654310  0.946616  0.836443  0.482425  0.443760  0.71330  0.51890   \n",
       "2  0.711159  0.412789  0.718531  0.212308  0.325779  0.29758  0.34365   \n",
       "3  0.592681  0.354893  0.397069  0.369930  0.342355  0.40028  0.33237   \n",
       "4  0.263570  0.696873  0.302678  0.398862  0.391833  0.23688  0.43731   \n",
       "\n",
       "    cont10    cont11    cont12    cont13    cont14  \n",
       "0  0.38016  0.377724  0.369858  0.704052  0.392562  \n",
       "1  0.60401  0.689039  0.675759  0.453468  0.208045  \n",
       "2  0.30529  0.245410  0.241676  0.258586  0.297232  \n",
       "3  0.31480  0.348867  0.341872  0.592264  0.555955  \n",
       "4  0.50556  0.359572  0.352251  0.301535  0.825823  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_base = train.columns\n",
    "cat = feat_base[1:117]\n",
    "cont = feat_base[117:-1]\n",
    "y = train.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub['c'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr = pd.DataFrame()\n",
    "tr['id'] = train['id']\n",
    "tr['loss'] = train['loss']\n",
    "tr['c'] = 1\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.concat([tr,sub])\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(tr.id,tr.loss,c='r', s=10, marker='o', alpha=.4)\n",
    "plt.scatter(sub.id,sub.loss,c='b', s=10, marker='o', alpha=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(d.id,d.loss,c=d.c, s=10, marker='o', alpha=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualization and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc = train.describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train.id,y,c=train.c, s=10, marker='o', alpha=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train.cont1,train.cont2,c=train.c, s=5, marker='o', alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train.id,np.log(y+1),color='r', s=10, marker='o', alpha=.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log(y[y]+200).hist(bins=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "razmah = desc['loss']['75%']+1.5*(desc['loss']['75%']-desc['loss']['25%'])+20000\n",
    "razmah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_loss(x):\n",
    "    if x<razmah:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "train['c'] = train['loss'].apply(get_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.clustermap(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"cont1\", y=\"cont3\", data=train, size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train[train.loss>razmah])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(cat)):\n",
    "    sns.boxplot(x=cat[i], y=\"loss\", data=train)\n",
    "    #ax = sns.boxplot(x=cat[i], y=\"loss\", data=train)\n",
    "    #ax = sns.stripplot(x=cat[i], y=\"loss\", data=train, jitter=False, edgecolor=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(cont)):\n",
    "    for j in range(i+1,len(cont)):\n",
    "        sns.FacetGrid(train, hue=\"c\", size=5).map(plt.scatter, cont[i], cont[j]).add_legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot('cont1', 'cont2',data=train, \n",
    "           fit_reg=False,\n",
    "           hue=\"c\",  \n",
    "           scatter_kws={\"marker\": \"*\", \n",
    "                        \"s\": 3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=cat[0], y=\"loss\", data=train, size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=cat[i], y=\"loss\", data=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.FacetGrid(train, hue=\"c\", size=6).map(sns.kdeplot, \"cont13\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train[cont], hue=train.c, size=3)\n",
    "#sns.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", size=3, diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = list(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.extend('c')\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[z].boxplot(by='c', figsize=(12, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One cool more sophisticated technique pandas has available is called Andrews Curves\n",
    "# Andrews Curves involve using attributes of samples as coefficients for Fourier series\n",
    "# and then plotting these\n",
    "from pandas.tools.plotting import andrews_curves\n",
    "andrews_curves(train[z], \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another multivariate visualization technique pandas has is parallel_coordinates\n",
    "# Parallel coordinates plots each feature on a separate column & then draws lines\n",
    "# connecting the features for each data sample\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "parallel_coordinates(train[z], \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A final multivariate visualization technique pandas has is radviz\n",
    "# Which puts each feature as a point on a 2D plane, and then simulates\n",
    "# having each sample attached to those points through a spring weighted\n",
    "# by the relative value for that feature\n",
    "from pandas.tools.plotting import radviz\n",
    "radviz(iris.drop(\"Id\", axis=1), \"Species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REGR:1951\n",
    "XGB:datat\n",
    "RegrLog:1307\n",
    "    \n",
    "factor:train-mae:1101.17\teval-mae:1180.22\n",
    "get_dum 1177"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clastering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=2, random_state= 6).fit_predict(train[cont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train['cont1'], train['loss'], c=y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(cont)):\n",
    "    plt.scatter(train[cont[i]], train['loss'], c=y_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following bandwidth can be automatically detected using\n",
    "#bandwidth = estimate_bandwidth(train[cont], quantile=0.2, n_samples=10)\n",
    "#ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms = MeanShift( bin_seeding=True)\n",
    "ms.fit(train[cont])\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "print(\"number of estimated clusters : %d\" % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    my_members = labels == k\n",
    "    cluster_center = cluster_centers[k]\n",
    "    plt.plot(X[my_members, 0], X[my_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NewData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['loss'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "      <th>cat19</th>\n",
       "      <th>cat20</th>\n",
       "      <th>cat21</th>\n",
       "      <th>cat22</th>\n",
       "      <th>cat23</th>\n",
       "      <th>cat24</th>\n",
       "      <th>cat25</th>\n",
       "      <th>cat26</th>\n",
       "      <th>cat27</th>\n",
       "      <th>cat28</th>\n",
       "      <th>cat29</th>\n",
       "      <th>cat30</th>\n",
       "      <th>cat31</th>\n",
       "      <th>cat32</th>\n",
       "      <th>cat33</th>\n",
       "      <th>cat34</th>\n",
       "      <th>cat35</th>\n",
       "      <th>cat36</th>\n",
       "      <th>cat37</th>\n",
       "      <th>cat38</th>\n",
       "      <th>cat39</th>\n",
       "      <th>cat40</th>\n",
       "      <th>cat41</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat43</th>\n",
       "      <th>cat44</th>\n",
       "      <th>cat45</th>\n",
       "      <th>cat46</th>\n",
       "      <th>cat47</th>\n",
       "      <th>cat48</th>\n",
       "      <th>cat49</th>\n",
       "      <th>cat50</th>\n",
       "      <th>cat51</th>\n",
       "      <th>cat52</th>\n",
       "      <th>cat53</th>\n",
       "      <th>cat54</th>\n",
       "      <th>cat55</th>\n",
       "      <th>cat56</th>\n",
       "      <th>cat57</th>\n",
       "      <th>cat58</th>\n",
       "      <th>cat59</th>\n",
       "      <th>cat60</th>\n",
       "      <th>cat61</th>\n",
       "      <th>cat62</th>\n",
       "      <th>cat63</th>\n",
       "      <th>cat64</th>\n",
       "      <th>cat65</th>\n",
       "      <th>cat66</th>\n",
       "      <th>cat67</th>\n",
       "      <th>cat68</th>\n",
       "      <th>cat69</th>\n",
       "      <th>cat70</th>\n",
       "      <th>cat71</th>\n",
       "      <th>cat72</th>\n",
       "      <th>cat73</th>\n",
       "      <th>cat74</th>\n",
       "      <th>cat75</th>\n",
       "      <th>cat76</th>\n",
       "      <th>cat77</th>\n",
       "      <th>cat78</th>\n",
       "      <th>cat79</th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat81</th>\n",
       "      <th>cat82</th>\n",
       "      <th>cat83</th>\n",
       "      <th>cat84</th>\n",
       "      <th>cat85</th>\n",
       "      <th>cat86</th>\n",
       "      <th>cat87</th>\n",
       "      <th>cat88</th>\n",
       "      <th>cat89</th>\n",
       "      <th>cat90</th>\n",
       "      <th>cat91</th>\n",
       "      <th>cat92</th>\n",
       "      <th>cat93</th>\n",
       "      <th>cat94</th>\n",
       "      <th>cat95</th>\n",
       "      <th>cat96</th>\n",
       "      <th>cat97</th>\n",
       "      <th>cat98</th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat102</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>B</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>BU</td>\n",
       "      <td>BC</td>\n",
       "      <td>C</td>\n",
       "      <td>AS</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>LB</td>\n",
       "      <td>0.726300</td>\n",
       "      <td>0.245921</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CQ</td>\n",
       "      <td>A</td>\n",
       "      <td>AV</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DP</td>\n",
       "      <td>0.330514</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>O</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>AB</td>\n",
       "      <td>DK</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>AF</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>GK</td>\n",
       "      <td>0.261841</td>\n",
       "      <td>0.358319</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>AE</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DJ</td>\n",
       "      <td>0.321594</td>\n",
       "      <td>0.555782</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>K</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>CK</td>\n",
       "      <td>0.273204</td>\n",
       "      <td>0.159990</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10 cat11 cat12 cat13  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B     A     B     A     A   \n",
       "1   2    A    B    A    A    A    A    A    A    B     B     A     A     A   \n",
       "2   5    A    B    A    A    B    A    A    A    B     B     B     B     B   \n",
       "3  10    B    B    A    B    A    A    A    A    B     A     A     A     A   \n",
       "4  11    A    B    A    B    A    A    A    A    B     B     A     B     A   \n",
       "\n",
       "  cat14 cat15 cat16 cat17 cat18 cat19 cat20 cat21 cat22 cat23 cat24 cat25  \\\n",
       "0     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "\n",
       "  cat26 cat27 cat28 cat29 cat30 cat31 cat32 cat33 cat34 cat35 cat36 cat37  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat38 cat39 cat40 cat41 cat42 cat43 cat44 cat45 cat46 cat47 cat48 cat49  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat50 cat51 cat52 cat53 cat54 cat55 cat56 cat57 cat58 cat59 cat60 cat61  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat62 cat63 cat64 cat65 cat66 cat67 cat68 cat69 cat70 cat71 cat72 cat73  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     B   \n",
       "4     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "\n",
       "  cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81 cat82 cat83 cat84 cat85  \\\n",
       "0     A     B     A     D     B     B     D     D     B     D     C     B   \n",
       "1     A     A     A     D     B     B     D     D     A     B     C     B   \n",
       "2     A     A     A     D     B     B     B     D     B     D     C     B   \n",
       "3     A     A     A     D     B     B     D     D     D     B     C     B   \n",
       "4     A     A     A     D     B     D     B     D     B     B     C     B   \n",
       "\n",
       "  cat86 cat87 cat88 cat89 cat90 cat91 cat92 cat93 cat94 cat95 cat96 cat97  \\\n",
       "0     D     B     A     A     A     A     A     D     B     C     E     A   \n",
       "1     D     B     A     A     A     A     A     D     D     C     E     E   \n",
       "2     B     B     A     A     A     A     A     D     D     C     E     E   \n",
       "3     D     B     A     A     A     A     A     D     D     C     E     E   \n",
       "4     B     C     A     A     A     B     H     D     B     D     E     E   \n",
       "\n",
       "  cat98 cat99 cat100 cat101 cat102 cat103 cat104 cat105 cat106 cat107 cat108  \\\n",
       "0     C     T      B      G      A      A      I      E      G      J      G   \n",
       "1     D     T      L      F      A      A      E      E      I      K      K   \n",
       "2     A     D      L      O      A      B      E      F      H      F      A   \n",
       "3     D     T      I      D      A      A      E      E      I      K      K   \n",
       "4     A     P      F      J      A      A      D      E      K      G      B   \n",
       "\n",
       "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116     cont1     cont2  \\\n",
       "0     BU     BC      C     AS      S      A      O     LB  0.726300  0.245921   \n",
       "1     BI     CQ      A     AV     BM      A      O     DP  0.330514  0.737068   \n",
       "2     AB     DK      A      C     AF      A      I     GK  0.261841  0.358319   \n",
       "3     BI     CS      C      N     AE      A      O     DJ  0.321594  0.555782   \n",
       "4      H      C      C      Y     BM      A      K     CK  0.273204  0.159990   \n",
       "\n",
       "      cont3     cont4     cont5     cont6     cont7    cont8    cont9  \\\n",
       "0  0.187583  0.789639  0.310061  0.718367  0.335060  0.30260  0.67135   \n",
       "1  0.592681  0.614134  0.885834  0.438917  0.436585  0.60087  0.35127   \n",
       "2  0.484196  0.236924  0.397069  0.289648  0.315545  0.27320  0.26076   \n",
       "3  0.527991  0.373816  0.422268  0.440945  0.391128  0.31796  0.32128   \n",
       "4  0.527991  0.473202  0.704268  0.178193  0.247408  0.24564  0.22089   \n",
       "\n",
       "    cont10    cont11    cont12    cont13    cont14     loss  \n",
       "0  0.83510  0.569745  0.594646  0.822493  0.714843  2213.18  \n",
       "1  0.43919  0.338312  0.366307  0.611431  0.304496  1283.60  \n",
       "2  0.32446  0.381398  0.373424  0.195709  0.774425  3005.09  \n",
       "3  0.44467  0.327915  0.321570  0.605077  0.602642   939.85  \n",
       "4  0.21230  0.204687  0.202213  0.246011  0.432606  2763.85  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train,test],ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAGGLE MAGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COMB_FEATURE = 'cat80,cat87,cat57,cat12,cat79,cat10,cat7,cat89,cat2,cat72,' \\\n",
    "               'cat81,cat11,cat1,cat13,cat9,cat3,cat16,cat90,cat23,cat36,' \\\n",
    "               'cat73,cat103,cat40,cat28,cat111,cat6,cat76,cat50,cat5,' \\\n",
    "               'cat4,cat14,cat38,cat24,cat82,cat25'.split(',')\n",
    "\n",
    "def encode(charcode):\n",
    "    r = 0\n",
    "    ln = len(str(charcode))\n",
    "    for i in range(ln):\n",
    "        r += (ord(str(charcode)[i]) - ord('A') + 1) * 26 ** (ln - i - 1)\n",
    "    return r\n",
    "\n",
    "fair_constant = 2\n",
    "def fair_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    x = (preds - labels)\n",
    "    den = abs(x) + fair_constant\n",
    "    grad = fair_constant * x / (den)\n",
    "    hess = fair_constant * fair_constant / (den * den)\n",
    "    return grad, hess\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y)-shift,\n",
    "                                      np.exp(yhat)-shift)\n",
    "def mungeskewed(train, test, numeric_feats):\n",
    "    ntrain = train.shape[0]\n",
    "    test['loss'] = 0\n",
    "    train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.25]\n",
    "    skewed_feats = skewed_feats.index\n",
    "\n",
    "    for feats in skewed_feats:\n",
    "        train_test[feats] = train_test[feats] + 1\n",
    "        train_test[feats], lam = boxcox(train_test[feats])\n",
    "    return train_test, ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxcox(train['cont14']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_feats = [x for x in train.columns[1:-1] if 'cont' in x]\n",
    "categorical_feats = [x for x in train.columns[1:-1] if 'cat' in x]\n",
    "train_test, ntrain = mungeskewed(train, test, numeric_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for comb in itertools.combinations(COMB_FEATURE, 2):\n",
    "        feat = comb[0] + \"_\" + comb[1]\n",
    "        train_test[feat] = train_test[comb[0]] + train_test[comb[1]]\n",
    "        train_test[feat] = train_test[feat].apply(encode)\n",
    "        print('Analyzing Columns:', feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_feats = [x for x in train_test.columns[1:] if 'cat' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in categorical_feats:\n",
    "        print('Analyzing Column:', col)\n",
    "        train_test[col] = train_test[col].apply(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "train_test[numeric_feats] = \\\n",
    "        ss.fit_transform(train_test[numeric_feats].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train_test.iloc[:ntrain, :].copy()\n",
    "test = train_test.iloc[ntrain:, :].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET DOMMIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = remove_train.union(remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        data[column] = data[column].apply(lambda x: filter_cat(x), 1)\n",
    "            \n",
    "    data[column] = pd.factorize(data[column].values, sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat = data.columns[1:-15]\n",
    "cat[-1],cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.get_dummies(data,columns = cat).rename(columns=lambda x: str(x))\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.int8(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in data.columns[16:]:\n",
    "    data[i] = data[i].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"datap/data_get_dum_col_nan_bool.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[data.Test == 0].drop('Test', axis=1).copy()\n",
    "test = data[data.Test == 1].drop('Test', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    if mean(train[i])==0:\n",
    "        train.drop([i],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in test.columns:\n",
    "    if mean(test[i])==0:\n",
    "        test.drop([i],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.columns[15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.columns[16:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# del cat 0 cat-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['cat{}_0'.format(i)],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,117):\n",
    "    try:\n",
    "        data.drop(['cat{}_0'.format(i)],axis=1,inplace=True)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat113_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    data[column] = data.groupby(column).transform('count')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    data[column] = data.groupby(column)['cont14'].transform(\"mean\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACTORIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = remove_train.union(remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        data[column] = data[column].apply(lambda x: filter_cat(x), 1)\n",
    "            \n",
    "    data[column] = pd.factorize(data[column].values, sort=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in list(data.columns[1:-15]):\n",
    "    data[i]= pd.factorize(data[i])[0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat=list(set(train.columns)-{\"id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group mean(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transf_cat(train,test,feat_cat,feat_cont,fold):\n",
    "    test['Proba'] = 0\n",
    "    train['Proba'] = 0\n",
    "    n_folds = fold\n",
    "    kf = KFold(train.shape[0],n_folds)#,shuffle=True\n",
    "    for train_index, val_index in kf:\n",
    "        print(\"new_fold\")\n",
    "        training_data, validation_data = train.loc[train_index], train.loc[val_index]\n",
    "        training_data['new_feat'] = training_data.groupby(feat_cat)[feat_cont].transform(\"mean\")\n",
    "        dat = training_data.groupby(feat_cat,as_index=False).mean()\n",
    "        d={}\n",
    "        for i in range(len(dat)):\n",
    "            d[dat[feat_cat][i]] = dat['new_feat'][i]\n",
    "        m=np.mean(training_data[feat_cont])\n",
    "        def gr(x):\n",
    "            try:\n",
    "                return d[x]\n",
    "            except:\n",
    "                return m  \n",
    "        train['Proba'].loc[val_index] = train[feat_cat].loc[val_index].apply(gr)\n",
    "        test_new = test[feat_cat].apply(gr)\n",
    "        test['Proba'] += np.array(test_new)\n",
    "    return train['Proba'],test['Proba']*(1/n_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[data['loss'].notnull()].reset_index()\n",
    "test = data[data['loss'].isnull()].reset_index()\n",
    "train.drop(['id','index'],axis=1,inplace=True)\n",
    "test.drop(['id','index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat = list(train.columns[:-15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in cat:\n",
    "    print(i)\n",
    "    %time train[i+\"n\"] , test[i+\"n\"] = transf_cat(train,test,i,\"loss\",5)\n",
    "    print(\"next_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(cat,axis=1,inplace=True)\n",
    "train.drop(['Proba'],axis=1,inplace=True)\n",
    "test.drop(cat,axis=1,inplace=True)\n",
    "test.drop(['Proba'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('datap/train5foldmean.csv',index=False)\n",
    "test.to_csv('datap/test5foldmean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group_kfold(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transf_cat(train,test,feat_cat,feat_cont,fold):\n",
    "    test['Proba'] = 0\n",
    "    train['Proba'] = 0\n",
    "    n_folds = fold\n",
    "    kf = KFold(train.shape[0],n_folds)#,shuffle=True\n",
    "    for train_index, val_index in kf:\n",
    "        print(\"new_fold\")\n",
    "        training_data, validation_data = train.loc[train_index], train.loc[val_index]\n",
    "        training_data['new_feat'] = training_data.groupby(feat_cat)[feat_cont].transform(\"median\")\n",
    "        dat = training_data.groupby(feat_cat,as_index=False).median()\n",
    "        d={}\n",
    "        for i in range(len(dat)):\n",
    "            d[dat[feat_cat][i]] = dat['new_feat'][i]\n",
    "        m=np.median(training_data[feat_cont])\n",
    "        def gr(x):\n",
    "            try:\n",
    "                return d[x]\n",
    "            except:\n",
    "                return m  \n",
    "        train['Proba'].loc[val_index] = train[feat_cat].loc[val_index].apply(gr)\n",
    "        test_new = test[feat_cat].apply(gr)\n",
    "        test['Proba'] += np.array(test_new)\n",
    "    return train['Proba'],test['Proba']*(1/n_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[data['loss'].notnull()].reset_index()\n",
    "test = data[data['loss'].isnull()].reset_index()\n",
    "train.drop(['id','index'],axis=1,inplace=True)\n",
    "test.drop(['id','index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat = list(train.columns[:-15])\n",
    "cat[-1],cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in cat:\n",
    "    print(i)\n",
    "    %time train[i+\"n\"] , test[i+\"n\"] = transf_cat(train,test,i,\"loss\",5)\n",
    "    print(\"next_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(cat,axis=1,inplace=True)\n",
    "train.drop(['Proba'],axis=1,inplace=True)\n",
    "test.drop(cat,axis=1,inplace=True)\n",
    "test.drop(['Proba'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_csv('datap/trainkagglebox.csv',index=False)\n",
    "test.to_csv('datap/testkagglebox.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('datap/train5fold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "с = х"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NewFeatches From Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"cont1\"] = np.sqrt(preprocessing.minmax_scale(data[\"cont1\"]))\n",
    "data[\"cont4\"] = np.sqrt(preprocessing.minmax_scale(data[\"cont4\"]))\n",
    "data[\"cont5\"] = np.sqrt(preprocessing.minmax_scale(data[\"cont5\"]))\n",
    "data[\"cont8\"] = np.sqrt(preprocessing.minmax_scale(data[\"cont8\"]))\n",
    "data[\"cont10\"] = np.sqrt(preprocessing.minmax_scale(data[\"cont10\"]))\n",
    "data[\"cont11\"] = np.sqrt(preprocessing.minmax_scale(data[\"cont11\"]))\n",
    "data[\"cont12\"] = np.sqrt(preprocessing.minmax_scale(data[\"cont12\"]))\n",
    "\n",
    "data[\"cont6\"] = np.log(preprocessing.minmax_scale(data[\"cont6\"])+0000.1)\n",
    "data[\"cont7\"] = np.log(preprocessing.minmax_scale(data[\"cont7\"])+0000.1)\n",
    "data[\"cont9\"] = np.log(preprocessing.minmax_scale(data[\"cont9\"])+0000.1)\n",
    "data[\"cont13\"] = np.log(preprocessing.minmax_scale(data[\"cont13\"])+0000.1)\n",
    "data[\"cont14\"]=(np.maximum(data[\"cont14\"]-0.179722,0)/0.665122)**0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datap/train3foldmean.csv\")\n",
    "test = pd.read_csv(\"datap/test3foldmean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"cont15\"]=(np.maximum(train[\"cont14\"]-0.179722,0))\n",
    "test[\"cont15\"]=(np.maximum(test[\"cont14\"]-0.179722,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop([\"id\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['id'] = list(d['id'])\n",
    "data['id'] = data['id']*(1/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[data['loss'].notnull()]\n",
    "test = data[data['loss'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xval, ytr, yval = train_test_split(train,np.array(train.loss),random_state = 7, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr.drop(['loss'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 200\n",
    "feat = list(set(test.columns)-{\"loss\",'id'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18052974224450133"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train['loss']<1000].loss)/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-455d6179c1a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#log_loss(yval, rf.predict_proba(Xval))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 290\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=200, n_jobs=-1)\n",
    "rf.fit(Xtr[feat], np.log(ytr+shift))\n",
    "#log_loss(yval, rf.predict_proba(Xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = rf.predict(Xval[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37664, 37664)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred),len(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1245.0135099604395"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(pred,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-f607fcd0495b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \"\"\"\n\u001b[1;32m    162\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 163\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    164\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n\u001b[1;32m    165\u001b[0m                                weights=sample_weight, axis=0)\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "mean_absolute_error(np.exp(np.array(pred))-shift,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pylightgbm.models import GBMRegressor\n",
    "#os.environ['LIGHTGBM_EXEC'] = \"/root/tools/LightGBM/lightgbm\"\n",
    "os.environ['LIGHTGBM_EXEC'] = \"/home/dz/anaconda3/LightGBM/lightgbm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GBMRegressor(\n",
    "    #exec_path='/path/to/your/LightGBM/lightgbm',\n",
    "    exec_path='/home/dz/anaconda3/LightGBM/lightgbm',\n",
    "    num_threads=-1,\n",
    "    learning_rate = 0.01,\n",
    "    num_iterations = 5000, \n",
    "    verbose = False, \n",
    "    early_stopping_round = 5,\n",
    "    feature_fraction = 0.75,\n",
    "    bagging_fraction = 0.9,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f0622a45ae43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clf.fit(Xtr, np.log(ytr + shift))\\ny_pred_2 = np.exp(clf.predict(Xval)) - shift\\nprint(mean_absolute_error(y_pred_2, yval))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/site-packages/pylightgbm/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, test_data, init_scores)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             process = subprocess.Popen([self.exec_path, \"config={}\".format(conf_filepath)],\n\u001b[0;32m--> 131\u001b[0;31m                                        stdout=subprocess.PIPE, bufsize=1)\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[1;32m    945\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    948\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1549\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                                 \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_executable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(Xtr, np.log(ytr + shift))\n",
    "y_pred_2 = np.exp(clf.predict(Xval)) - shift\n",
    "print(mean_absolute_error(y_pred_2, yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 85.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'verbose': False, 'num_iterations': 100}\n",
    "clf = GBMRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pylightgbm.models import GBMRegressor\n",
    "params = {'verbose': False, 'num_iterations': 100}\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(train, np.log(y_train + SHIFT))\n",
    "y_pred_2 = np.exp(clf.predict(test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred_2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = list(set(test.columns)-{\"id\",\"loss\"} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat = list(set(test.columns)-{\"id\",\"loss\"} - set(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr[feat].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear_model on cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr[feat].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "regr.fit(np.log(Xtr[feat]+shift),np.log(ytr+shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = regr.predict(np.log(Xval[feat]+shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAE = sum(abs(yval-(np.exp(pred)-shift))) / len(yval)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(np.exp(pred)-shift,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gal(1114 fact 1274)\n",
    "1258 med 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr = xgb.DMatrix(Xtr[feat], label=np.log(ytr+shift))\n",
    "dval = xgb.DMatrix(Xval[feat], label=np.log(yval+shift))\n",
    "watchlist = [(dtr, 'train'), (dval, 'eval')]\n",
    "history = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Xtr,Xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.1,\n",
    "    'nthread': 4,\n",
    "    'subsample': 0.8,\n",
    "    'eval_metric': ['mae'],\n",
    "    'objective': 'reg:linear',\n",
    "    'colsample_bytree': 0.6,\n",
    "    'min_child_weight': 0,\n",
    "    #'scale_pos_weight':(1-train.Label.mean())/train.Label.mean(),\n",
    "    'seed':7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot([1000, 1001, 1002])  # scales with m = 1, c = -1000\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "            'min_child_weight': 1,\n",
    "            'eta': 0.1,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'max_depth': 12,\n",
    "            'subsample': 0.8,\n",
    "            'alpha': 1,\n",
    "            'gamma': 1,\n",
    "            'silent': 1,\n",
    "            'verbose_eval': True,\n",
    "            'seed':7\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'seed': 1,\n",
    "    'colsample_bytree': 0.3085,\n",
    "    'subsample': 0.9930,\n",
    "    'eta': 0.1,\n",
    "    'gamma': 0.5290,\n",
    "    'booster' :  'gbtree',    \n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 4.2922,\n",
    "    'eval_metric': 'mae'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2016\n",
    "params = {\n",
    "        'min_child_weight': 1,\n",
    "        'eta': 0.01,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.8,\n",
    "        'alpha': 1,\n",
    "        'gamma': 1,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': True,\n",
    "        'seed': RANDOM_STATE\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "        'seed': 7,\n",
    "        'gamma': 0.9,\n",
    "        'alpha': 1,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'silent': 0,\n",
    "        'subsample': 0.7,\n",
    "        'learning_rate': 0.01,\n",
    "        'objective': 'reg:linear',\n",
    "        'verbose_eval': True,\n",
    "        'max_depth': 12,\n",
    "        'min_child_weight': 1,\n",
    "        'booster': 'gbtree',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = { 'min_child_weight': 1.3921626196385004, 'eta': 0.00569207582224922, 'colsample_bytree': 0.6693550027860175, 'max_depth': 12, 'subsample': 0.6980320503253816, 'alpha': 0.9925559487305438, 'gamma': 0.904325256736723, 'silent': 0, 'verbose_eval': True, 'seed': RANDOM_STATE }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.cv(params, dtr, 2000, nfold=5,\n",
    "       metrics={'mae'}, seed = 7,verbose_eval=50,\n",
    "       callbacks=[xgb.callback.print_evaluation(show_stdv=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtr, num_boost_round=2000, evals=watchlist,evals_result=history, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_xgb = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(np.exp(pred_xgb)-shift,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_xgb = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1133\n",
    "1134 med 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtr,num_boost_round= int(2012 / 0.9), evals=watchlist,evals_result=history,  feval=evalerror,verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count model 1131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train[feat], label=np.log(train.loss+shift))\n",
    "xgtest = xgb.DMatrix(test[feat])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(params, xgtrain, int(2012 / 0.9), feval=evalerror)\n",
    "\n",
    "predicti = np.exp(model.predict(xgtest)) - shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_all = list(set(train.columns) -{'id','loss'})\n",
    "feat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift=200\n",
    "def get_prob_xgb(train,test,feat,fold,y,method,i):\n",
    "    h = []\n",
    "    er = []\n",
    "    proba = 0\n",
    "    params = {\n",
    "            'min_child_weight': 10,\n",
    "            'eta': 0.025,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 0.9,\n",
    "            'alpha': 1,\n",
    "            'gamma': 1,\n",
    "            'silent': 1,\n",
    "            'verbose_eval': True,\n",
    "            'seed': 7\n",
    "        }\n",
    "    train['pred'+method+str(i)]=0\n",
    "    test['pred'+method+str(i)] =0 \n",
    "    kf = KFold(train.shape[0], n_folds=fold,shuffle=True)\n",
    "    for train_index, val_index in kf:\n",
    "        training_data, validation_data = train.loc[train_index], train.loc[val_index]\n",
    "        dtr = xgb.DMatrix(training_data[feat], label=np.log(training_data[y]+shift))\n",
    "        dval = xgb.DMatrix(validation_data[feat], label=np.log(validation_data[y]+shift))\n",
    "        watchlist = [(dtr, 'train'), (dval, 'eval')]\n",
    "        history = dict()\n",
    "        model0 = xgb.train(params, dtr,num_boost_round= 800, evals=watchlist,evals_result=history,  feval=evalerror,verbose_eval=50)\n",
    "        pred =  model0.predict(dval)\n",
    "        pred = np.exp(pred)-shift\n",
    "        er.append(mean_absolute_error(pred,validation_data[y]))\n",
    "        print(\"mae\",mean_absolute_error(pred,validation_data[y]))\n",
    "        train['pred'+method+str(i)].loc[val_index] = pred\n",
    "        dtest = xgb.DMatrix(test[feat])\n",
    "        proba = proba+(np.exp(model0.predict(dtest))-shift)\n",
    "        imps = pd.Series(model0.get_fscore()).sort_values()\n",
    "        h.append(imps)\n",
    "        print('NEXT FOLD')\n",
    "    test['pred'+method+str(i)] = proba*(1/fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(2):\n",
    "    feat = []\n",
    "    rand = list(set(np.random.randint(0,len(feat_all),size=(len(feat_all)))))\n",
    "    print(len(rand)/len(feat_all))\n",
    "    for j in range(len(rand)):\n",
    "        feat.append(feat_all[rand[j]])\n",
    "    get_prob_xgb(train,test,feat,3,'loss','regr',i)\n",
    "feat_prob = list(set(train.columns)-set(feat_all))\n",
    "tr = train[feat_prob]\n",
    "te = test[feat_prob]\n",
    "te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shift = 200\n",
    "def get_prob_lin(train,test,feat,fold,y,method,i):\n",
    "    model0 = linear_model.LinearRegression()\n",
    "    train['pred'+method+str(i)]=0\n",
    "    test['pred'+method+str(i)] =0 \n",
    "    er = []\n",
    "    proba = 0\n",
    "    kf = KFold(train.shape[0], n_folds=fold,shuffle=True)\n",
    "    for train_index, val_index in kf:\n",
    "        training_data, validation_data = train.loc[train_index], train.loc[val_index]\n",
    "        model0.fit(np.log(training_data[feat]+shift),np.log(training_data[y]+shift))\n",
    "        pred = model0.predict(np.log(validation_data[feat]+shift))\n",
    "        pred = np.exp(pred)-shift\n",
    "        er.append(mean_absolute_error(pred,validation_data[y]))\n",
    "        print(\"mae\",mean_absolute_error(pred,validation_data[y]))\n",
    "        train['pred'+method+str(i)].loc[val_index] = pred\n",
    "        proba = proba+(np.exp(model0.predict(np.log(test[feat]+shift)))-shift)\n",
    "    print(\"mean\",np.mean(er))\n",
    "    test['pred'+method+str(i)]=(proba)*(1/fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_all = list(set(train.columns) -{'id','loss'})\n",
    "feat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    feat = []\n",
    "    rand = list(set(np.random.randint(0,len(feat_all),size=(len(feat_all)))))\n",
    "    print(len(rand)/len(feat_all))\n",
    "    for j in range(len(rand)):\n",
    "        feat.append(feat_all[rand[j]])\n",
    "    get_prob_lin(train,test,feat,3,'loss','regr',i)\n",
    "feat_prob = list(set(train.columns)-set(feat_all))\n",
    "tr = train[feat_prob]\n",
    "te = test[feat_prob]\n",
    "te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.uniform(0, 20)\n",
    "random.randint(1,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift=200\n",
    "def get_prob_xgb(train,test,feat,fold,y,method,i):\n",
    "    h = []\n",
    "    seed = random.randint(1,1337)\n",
    "    mcw = random.randint(0,10)\n",
    "    eta = random.uniform(0.01, 0.05)\n",
    "    cb = random.uniform(0.5, 1)\n",
    "    md = random.randint(4,15)\n",
    "    s = random.uniform(0.8, 1)\n",
    "    er = []\n",
    "    proba = 0\n",
    "    params = {\n",
    "            'min_child_weight': mcw,\n",
    "            'eta': eta,\n",
    "            'colsample_bytree': cb,\n",
    "            'max_depth': md,\n",
    "            'subsample': s,\n",
    "            'alpha': 1,\n",
    "            'gamma': 1,\n",
    "            'silent': 1,\n",
    "            'verbose_eval': True,\n",
    "            'seed': seed\n",
    "        }\n",
    "    train['pred'+method+str(i)+str(mcw)+str(eta)+str(cb)+str(md)+str(s)]=0\n",
    "    test['pred'+method+str(i)+str(mcw)+str(eta)+str(cb)+str(md)+str(s)] =0 \n",
    "    kf = KFold(train.shape[0], n_folds=fold,shuffle=True)\n",
    "    for train_index, val_index in kf:\n",
    "        training_data, validation_data = train.loc[train_index], train.loc[val_index]\n",
    "        dtr = xgb.DMatrix(training_data[feat], label=np.log(training_data[y]+shift))\n",
    "        dval = xgb.DMatrix(validation_data[feat], label=np.log(validation_data[y]+shift))\n",
    "        watchlist = [(dtr, 'train'), (dval, 'eval')]\n",
    "        history = dict()\n",
    "        model0 = xgb.train(params, dtr,num_boost_round= 1000, evals=watchlist,evals_result=history,  feval=evalerror,verbose_eval=50)\n",
    "        pred =  model0.predict(dval)\n",
    "        pred = np.exp(pred)-shift\n",
    "        er.append(mean_absolute_error(pred,validation_data[y]))\n",
    "        print(\"mae\",mean_absolute_error(pred,validation_data[y]))\n",
    "        train['pred'+method+str(i)+str(mcw)+str(eta)+str(cb)+str(md)+str(s)].loc[val_index] = pred\n",
    "        dtest = xgb.DMatrix(test[feat])\n",
    "        proba = proba+(np.exp(model0.predict(dtest))-shift)\n",
    "        imps = pd.Series(model0.get_fscore()).sort_values()\n",
    "        h.append(imps)\n",
    "        print('NEXT FOLD')\n",
    "    test['pred'+method+str(i)+str(mcw)+str(eta)+str(cb)+str(md)+str(s)] = proba*(1/fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(2):\n",
    "    feat = []\n",
    "    rand = list(set(np.random.randint(0,len(feat_all),size=(len(feat_all)))))\n",
    "    print(len(rand)/len(feat_all))\n",
    "    for j in range(len(rand)):\n",
    "        feat.append(feat_all[rand[j]])\n",
    "    get_prob_xgb(train,test,feat_all,3,'loss','regr',i)\n",
    "feat_prob = list(set(train.columns)-set(feat_all))\n",
    "tr = train[feat_prob]\n",
    "te = test[feat_prob]\n",
    "te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = (tr.loss-tr[\"predregr040.0187086573326524370.9361401852393766100.9245917889729721\"])>0\n",
    "k=0\n",
    "for i in range(len(z)):\n",
    "    if z[i]==True:\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(tr[\"predregr040.0187086573326524370.9361401852393766100.9245917889729721\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(tr.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_absolute_error((tr[\"predregr040.0187086573326524370.9361401852393766100.9245917889729721\"]-75),tr.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xval, ytr, yval = train_test_split(tr,tr.loss,random_state = 7, test_size=0.2)\n",
    "shift = 200\n",
    "feat = list(set(te.columns)-{\"id\",\"loss\"} )\n",
    "dtr = xgb.DMatrix(Xtr[feat], label=np.log(ytr+shift))\n",
    "dval = xgb.DMatrix(Xval[feat], label=np.log(yval+shift))\n",
    "watchlist = [(dtr, 'train'), (dval, 'eval')]\n",
    "history = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['dif'] = train['predregr1'] - train['predregr0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_absolute_error((train['predregr060.0167500983541034420.887604619346874140.8687493386495285'])*(2/2),tr.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtr,num_boost_round= int(2012 / 0.9), evals=watchlist,evals_result=history,  feval=evalerror,verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicti = np.exp(model.predict(dtest)) - shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result:\n",
    "non_feat_linear_non_param = 1219\n",
    "all_feat = 1134"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle new metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    con = 2\n",
    "    x =preds-labels\n",
    "    grad =con*x / (np.abs(x)+con)\n",
    "    hess =con**2 / (np.abs(x)+con)**2\n",
    "    return grad, hess \n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtr,num_boost_round= int(2012 / 0.9) , evals=watchlist,evals_result=history, obj=logregobj, feval=evalerror, early_stopping_rounds=50,verbose_eval=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam fo cont(sglazhivanie)\n",
    "to_remove = function (x, prop = 0.99) { # prop is the proportion with default 99% \n",
    "factor_vars = sapply(x, class) == 'factor' \n",
    "remove_vars = numeric() \n",
    "for (i in 1:ncol(x)){ \n",
    "if (factor_vars[i] && any(table(x[, i])/nrow(x) >= prop)) remove_vars = c(remove_vars, i) \n",
    "} \n",
    "print(remove_vars) \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(params, xgtrain,num_boost_round= int(2012 / 0.9) , evals=watchlist,evals_result=history, obj=logregobj, feval=evalerror, early_stopping_rounds=50,verbose_eval=50) \n",
    "\n",
    "predicti = np.exp(model.predict(xgtest)) - shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMP FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imps = pd.Series(model.get_fscore()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "imps.plot(kind='bar', figsize=(15,6),logy=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imps.to_csv('dataf/id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub['loss']=predicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('pred/xgb_mean5fold(cont14+id)(new12,2200,count).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl=sub.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = pd.read_csv(\"pred/xgb_kagglfeatboxcox(12,2200,count).csv\")\n",
    "x2 = pd.read_csv(\"pred/xgb_kaggl1(12,2200,3foldmean).csv\")\n",
    "x3 = pd.read_csv(\"pred/xgb_kaggl1(12,2200,getnan).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.pearsonr(x3.loss,x1.loss),stats.spearmanr(x3.loss,x1.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x['loss'] = (x1['loss'] + x2['loss'] +x3[\"loss\"])*(1/3)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('pred/mean(kagglfeatboxcox(12,2200,count),xgb_kaggl1(12,2200,3foldmean)xgb_kaggl1(12,2200,getnan)).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

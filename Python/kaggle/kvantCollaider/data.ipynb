{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# подключим библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from rep.utils import train_test_split_group\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pandas.tools.plotting import radviz,scatter_matrix,bootstrap_plot,parallel_coordinates\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib\n",
    "#‘nbagg’, ‘notebook’, inline,‘osx’, ‘qt’, ‘qt4’, ‘qt5’, ‘tk’, ‘wx’). If given, the corresponding matplotlib backend is used, otherwise it will be matplotlib’s default (which you can set in your matplotlib config file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# пропишем функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation(X,y,size):\n",
    "    l=round(size*len(X))\n",
    "    Xtr=X[0:(l-1)]\n",
    "    Xval=X[(l):len(X)]\n",
    "    ytr=y[0:(l-1)]\n",
    "    yval=y[(l):len(X)]\n",
    "    \n",
    "    return Xtr,ytr,Xval,yval\n",
    "\n",
    "def create_cv(id_event, n_folds):\n",
    "    id_unique = id_event.unique()\n",
    "    size_fold = int(len(id_unique)/n_folds)\n",
    "    idx_cv = []\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        mask = id_event.isin(id_unique[i*size_fold : (i+1)*size_fold])\n",
    "        idx_train = id_event.index[~mask].values\n",
    "        idx_test = id_event.index[mask].values\n",
    "        idx_cv.append([idx_train, idx_test])\n",
    "\n",
    "    return idx_cv   \n",
    "\n",
    "def compute_mean(event_ids, values):\n",
    "    \"\"\" fore each event computes average of given values \"\"\"\n",
    "    number_of_sv_in_event = np.bincount(event_ids)\n",
    "    return np.bincount(event_ids, weights=values) / number_of_sv_in_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/training.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "subm = pd.read_csv(\"data/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['size'] = train.groupby(['EventID'])['Mass'].transform('count') \n",
    "test['size'] = test.groupby(['EventID'])['Mass'].transform('count') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lab1 = train[train['Label']==1]\n",
    "lab0 = train[train[\"Label\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(lab0['size'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev=lab1.EventID\n",
    "trains =lab1.groupby('EventID',as_index=False)\n",
    "\n",
    "di=list(set('qwertyuiopasdfghjklzxcvb'))\n",
    "trainn=trains.nth(0)\n",
    "trainn['keys'] = np.arange(len(trainn))\n",
    "trainn.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traink=trains.nth(2)\n",
    "traink.columns[1:16]+'i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traink.columns = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z=['EventID']\n",
    "z.extend(traink.columns[1:17]+'i')\n",
    "traink.columns = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "traink.columns = z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traink.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(lab1[lab1['Flight_distance']>1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res=trainn.append(traink)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = pd.merge(traink,trainn,on='EventID')\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = pd.concat([traink,trainn],axis=1,join_axes=traink['key'])\n",
    "#z['EventID'] =ev\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(['EventID','Weight','size'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = train.Label\n",
    "train.drop(['Label'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr, Xval, ytr, yval = train_test_split(train, y, test_size=0.20, random_state=42)\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "\n",
    "X = Xtr\n",
    "\n",
    "\n",
    "estimators = {'k_means_iris_3': KMeans(n_clusters=3),\n",
    "              'k_means_iris_8': KMeans(n_clusters=8),\n",
    "              'k_means_iris_bad_init': KMeans(n_clusters=3, n_init=1,\n",
    "                                              init='random')}\n",
    "\n",
    "\n",
    "fignum = 1\n",
    "for name, est in estimators.items():\n",
    "    fig = plt.figure(fignum, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "    plt.cla()\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "\n",
    "    ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(np.float))\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Petal width')\n",
    "    ax.set_ylabel('Sepal length')\n",
    "    ax.set_zlabel('Petal length')\n",
    "    fignum = fignum + 1\n",
    "\n",
    "# Plot the ground truth\n",
    "fig = plt.figure(fignum, figsize=(4, 3))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "plt.cla()\n",
    "\n",
    "for name, label in [('Setosa', 0),\n",
    "                    ('Versicolour', 1),\n",
    "                    ('Virginica', 2)]:\n",
    "    ax.text3D(X[y == label, 3].mean(),\n",
    "              X[y == label, 0].mean() + 1.5,\n",
    "              X[y == label, 2].mean(), name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "# Reorder the labels to have colors matching the cluster results\n",
    "y = np.choose(y, [1, 2, 0]).astype(np.float)\n",
    "ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=y)\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('Petal width')\n",
    "ax.set_ylabel('Sepal length')\n",
    "ax.set_zlabel('Petal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "y_pred = KMeans(n_clusters=3, random_state=7).fit_predict(Xtr)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.scatter(Xtr[:, 5], Xtr[:, 6], c=y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "losses=[]\n",
    "ks = np.arange(1,15,1)\n",
    "for k in ks:\n",
    "    knn = KNeighborsClassifier(weights='distance', n_neighbors=k)\n",
    "    knn.fit(Xtr, ytr)\n",
    "    losses.append(roc_auc_score(yval, knn.predict_proba(Xval)))\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainn.columns=[trainn.columns[] + di[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vl.columns[1:14]=[vl.columns[1:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"size\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baes(data,test,k,size_train,tree):\n",
    "    di=list(set('qwertyuiopasdfghjklzxcvbnm1234567890'))\n",
    "    prob = 0\n",
    "    s = 0\n",
    "    auc = 0\n",
    "    prob_test = 0\n",
    "    training_data, validation_dataa = train_test_split_group(data.EventID, data, random_state=7, train_size=size_train)\n",
    "    lab1 = training_data[training_data['Label']==1]\n",
    "    lab0 = training_data[training_data[\"Label\"]==0]\n",
    "    validation_dataa['tracks_dif']=validation_dataa.Tracks_number-validation_dataa.Tracks_number_passed\n",
    "    #validation_data=validation_data.groupby('EventID', as_index=False).mean()\n",
    "    daq=pd.DataFrame()\n",
    "    for i in range(1,200):\n",
    "        print(\"Model for\",i)\n",
    "        if(i<k):\n",
    "            validation_dataq = validation_dataa[validation_dataa['size']==i]\n",
    "            validation_dataq.drop(['size'],axis=1,inplace=True)\n",
    "            data_1 = lab1[lab1[\"size\"] ==i]\n",
    "            trainnn=pd.concat([data_1,lab0])\n",
    "            trainnn.drop(['size'],axis=1,inplace=True)\n",
    "            trainnn['tracks_dif']=trainnn.Tracks_number-trainnn.Tracks_number_passed\n",
    "            trainn=trainnn.groupby('EventID', as_index=False).mean()\n",
    "            \n",
    "            validation_data=validation_dataq.groupby('EventID', as_index=False).mean()\n",
    "            print(trainn.shape,validation_data.shape)\n",
    "            #test['tracks_dif']=test.Tracks_number-test.Tracks_number_passed\n",
    "            trains =trainnn.groupby('EventID',as_index=False)\n",
    "            #trains.drop(['Weight','Label'],axis=1,inplace=True)\n",
    "            validation_datas = validation_dataq.groupby('EventID',as_index=False)\n",
    "            #validation_datas.drop(['Weight','Label'],axis=1,inplace=True)\n",
    "            #validation_data = validation_datas.nth(0)\n",
    "            #trainn=trains.nth(0)\n",
    "            if (i>1):\n",
    "                for te in range(0,i):\n",
    "                    z=['EventID']\n",
    "                    vl = validation_datas.nth(te)\n",
    "                    vl.drop(['Weight','Label'],axis=1,inplace=True)\n",
    "                    z.extend(vl.columns[1:15]+di[te])\n",
    "                    vl.columns=z\n",
    "                    #validation_data = pd.concat([validation_data,vl],axis=1)\n",
    "                    validation_data = pd.merge(validation_data,vl,on='EventID')\n",
    "                    tr = trains.nth(te)\n",
    "                    tr.drop(['Weight','Label'],axis=1,inplace=True)\n",
    "                    tr.columns=z\n",
    "                    trainn = pd.merge(trainn,tr,on='EventID')\n",
    "                    \n",
    "                    #trainn = pd.concat([trainn,tr],axis=1)\n",
    "            #print(trainn.head())\n",
    "            #trainn=trainn.groupby('EventID', as_index=False).mean()\n",
    "            #trainn=trainn.groupby('EventID', as_index=False).mean()\n",
    "\n",
    "            #test=test.groupby('EventID', as_index=False).mean()\n",
    "\n",
    "            print(trainn.shape)\n",
    "            \n",
    "            features = list(set(trainn.columns) - {'EventID', 'Label', 'Weight','size'})\n",
    "            \n",
    "            y=trainn.Label\n",
    "            print((1-y.mean())/y.mean(),y.mean(),sum(y))\n",
    "            model = xgb.XGBClassifier(max_depth= 7,learning_rate= 0.015,nthread=4,subsample= 0.8,objective='binary:logistic',colsample_bytree= 0.9,min_child_weight=0,n_estimators=tree,seed=1337,scale_pos_weight=(1-y.mean())/y.mean())\n",
    "            model.fit(trainn[features], trainn.Label)\n",
    "            #kaggle_proba = model.predict_proba(test[features])\n",
    "            proba = model.predict_proba(validation_data[features])\n",
    "\n",
    "            events_ids = np.unique(validation_data.EventID)\n",
    "            \n",
    "            # compute number of SVs in each event\n",
    "            number_of_sv_in_event = np.bincount(validation_data.EventID)\n",
    "\n",
    "            # compute predictions for events (take the mean value of predictions for SVs forming an event)\n",
    "            events_proba = compute_mean(validation_data.EventID, proba[:, 1])[events_ids]\n",
    "            \n",
    "           \n",
    "            #prob = prob + (1/k)*events_proba\n",
    "            # compute weights for events \n",
    "            events_weights = compute_mean(validation_data.EventID, validation_data.Weight)[events_ids]\n",
    "            \n",
    "            # compute labels for events \n",
    "            events_labels = compute_mean(validation_data.EventID, validation_data.Label)[events_ids]\n",
    "            daqa = pd.DataFrame()\n",
    "            daqa['EventID']=events_ids\n",
    "            daqa['proba'] = events_proba\n",
    "            daqa['Weight'] = events_weights\n",
    "            daqa['Label'] = events_labels\n",
    "            print(daqa.shape)\n",
    "            a = roc_auc_score(events_labels, events_proba, sample_weight=events_weights)\n",
    "            #print(roc_auc_score(events_labels, prob, sample_weight=events_weights))\n",
    "            auc = auc +a\n",
    "            s=s+i\n",
    "            daq=pd.concat([daq,daqa])\n",
    "            print(a)\n",
    "            #prob_test = prob_test+(1/k)*kaggle_proba\n",
    "            \n",
    "        if(i==k):\n",
    "            validation_data = validation_dataa[validation_dataa['size']>(k-1)]\n",
    "            validation_data.drop(['size'],axis=1,inplace=True)\n",
    "            validation_data=validation_data.groupby('EventID', as_index=False).mean()\n",
    "            data_1 = lab1[lab1[\"size\"] >(k-1)]\n",
    "            trainn=pd.concat([data_1,lab0])\n",
    "            trainn['tracks_dif']=trainn.Tracks_number-trainn.Tracks_number_passed\n",
    "\n",
    "            test['tracks_dif']=test.Tracks_number-test.Tracks_number_passed\n",
    "            trainn.drop(['size'],axis=1,inplace=True)\n",
    "            trainn=trainn.groupby('EventID', as_index=False).mean()\n",
    "\n",
    "            #test=test.groupby('EventID', as_index=False).mean()\n",
    "\n",
    "            print(trainn.shape)\n",
    "            features = list(set(trainn.columns) - {'EventID', 'Label', 'Weight','size'})\n",
    "            y=trainn.Label\n",
    "            print((1-y.mean())/y.mean(),y.mean(),sum(y))\n",
    "            model = xgb.XGBClassifier(max_depth= 7,learning_rate= 0.015,nthread=4,subsample= 0.8,objective='binary:logistic',colsample_bytree= 0.9,min_child_weight=0,n_estimators=tree,seed=1337,scale_pos_weight=(1-y.mean())/y.mean())\n",
    "            model.fit(trainn[features], trainn.Label)\n",
    "            #kaggle_proba = model.predict_proba(test[features])\n",
    "            proba = model.predict_proba(validation_data[features])\n",
    "            events_ids = np.unique(validation_data.EventID)\n",
    "\n",
    "            # compute number of SVs in each event\n",
    "            number_of_sv_in_event = np.bincount(validation_data.EventID)\n",
    "\n",
    "            # compute predictions for events (take the mean value of predictions for SVs forming an event)\n",
    "            events_proba = compute_mean(validation_data.EventID, proba[:, 1])[events_ids]\n",
    "\n",
    "            #prob = prob + (1/k)*events_proba\n",
    "            # compute weights for events \n",
    "            events_weights = compute_mean(validation_data.EventID, validation_data.Weight)[events_ids]\n",
    "\n",
    "            # compute labels for events \n",
    "            events_labels = compute_mean(validation_data.EventID, validation_data.Label)[events_ids]\n",
    "            daqa = pd.DataFrame()\n",
    "            daqa['EventID']=events_ids\n",
    "            daqa['proba'] = events_proba\n",
    "            daqa['Weight'] = events_weights\n",
    "            daqa['Label'] = events_labels\n",
    "            daq=pd.concat([daq,daqa])\n",
    "            a = roc_auc_score(events_labels, events_proba, sample_weight=events_weights)\n",
    "            #print(roc_auc_score(events_labels, prob, sample_weight=events_weights))\n",
    "            auc = auc +a\n",
    "            s=s+i\n",
    "            print(a)\n",
    "            #prob_test = prob_test+(1/k)*kaggle_proba\n",
    "            break\n",
    "    print( roc_auc_score(daq.Label, daq.proba, sample_weight=daq.Weight))\n",
    "    #print(auc*(1/5))\n",
    "    #print(\"prob\",prob*(1/s))\n",
    "    return 1#prob_test*(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for 1\n",
      "(14376, 17) (3120, 17)\n",
      "(14376, 17)\n",
      "0.43846307784670796 0.6951864218141347 9994.0\n",
      "(3120, 4)\n",
      "0.954242981975\n",
      "Model for 2\n",
      "(10561, 17) (1746, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7890, 45)\n",
      "0.2769056481631332 0.7831432192648923 6179.0\n",
      "(1746, 4)\n",
      "0.943189576762\n",
      "Model for 3\n",
      "(14206, 17) (2600, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10711, 59)\n",
      "0.09028908794788276 0.9171879376342078 9824.0\n",
      "(2600, 4)\n",
      "0.982317002475\n",
      "Model for 4\n",
      "(11727, 17) (1942, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7916, 73)\n",
      "0.07773995915588842 0.9278676099039919 7345.0\n",
      "(1942, 4)\n",
      "0.957290111759\n",
      "Model for 5\n",
      "(7965, 17) (910, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 87)\n",
      "0.11442924923248671 0.8973203105434511 3583.0\n",
      "(910, 4)\n",
      "0.957601620081\n",
      "Model for 6\n",
      "(8125, 17) (933, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4056, 101)\n",
      "0.08362276248998134 0.9228303747534516 3743.0\n",
      "(933, 4)\n",
      "0.981917804311\n",
      "Model for 7\n",
      "(7848, 17) (811, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3708, 115)\n",
      "0.06982111944604734 0.9347357065803668 3466.0\n",
      "(811, 4)\n",
      "0.984905093197\n",
      "Model for 8\n",
      "(7658, 17) (830, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3464, 129)\n",
      "0.057387057387057336 0.9457274826789839 3276.0\n",
      "(830, 4)\n",
      "0.873938160682\n",
      "Model for 9\n",
      "(6900, 17) (639, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2664, 143)\n",
      "0.05798252581413816 0.9451951951951952 2518.0\n",
      "(639, 4)\n",
      "0.96920884178\n",
      "Model for 10\n",
      "(6299, 17) (478, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2041, 157)\n",
      "0.0646844027125717 0.9392454679078883 1917.0\n",
      "(478, 4)\n",
      "0.992179657041\n",
      "Model for 11\n",
      "(5790, 17) (407, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1520, 171)\n",
      "0.07954545454545456 0.9263157894736842 1408.0\n",
      "(407, 4)\n",
      "0.87449978418\n",
      "Model for 12\n",
      "(5060, 17) (149, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(774, 185)\n",
      "0.1415929203539823 0.875968992248062 678.0\n",
      "(149, 4)\n",
      "0.904027414356\n",
      "Model for 13\n",
      "(4945, 17) (134, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(646, 199)\n",
      "0.14742451154529312 0.871517027863777 563.0\n",
      "(134, 4)\n",
      "0.990734671391\n",
      "Model for 14\n",
      "(4899, 17) (138, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589, 213)\n",
      "0.13926499032882017 0.8777589134125636 517.0\n",
      "(138, 4)\n",
      "0.940285999183\n",
      "Model for 15\n",
      "(4860, 17) (123, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538, 227)\n",
      "0.12552301255230128 0.8884758364312267 478.0\n",
      "(123, 4)\n",
      "0.984995357842\n",
      "Model for 16\n",
      "(4846, 17) (117, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515, 241)\n",
      "0.10991379310344833 0.9009708737864077 464.0\n",
      "(117, 4)\n",
      "1.0\n",
      "Model for 17\n",
      "(4761, 17) (90, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 255)\n",
      "0.12137203166226918 0.8917647058823529 379.0\n",
      "(90, 4)\n",
      "1.0\n",
      "Model for 18\n",
      "(4764, 17) (93, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 269)\n",
      "0.10994764397905764 0.9009433962264151 382.0\n",
      "(93, 4)\n",
      "0.99686396614\n",
      "Model for 19\n",
      "(4789, 17) (88, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 283)\n",
      "0.0933660933660934 0.9146067415730337 407.0\n",
      "(88, 4)\n",
      "0.981678670758\n",
      "Model for 20\n",
      "(4740, 17) (93, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dz/.local/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 297)\n",
      "0.09776536312849157 0.910941475826972 358.0\n",
      "(93, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-49ec5ded56c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-d597d997b740>\u001b[0m in \u001b[0;36mbaes\u001b[0;34m(data, test, k, size_train, tree)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mdaqa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevents_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaqa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevents_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;31m#print(roc_auc_score(events_labels, prob, sample_weight=events_weights))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    255\u001b[0m     return _average_binary_score(\n\u001b[1;32m    256\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/.local/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    249\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "pr = baes(train,test,25,0.8,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_1 = lab1[lab1[\"size\"] ==1]\n",
    "data_1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data_1[data_1.Label ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome = train.Weight\n",
    "\n",
    "outcome.value_counts(normalize=True)\n",
    "outcome.value_counts().plot(kind='pie', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train[train['Mass']<100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['EventID','Track_number_PV','Tracks_number','Tracks_number_passed','Weight','Flight_distance'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lab0 = train[train.Label == 0]\n",
    "lab1 = train[train.Label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lab0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lab1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lab1[lab1.Pseudorapidity < lab1.Pseudorapidity.min()+3*0.562888].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.runtime[data.runtime==0] = np.nan\n",
    "lab0[[ 'Mass', 'Corrected_mass', 'Pt', 'Pt_sum', 'Pt_min',\n",
    "       'IP_chi2', 'IP_chi2_sum', 'Flight_distance', 'Pseudorapidity',\n",
    "       'Track_number_PV', 'Tracks_number', 'Tracks_number_passed',\n",
    "       'Vertex_chi2','size']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lab1[['Mass', 'Corrected_mass', 'Pt', 'Pt_sum', 'Pt_min',\n",
    "       'IP_chi2', 'IP_chi2_sum', 'Flight_distance', 'Pseudorapidity',\n",
    "       'Track_number_PV', 'Tracks_number', 'Tracks_number_passed',\n",
    "       'Vertex_chi2', 'size']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.Label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['EventID','Track_number_PV','Tracks_number','Tracks_number_passed','Weight','Flight_distance'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lab0 = train[train.Label == 0]\n",
    "lab1 = train[train.Label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lab0.drop(['Label'],axis=1,inplace=True)\n",
    "#lab1.drop(['Label'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt, mean, std\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = train.columns\n",
    "\n",
    "for c in col:\n",
    "    z_statistic, p_value = stats.wilcoxon(lab0[c] - lab1[c])\n",
    "    print(c,lab0[c].mean(),lab0[c].std(),lab1[c].mean(),lab1[c].std(),p_value)\n",
    "#scatter_matrix(train, alpha=0.2, figsize=(6, 6), diagonal='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = train.columns\n",
    "\n",
    "for c in col:\n",
    "    print(c,lab0[c].min(),lab1[c].min())\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(lab0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lab1[lab1['Corrected_mass']>25000].Corrected_mass\n",
    "plt.figure();\n",
    "#train['Mass'].diff().hist(color='k', alpha=0.5, bins=50,figsize=(200, 200));\n",
    "lab0['Flight_distance'].hist(color='k', alpha=1, bins=100,figsize=(9, 9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "lab1.diff().hist(color='k', alpha=0.5, bins=100,figsize=(100, 100));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lab0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = train.take(np.random.permutation(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Test']= False\n",
    "test['Test']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train,test],ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['z'] = data.Tracks_number_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns = ['Tracks_number_passed'])#,'Tracks_number'])#,'Tracks_number_passed'])['Tracks_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.Track_number_PV.unique(),train.Tracks_number.unique(),train.Tracks_number_passed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.Track_number_PV.unique(),test.Tracks_number.unique(),test.Tracks_number_passed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=[1,100,3,4,50,6,7,8,90,10]\n",
    "stats.shapiro(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "#scipy.stats.shapiro(x, a=None, reta=False)[source]\n",
    "y=train.Label\n",
    "for s in train.columns:\n",
    "    z1=s\n",
    "    print(z1,stats.anderson(train[z1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new = pd.concat([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data[data.Test == 0].drop('Test', axis=1).copy()\n",
    "test = data[data.Test == 1].drop('Test', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainn=pd.concat([data_1,lab0])\n",
    "print(trainn.shape)\n",
    "trainn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Xtr,ytr,Xval,yval = validation(train,y,0.8)\n",
    "#create_cv(id_event, n_folds)\n",
    "features = list(set(trainn.columns) - {'EventID', 'Label', 'Weight','size'})\n",
    "print(features)\n",
    "training_data, validation_data = train_test_split_group(trainn.EventID, trainn, random_state=7, train_size=0.8)\n",
    "training_data.shape,validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=300, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(training_data[features], training_data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=trainn.Label\n",
    "(1-y.mean())/y.mean(),y.mean(),sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth= 6,learning_rate= 0.025,nthread=4,subsample= 0.8,objective='binary:logistic',colsample_bytree= 0.9,min_child_weight=0,\n",
    "                       n_estimators=1000,seed=1337,scale_pos_weight=(1-y.mean())/y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(training_data[features], training_data.Label,early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 7,\n",
    "    'eta': 0.015,\n",
    "    'nthread': 4,\n",
    "    'subsample': 0.8,\n",
    "    'eval_metric': ['auc'],\n",
    "    'objective': 'binary:logistic',\n",
    "    'colsample_bytree': 0.9,\n",
    "    'min_child_weight': 0,\n",
    "    'scale_pos_weight':(1-y.mean())/y.mean(),\n",
    "    'seed':1337\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr = xgb.DMatrix(training_data[features], label=training_data.Label)\n",
    "dval = xgb.DMatrix(validation_data[features], label=validation_data.Label)\n",
    "watchlist = [(dtr, 'train'), (dval, 'eval')]\n",
    "history = dict()\n",
    "model = xgb.train(params, dtr, num_boost_round=2000, evals=watchlist,evals_result=history, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mean(event_ids, values):\n",
    "    \"\"\" fore each event computes average of given values \"\"\"\n",
    "    number_of_sv_in_event = np.bincount(event_ids)\n",
    "    return np.bincount(event_ids, weights=values) / number_of_sv_in_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_data[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba = model.predict(dval)\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events_ids = np.unique(validation_data.EventID)\n",
    "\n",
    "# compute number of SVs in each event\n",
    "number_of_sv_in_event = np.bincount(validation_data.EventID)\n",
    "\n",
    "# compute predictions for events (take the mean value of predictions for SVs forming an event)\n",
    "events_proba = compute_mean(validation_data.EventID, proba[:])[events_ids]\n",
    "\n",
    "# compute weights for events \n",
    "events_weights = compute_mean(validation_data.EventID, validation_data.Weight)[events_ids]\n",
    "\n",
    "# compute labels for events \n",
    "events_labels = compute_mean(validation_data.EventID, validation_data.Label)[events_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mean(event_ids, values):\n",
    "    \"\"\" fore each event computes average of given values \"\"\"\n",
    "    number_of_sv_in_event = np.bincount(event_ids)\n",
    "    return np.bincount(event_ids, weights=values) / number_of_sv_in_event\n",
    "dtest = xgb.DMatrix(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba = model.predict_proba(validation_data[features])\n",
    "events_ids = np.unique(validation_data.EventID)\n",
    "\n",
    "# compute number of SVs in each event\n",
    "number_of_sv_in_event = np.bincount(validation_data.EventID)\n",
    "\n",
    "# compute predictions for events (take the mean value of predictions for SVs forming an event)\n",
    "events_proba = compute_mean(validation_data.EventID, proba[:, 1])[events_ids]\n",
    "\n",
    "# compute weights for events \n",
    "events_weights = compute_mean(validation_data.EventID, validation_data.Weight)[events_ids]\n",
    "\n",
    "# compute labels for events \n",
    "events_labels = compute_mean(validation_data.EventID, validation_data.Label)[events_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score(events_labels, events_proba, sample_weight=events_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=trainn.Label\n",
    "(1-y.mean())/y.mean(),y.mean(),sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data[features], training_data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pr),len(subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_proba = model.predict_proba(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kaggle_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#kaggle_proba = model.predict_proba(test[features])\n",
    "kaggle_proba = pr\n",
    "kaggle_ids = np.unique(test.EventID)\n",
    "# compute predictions for events (take the mean value of predictions for SVs forming an event)\n",
    "kaggle_events_proba = compute_mean(test.EventID, kaggle_proba[:, 1])[kaggle_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kaggle_proba[kaggle_ids]),len(kaggle_events_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usually mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x =pd.read_csv('xgbmean700full.csv')\n",
    "y = pd.read_csv('baesSizeFeatch20minmaxformorekfulldata.csv')\n",
    "#z = pd.read_csv('baesSizeFeatch20minmax.csv')\n",
    "l = pd.read_csv('xgbmin-mean.csv')\n",
    "#a = pd.read_csv('nwtmean.csv')\n",
    "g = pd.read_csv('gbt.csv')\n",
    "r =pd.read_csv('rf1000iso3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.080462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.969521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.974991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.105194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventID     Label\n",
       "0        0  0.080462\n",
       "1        1  0.997553\n",
       "2        2  0.969521\n",
       "3        3  0.974991\n",
       "4        4  0.105194"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventID</th>\n",
       "      <th>Label_x</th>\n",
       "      <th>Label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>0.008036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995567</td>\n",
       "      <td>0.998945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.837679</td>\n",
       "      <td>0.970941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.884182</td>\n",
       "      <td>0.993898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.046013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventID   Label_x   Label_y\n",
       "0        0  0.005918  0.008036\n",
       "1        1  0.995567  0.998945\n",
       "2        2  0.837679  0.970941\n",
       "3        3  0.884182  0.993898\n",
       "4        4  0.009715  0.046013"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.merge(x,y,on='EventID')\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-19da76df17bc>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-19da76df17bc>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    corr = {}l\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "x=s.Label_x\n",
    "y=s.Label_y\n",
    "corr = {}l\n",
    "corr['pearson'], _ = stats.pearsonr(x,y)\n",
    "corr['spearman'], _ = stats.spearmanr(x,y)\n",
    "corr['kendall'], _ = stats.kendalltau(x,y)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.098019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.987851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.648814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.757560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.169390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventID     Label\n",
       "0        0  0.098019\n",
       "1        1  3.987851\n",
       "2        2  3.648814\n",
       "3        3  3.757560\n",
       "4        4  0.169390"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['Label'] = s.Label_x+s.Label_y+l.Label+r.Label\n",
    "g.to_csv('mean.csv', index=False)\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.837679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.884182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventID     Label\n",
       "0        0  0.005918\n",
       "1        1  0.995567\n",
       "2        2  0.837679\n",
       "3        3  0.884182\n",
       "4        4  0.009715"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rank mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x =pd.read_csv('xgbmean700full.csv')\n",
    "y = pd.read_csv('bayes.csv')\n",
    "array = np.array(x.Label)\n",
    "temp = array.argsort()\n",
    "ranksx = np.arange(len(array))[temp.argsort()]\n",
    "array = np.array(y.Label)\n",
    "temp = array.argsort()\n",
    "ranksb = np.arange(len(array))[temp.argsort()]\n",
    "ranksb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsk = ranksb+ranksx\n",
    "y['Label'] = predsk\n",
    "y.to_csv('meanbayes+xgbmean(rank).csv', index=False)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = pd.read_csv('meanbayes+xgbmean.csv')\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prb=pr[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probas = pd.DataFrame()\n",
    "probas = x.Label+pr[:,1]\n",
    "probas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "def create_solution(ids, proba, filename='nwtmean.csv'):\n",
    "    \"\"\"saves predictions to file and provides a link for downloading \"\"\"\n",
    "    pd.DataFrame({'EventID': ids, 'Label': proba}).to_csv('{}'.format(filename), index=False)\n",
    "    return FileLink('{}'.format(filename))\n",
    "    \n",
    "create_solution(kaggle_ids, kaggle_events_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = np.array(prx)\n",
    "temp = array.argsort()\n",
    "ranksx = np.arange(len(array))[temp.argsort()]\n",
    "array = np.array(prb)\n",
    "temp = array.argsort()\n",
    "ranksb = np.arange(len(array))[temp.argsort()]\n",
    "ranksb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_mean = p"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

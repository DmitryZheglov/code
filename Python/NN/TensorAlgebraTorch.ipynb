{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  5   6   7   8\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- tensor\n",
      "torch.Size([3, 4]) <- tensor size\n",
      "3 <- dimension size\n",
      "\n",
      "  6   7\n",
      " 10  11\n",
      "[torch.FloatTensor of size 2x2]\n",
      " <- slicing support\n"
     ]
    }
   ],
   "source": [
    "# Создаем тензор\n",
    "x = torch.rand([3, 4])\n",
    "x = torch.zeros([3, 4])\n",
    "x = torch.ones([3, 4])\n",
    "x = torch.eye(3, 4)\n",
    "\n",
    "x = torch.Tensor(\n",
    "[[1,  2,  3,  4],\n",
    " [5,  6,  7,  8],\n",
    " [9, 10, 11, 12]])\n",
    "\n",
    "print (x, '<- tensor')\n",
    "print (x.size(), '<- tensor size')\n",
    "print (x.size(0), '<- dimension size')\n",
    "print (x[1:, 1:3], '<- slicing support')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- shallow copy\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "  1   2   3   4\n",
      "  2   2   2   2\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- deep copy\n"
     ]
    }
   ],
   "source": [
    "# Копирование (по ссылке и глубокое)\n",
    "y = x\n",
    "\n",
    "y[1, :] = 1\n",
    "print (x, y, '<- shallow copy')\n",
    "\n",
    "y = x.clone()\n",
    "y[1, :] = 2\n",
    "print (x, y, '<- deep copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2   4   6   8\n",
      "  3   3   3   3\n",
      " 18  20  22  24\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "   1    4    9   16\n",
      "   2    2    2    2\n",
      "  81  100  121  144\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 1.0000  1.0000  1.0000  1.0000\n",
      " 0.5000  0.5000  0.5000  0.5000\n",
      " 1.0000  1.0000  1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 0  0  0  0\n",
      "-1 -1 -1 -1\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 0  0  0  0\n",
      " 1  1  1  1\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "   1    4    9   16\n",
      "   1    1    1    1\n",
      "  81  100  121  144\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 1.0000e+00  4.0000e+00  2.7000e+01  2.5600e+02\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      " 3.8742e+08  1.0000e+10  2.8531e+11  8.9161e+12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- basic math\n"
     ]
    }
   ],
   "source": [
    "# Математические операции (стандартные поэлементные)\n",
    "print( x + y, x * y, x / y, x - y, x % y, x**2, x**y, '<- basic math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dot(y.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.7183e+00  7.3891e+00  2.0086e+01  5.4598e+01\n",
      " 2.7183e+00  2.7183e+00  2.7183e+00  2.7183e+00\n",
      " 8.1031e+03  2.2026e+04  5.9874e+04  1.6275e+05\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.0000  0.6931  1.0986  1.3863\n",
      " 0.0000  0.0000  0.0000  0.0000\n",
      " 2.1972  2.3026  2.3979  2.4849\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.8415  0.9093  0.1411 -0.7568\n",
      " 0.8415  0.8415  0.8415  0.8415\n",
      " 0.4121 -0.5440 -1.0000 -0.5366\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Более сложные операции\n",
    "print (torch.exp(x))\n",
    "print (torch.log(x))\n",
    "print (torch.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4\n",
      "  9\n",
      " 10\n",
      " 11\n",
      " 12\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "\n",
      " 0  0  0  1\n",
      " 0  0  0  0\n",
      " 1  1  1  1\n",
      "[torch.ByteTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Логические операции\n",
    "y = x[x > 3]\n",
    "print(y)\n",
    "y = (x > 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.DoubleTensor of size 3x4]\n",
      "\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.IntTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Переопределение типа\n",
    "x = x.float()\n",
    "print (x)\n",
    "x = x.double()\n",
    "print (x)\n",
    "x = x.int()\n",
    "print(x)\n",
    "x = x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n",
      "\n",
      " 1  2  3  4\n",
      " 4  3  2  1\n",
      "[torch.LongTensor of size 2x4]\n",
      "\n",
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n"
     ]
    }
   ],
   "source": [
    "# Взаимодействие с Numpy\n",
    "x = numpy.array([[1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print (x)\n",
    "x = torch.from_numpy(x)\n",
    "print (x)\n",
    "x = x.numpy()\n",
    "print (x)\n",
    "x = torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2ebb94709380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Перемещение на GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<- CUDA Tensor!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m         raise RuntimeError(\n\u001b[1;32m     95\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dz/anaconda3/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Перемещение на GPU\n",
    "import time\n",
    "x_cuda = x.cuda()\n",
    "print (x_cuda, '<- CUDA Tensor!')\n",
    "start = time.time()\n",
    "y = (x - x + x*10.0) ** 2\n",
    "print (time.time() - start, '<- CPU time')\n",
    "start = time.time()\n",
    "y_cuda = (x_cuda - x_cuda + x_cuda * 10.0) ** 2\n",
    "print (time.time() - start, '<- GPU time' )\n",
    "y = y_cuda.cpu()\n",
    "print (y)\n",
    "# print(x ** 2, '<- operation performed on the GPU!!!')\n",
    "# print x = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "   14.7781   109.1963   806.8576  5961.9155\n",
      " 5961.9155   806.8576   109.1963    14.7781\n",
      "[torch.FloatTensor of size 2x4]\n",
      " <- gradient\n",
      "Variable containing:\n",
      "   14.7781   109.1963   806.8576  5961.9155\n",
      " 5961.9155   806.8576   109.1963    14.7781\n",
      "[torch.FloatTensor of size 2x4]\n",
      " <- gradient\n",
      "Variable containing:\n",
      "    29.5562    218.3926   1613.7152  11923.8311\n",
      " 11923.8311   1613.7152    218.3926     29.5562\n",
      "[torch.FloatTensor of size 2x4]\n",
      " <- gradient\n"
     ]
    }
   ],
   "source": [
    "# Автоматическое (символьное) дифференциирование (обратное распространение градиента) (случай скаляра)\n",
    "import torch.autograd\n",
    "x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "formula = (torch.exp(x_var) ** 2).sum()\n",
    "formula.backward()\n",
    "\n",
    "print x_var.grad, '<- gradient'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    7.3891    54.5982   403.4288  2980.9578\n",
      " 2980.9578   403.4288    54.5982     7.3891\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "Variable containing:\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "Variable containing:\n",
      "   14.7781   109.1963   806.8576  5961.9155\n",
      " 5961.9155   806.8576   109.1963    14.7781\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Автоматическое дифференциирование (обратное распространение градиента) (случай тензора)\n",
    "# variable -> formula1 (вектор) -> formula2 (скаляр)\n",
    "x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "formula1 = torch.exp(x_var) ** 2.0\n",
    "y_var = torch.autograd.Variable(formula1.data.clone(), requires_grad=True)\n",
    "formula2 = y_var.sum()\n",
    "formula2.backward()\n",
    "y_grad = y_var.grad.clone()\n",
    "print formula1\n",
    "print y_grad\n",
    "formula1.backward(gradient=y_grad.data)\n",
    "print x_var.grad"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, inp_size, hid_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \"\"\"\n",
    "        Here you should define layers of your autoencoder\n",
    "        Please note, if a layer has trainable parameters, it should be nn.Linear. \n",
    "        ## !! CONVOLUTIONAL LAYERS CAN NOT BE HERE !! ##\n",
    "        However, you can use any noise inducing layers, e.g. Dropout.\n",
    "\n",
    "        Your network must not have more than six layers with trainable parameters.\n",
    "        :param inp_size: integer, dimension of the input object\n",
    "        :param hid_size: integer, dimension of the hidden representation\n",
    "        \"\"\"\n",
    "        self.input_layer = nn.Linear(inp_size, hid_size)\n",
    "        self.encode_layer = nn.Linear(hid_size, hid_size)\n",
    "        self.encode2_layer = nn.Linear(hid_size, hid_size)\n",
    "        self.decode_layer = nn.Linear(hid_size, hid_size)\n",
    "        self.decode2_layer = nn.Linear(hid_size, hid_size)\n",
    "        self.output_layer = nn.Linear(hid_size, inp_size)\n",
    "        pass\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encodes objects to hidden representations (E: R^inp_size -> R^hid_size)\n",
    "\n",
    "        :param x: inputs, Variable of shape (batch_size, inp_size)\n",
    "        :return:  hidden represenation of the objects, Variable of shape (batch_size, hid_size)\n",
    "        \"\"\"\n",
    "        hid_enc_layer = nn.functional.elu(self.input_layer(x))\n",
    "        hid_enc_layer = nn.functional.dropout(hid_enc_layer)\n",
    "        hid_enc_layer = nn.functional.elu(self.encode_layer(hid_enc_layer))\n",
    "        hid_enc_layer = nn.functional.dropout(hid_enc_layer, p = 0.7)\n",
    "        #hid_enc_layer = nn.functional.elu(self.encode2_layer(hid_enc_layer))\n",
    "        #hid_enc_layer = nn.functional.dropout(hid_enc_layer)\n",
    "        return hid_enc_layer\n",
    "\n",
    "    def decode(self, h):\n",
    "        \"\"\"\n",
    "        Decodes objects from hidden representations (D: R^hid_size -> R^inp_size)\n",
    "\n",
    "        :param h: hidden represenatations, Variable of shape (batch_size, hid_size)\n",
    "        :return:  reconstructed objects, Variable of shape (batch_size, inp_size)\n",
    "        \"\"\"\n",
    "        hid_dec_layer = nn.functional.elu(self.decode_layer(h))\n",
    "        hid_dec_layer = nn.functional.dropout(hid_dec_layer, p = 0.7)\n",
    "        #hid_dec_layer = nn.functional.elu(self.decode2_layer(hid_dec_layer))\n",
    "        #hid_dec_layer = nn.functional.dropout(hid_dec_layer, p = 0.8)\n",
    "        output = nn.functional.self.output_layer(hid_dec_layer)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Encodes inputs to hidden representations and decodes back.\n",
    "\n",
    "        x: inputs, Variable of shape (batch_size, inp_size)\n",
    "        return: reconstructed objects, Variable of shape (batch_size, inp_size)\n",
    "        \"\"\"\n",
    "        return self.decode(self.encode(x))\n",
    "\n",
    "    def loss_function(self, recon_x, x):\n",
    "        \"\"\"\n",
    "        Calculates the loss function.\n",
    "\n",
    "        :params recon_x: reconstructed object, Variable of shape (batch_size, inp_size)\n",
    "        :params x: original object, Variable of shape (batch_size, inp_size)\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        lamb = 0.01\n",
    "        mse_loss = nn.MSELoss(size_average=False)\n",
    "        loss = mse_loss(recon_x, x)\n",
    "        loss = loss + self.input_layer.weight.norm(1) * lamb\n",
    "        loss = loss + self.encode_layer.weight.norm(1) * lamb\n",
    "        #loss = loss + self.encode2_layer.weight.norm(1) * lamb\n",
    "        loss = loss + self.decode_layer.weight.norm(1) * lamb\n",
    "        #loss = loss + self.decode2_layer.weight.norm(1) * lamb\n",
    "        loss = loss + self.output_layer.weight.norm(1) * lamb\n",
    "        \n",
    "\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, test_loader):\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        train_loss, test_loss = 0, 0\n",
    "        \n",
    "        lamb = 1\n",
    "        to_regularise = []\n",
    "        for param in model.parameters():\n",
    "            to_regularise.append(param.view(-1))\n",
    "        weig = lamb * torch.abs(torch.cat(to_regularise)).sum()\n",
    "    \n",
    "        print('grad', weig)\n",
    "        \n",
    "        for data, _ in train_loader:\n",
    "            data = Variable(data).view(-1, 784)\n",
    "            x_rec = model(data)\n",
    "            loss = model.loss_function(x_rec, data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data[0]\n",
    "            \n",
    "        lamb = 1\n",
    "        to_regularise = []\n",
    "        for param in model.parameters():\n",
    "            to_regularise.append(param.view(-1))\n",
    "        weig = lamb * torch.abs(torch.cat(to_regularise)).sum()\n",
    "    \n",
    "        print('grad', weig)\n",
    "        print('=> Epoch: %s Average loss: %.10f' % (epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "        model.eval()\n",
    "        for data, _ in test_loader:\n",
    "            data = Variable(data, volatile=True).view(-1, 784)\n",
    "            x_rec = model(data)\n",
    "            test_loss += model.loss_function(x_rec, data).data[0]\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('=> Test set loss: %.10f' % test_loss)\n",
    "\n",
    "        n = min(data.size(0), 8)\n",
    "        comparison = torch.cat([data.view(-1, 1, 28, 28)[:n], x_rec.view(-1, 1, 28, 28)[:n]])\n",
    "        if not os.path.exists('./pics'): os.makedirs('./pics')\n",
    "        save_image(comparison.data.cpu(), 'pics/reconstruction_n' + str(epoch) + '.png', nrow=n)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_work():\n",
    "    print('Start test')\n",
    "    get_loader = lambda train: torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=train, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=50, shuffle=True)\n",
    "    train_loader, test_loader = get_loader(True), get_loader(False)\n",
    "    \n",
    "    try:\n",
    "        model = AutoEncoder(inp_size=784, hid_size=20)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    except Exception:\n",
    "        assert False, 'Error during model creation'\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        model = train(model, optimizer, train_loader, test_loader)\n",
    "    except Exception:\n",
    "        assert False, 'Error during training'\n",
    "        return\n",
    "\n",
    "    test_x = Variable(torch.randn(1, 784))    \n",
    "    rec_x, hid_x = model(test_x), model.encode(test_x)\n",
    "    submodules = dict(model.named_children())\n",
    "    layers_with_params = np.unique(['.'.join(n.split('.')[:-1]) for n, _ in model.named_parameters()])\n",
    "    \n",
    "    assert (hid_x.dim() == 2) and (hid_x.size(1) == 20),  'Hidden representation size must be equal to 20'\n",
    "    assert (rec_x.dim() == 2) and (rec_x.size(1) == 784), 'Reconstruction size must be equal to 784'\n",
    "    assert len(layers_with_params) <= 6, 'The model must have no more than 6 layers '\n",
    "    assert np.all(np.concatenate([list(p.shape) for p in model.parameters()]) <= 800), 'All hidden sizes must be less than 800'\n",
    "    print('Success!ðŸŽ‰')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2309.6309\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1610.3176\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 33.0552580414\n",
      "=> Test set loss: 22.1630529236\n",
      "grad Variable containing:\n",
      " 1610.3176\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1462.3767\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 20.7240978689\n",
      "=> Test set loss: 19.5884071594\n",
      "grad Variable containing:\n",
      " 1462.3767\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1434.7466\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 19.6149927022\n",
      "=> Test set loss: 19.0110141907\n",
      "grad Variable containing:\n",
      " 1434.7466\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1421.0444\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 19.3256101176\n",
      "=> Test set loss: 18.9123745239\n",
      "grad Variable containing:\n",
      " 1421.0444\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1409.4445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 19.2652419657\n",
      "=> Test set loss: 18.9033342651\n",
      "grad Variable containing:\n",
      " 1409.4445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1401.4420\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 19.2366315318\n",
      "=> Test set loss: 18.8638883362\n",
      "grad Variable containing:\n",
      " 1401.4420\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1390.2031\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 19.2123822622\n",
      "=> Test set loss: 18.8465288879\n",
      "grad Variable containing:\n",
      " 1390.2031\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1383.7195\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 19.1922056376\n",
      "=> Test set loss: 18.8328130066\n",
      "grad Variable containing:\n",
      " 1383.7195\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1377.3547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 19.1808727315\n",
      "=> Test set loss: 18.8227215515\n",
      "grad Variable containing:\n",
      " 1377.3547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1371.1508\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 19.1742816325\n",
      "=> Test set loss: 18.8439709534\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#4 with drop lamd =0.01  relu out\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2295.6257\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1642.6779\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 33.5669330037\n",
      "=> Test set loss: 22.6939718811\n",
      "grad Variable containing:\n",
      " 1642.6779\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1464.5306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 21.3180523488\n",
      "=> Test set loss: 19.8343023132\n",
      "grad Variable containing:\n",
      " 1464.5306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1427.3098\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 19.9735260712\n",
      "=> Test set loss: 19.5669393066\n",
      "grad Variable containing:\n",
      " 1427.3098\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1436.2330\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 19.7097327291\n",
      "=> Test set loss: 19.0637307983\n",
      "grad Variable containing:\n",
      " 1436.2330\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1421.9390\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 19.3234170207\n",
      "=> Test set loss: 18.9066343018\n",
      "grad Variable containing:\n",
      " 1421.9390\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1412.3948\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 19.2306288340\n",
      "=> Test set loss: 18.8793697083\n",
      "grad Variable containing:\n",
      " 1412.3948\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1404.3752\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 19.1893990133\n",
      "=> Test set loss: 18.8121134460\n",
      "grad Variable containing:\n",
      " 1404.3752\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1395.7137\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 19.1790364309\n",
      "=> Test set loss: 18.8139389038\n",
      "grad Variable containing:\n",
      " 1395.7137\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1391.5078\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 19.1729779215\n",
      "=> Test set loss: 18.8204438110\n",
      "grad Variable containing:\n",
      " 1391.5078\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1384.7563\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 19.1719581665\n",
      "=> Test set loss: 18.8053801758\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#4 with drop lamd =0.01  elu all\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2314.6416\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1329.6965\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 31.6432058156\n",
      "=> Test set loss: 20.4173750366\n",
      "grad Variable containing:\n",
      " 1329.6965\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1269.1555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 19.7074066274\n",
      "=> Test set loss: 18.9114879761\n",
      "grad Variable containing:\n",
      " 1269.1555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1258.6685\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 19.2313594320\n",
      "=> Test set loss: 18.8156986511\n",
      "grad Variable containing:\n",
      " 1258.6685\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1251.4125\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 19.1696670288\n",
      "=> Test set loss: 18.7627396484\n",
      "grad Variable containing:\n",
      " 1251.4125\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1248.3119\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 19.1519089132\n",
      "=> Test set loss: 18.7969813782\n",
      "grad Variable containing:\n",
      " 1248.3119\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1243.5370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 19.1463035472\n",
      "=> Test set loss: 18.7822714111\n",
      "grad Variable containing:\n",
      " 1243.5370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1241.4209\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 19.1386834778\n",
      "=> Test set loss: 18.7743785339\n",
      "grad Variable containing:\n",
      " 1241.4209\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1237.5624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 19.1364025248\n",
      "=> Test set loss: 18.7855539063\n",
      "grad Variable containing:\n",
      " 1237.5624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1233.1107\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 19.1342995575\n",
      "=> Test set loss: 18.7690713074\n",
      "grad Variable containing:\n",
      " 1233.1107\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1231.9481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 19.1326102305\n",
      "=> Test set loss: 18.7788306458\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#2 with drop lamd =0.01  elu all\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2310.5317\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1782.8469\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 35.9894269165\n",
      "=> Test set loss: 26.4441925049\n",
      "grad Variable containing:\n",
      " 1782.8469\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1569.4493\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 25.2054465007\n",
      "=> Test set loss: 23.5956553101\n",
      "grad Variable containing:\n",
      " 1569.4493\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1508.8407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 23.3927992126\n",
      "=> Test set loss: 22.4288883911\n",
      "grad Variable containing:\n",
      " 1508.8407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1490.5808\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 22.3072722972\n",
      "=> Test set loss: 21.5811816589\n",
      "grad Variable containing:\n",
      " 1490.5808\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1464.1202\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 21.8454740712\n",
      "=> Test set loss: 21.4514420654\n",
      "grad Variable containing:\n",
      " 1464.1202\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1497.3179\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 21.4177641561\n",
      "=> Test set loss: 20.7376883301\n",
      "grad Variable containing:\n",
      " 1497.3179\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1492.5117\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 20.9976614502\n",
      "=> Test set loss: 20.5933902405\n",
      "grad Variable containing:\n",
      " 1492.5117\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1505.3162\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 20.8202617035\n",
      "=> Test set loss: 20.3961075073\n",
      "grad Variable containing:\n",
      " 1505.3162\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1509.2067\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 20.4640445882\n",
      "=> Test set loss: 20.0125980164\n",
      "grad Variable containing:\n",
      " 1509.2067\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1506.8478\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 20.2432784363\n",
      "=> Test set loss: 19.8111585938\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 with drop lamd =0.01  elu all\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2286.2600\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1511.4890\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 40.5066887614\n",
      "=> Test set loss: 29.7542896729\n",
      "grad Variable containing:\n",
      " 1511.4890\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1594.2330\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 28.6358888326\n",
      "=> Test set loss: 27.4226381714\n",
      "grad Variable containing:\n",
      " 1594.2330\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1524.7728\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 26.9517177795\n",
      "=> Test set loss: 25.8337398193\n",
      "grad Variable containing:\n",
      " 1524.7728\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1470.5261\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 25.5995509399\n",
      "=> Test set loss: 24.8847543701\n",
      "grad Variable containing:\n",
      " 1470.5261\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1460.9696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 25.0290299296\n",
      "=> Test set loss: 24.4481749512\n",
      "grad Variable containing:\n",
      " 1460.9696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1438.4205\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 24.4045016418\n",
      "=> Test set loss: 23.8877576233\n",
      "grad Variable containing:\n",
      " 1438.4205\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1424.3276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 24.0972813009\n",
      "=> Test set loss: 23.6749017944\n",
      "grad Variable containing:\n",
      " 1424.3276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1448.2371\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 23.8885391144\n",
      "=> Test set loss: 23.2662719727\n",
      "grad Variable containing:\n",
      " 1448.2371\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1452.2994\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 23.2858593577\n",
      "=> Test set loss: 22.7189212219\n",
      "grad Variable containing:\n",
      " 1452.2994\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1448.7694\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 22.9868004252\n",
      "=> Test set loss: 22.5343132751\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 with drop lamd =0.01  non\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2311.0378\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1449.5646\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 42.9684445841\n",
      "=> Test set loss: 34.1022025146\n",
      "grad Variable containing:\n",
      " 1449.5646\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1399.3937\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 32.1157795919\n",
      "=> Test set loss: 30.8355845581\n",
      "grad Variable containing:\n",
      " 1399.3937\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1356.3654\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 29.9864371623\n",
      "=> Test set loss: 28.3810823364\n",
      "grad Variable containing:\n",
      " 1356.3654\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1300.7369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 28.1422103068\n",
      "=> Test set loss: 27.3700321533\n",
      "grad Variable containing:\n",
      " 1300.7369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1288.4093\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 27.1201471944\n",
      "=> Test set loss: 26.3270909058\n",
      "grad Variable containing:\n",
      " 1288.4093\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1283.5647\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 26.3511328796\n",
      "=> Test set loss: 25.8335180054\n",
      "grad Variable containing:\n",
      " 1283.5647\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1292.1740\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 25.9710669718\n",
      "=> Test set loss: 25.4475033936\n",
      "grad Variable containing:\n",
      " 1292.1740\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1291.7053\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 25.4242429220\n",
      "=> Test set loss: 24.8758860840\n",
      "grad Variable containing:\n",
      " 1291.7053\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1297.9164\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 25.0127841125\n",
      "=> Test set loss: 24.4208478882\n",
      "grad Variable containing:\n",
      " 1297.9164\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1314.7915\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 24.6771834798\n",
      "=> Test set loss: 24.1405248047\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 with drop lamd =0.01 \n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2314.8250\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1416.3394\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 41.5609312846\n",
      "=> Test set loss: 31.7678521606\n",
      "grad Variable containing:\n",
      " 1416.3394\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1356.2966\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 30.1691095500\n",
      "=> Test set loss: 28.3201942383\n",
      "grad Variable containing:\n",
      " 1356.2966\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1350.3772\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 27.8143228190\n",
      "=> Test set loss: 26.8189135254\n",
      "grad Variable containing:\n",
      " 1350.3772\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1331.1981\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 26.5865759603\n",
      "=> Test set loss: 25.7204607422\n",
      "grad Variable containing:\n",
      " 1331.1981\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1361.3058\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 25.5195417938\n",
      "=> Test set loss: 24.9096584351\n",
      "grad Variable containing:\n",
      " 1361.3058\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1373.9407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 25.0439451681\n",
      "=> Test set loss: 24.4433409912\n",
      "grad Variable containing:\n",
      " 1373.9407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1360.1537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 24.4566270681\n",
      "=> Test set loss: 23.9117785522\n",
      "grad Variable containing:\n",
      " 1360.1537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1366.5114\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 24.0934982452\n",
      "=> Test set loss: 23.6729693054\n",
      "grad Variable containing:\n",
      " 1366.5114\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1368.5902\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 23.8638779277\n",
      "=> Test set loss: 23.4505322388\n",
      "grad Variable containing:\n",
      " 1368.5902\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1364.4731\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 23.7280580139\n",
      "=> Test set loss: 23.3336077393\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 with drop lamd =0.01 elu\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2309.0820\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1306.6409\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 51.5289968180\n",
      "=> Test set loss: 45.7441240845\n",
      "grad Variable containing:\n",
      " 1306.6409\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1353.1969\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 44.2440124349\n",
      "=> Test set loss: 43.1443000977\n",
      "grad Variable containing:\n",
      " 1353.1969\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1366.6925\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 42.3837350850\n",
      "=> Test set loss: 42.0536548706\n",
      "grad Variable containing:\n",
      " 1366.6925\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1396.2426\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 41.6112033325\n",
      "=> Test set loss: 41.4329685425\n",
      "grad Variable containing:\n",
      " 1396.2426\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1401.9677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 40.9454733948\n",
      "=> Test set loss: 40.9438616455\n",
      "grad Variable containing:\n",
      " 1401.9677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1411.0553\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 40.6607390503\n",
      "=> Test set loss: 40.7228076294\n",
      "grad Variable containing:\n",
      " 1411.0553\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1421.2139\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 40.5400047506\n",
      "=> Test set loss: 40.6321198608\n",
      "grad Variable containing:\n",
      " 1421.2139\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1435.9115\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 40.4528281108\n",
      "=> Test set loss: 40.6092537964\n",
      "grad Variable containing:\n",
      " 1435.9115\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1464.5504\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 40.3122094645\n",
      "=> Test set loss: 40.3722028564\n",
      "grad Variable containing:\n",
      " 1464.5504\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1466.0061\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 40.0194614746\n",
      "=> Test set loss: 40.1303990234\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 with drop lamd =0.01 relu\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2317.4285\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1504.4011\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 45.4244158183\n",
      "=> Test set loss: 35.8871722412\n",
      "grad Variable containing:\n",
      " 1504.4011\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1368.9613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 33.0433653605\n",
      "=> Test set loss: 31.6789344116\n",
      "grad Variable containing:\n",
      " 1368.9613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1299.6431\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 31.7259760763\n",
      "=> Test set loss: 31.2949506104\n",
      "grad Variable containing:\n",
      " 1299.6431\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1308.0544\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 31.0012339193\n",
      "=> Test set loss: 29.9137347412\n",
      "grad Variable containing:\n",
      " 1308.0544\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1309.4149\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 29.8763126892\n",
      "=> Test set loss: 29.2443177734\n",
      "grad Variable containing:\n",
      " 1309.4149\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1301.7294\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 29.4121775818\n",
      "=> Test set loss: 28.9319020264\n",
      "grad Variable containing:\n",
      " 1301.7294\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1295.5953\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 29.1851239360\n",
      "=> Test set loss: 28.7650206299\n",
      "grad Variable containing:\n",
      " 1295.5953\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1304.0402\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 28.9549475667\n",
      "=> Test set loss: 28.3560337891\n",
      "grad Variable containing:\n",
      " 1304.0402\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1330.1323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 28.4004551432\n",
      "=> Test set loss: 27.7695177612\n",
      "grad Variable containing:\n",
      " 1330.1323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1303.8466\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 27.8644465352\n",
      "=> Test set loss: 27.5635296875\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 without drop lamd =0.01 \n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2307.6943\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1552.4580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 42.3662590108\n",
      "=> Test set loss: 30.4274570435\n",
      "grad Variable containing:\n",
      " 1552.4580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1476.2120\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 29.3135714640\n",
      "=> Test set loss: 28.1761595581\n",
      "grad Variable containing:\n",
      " 1476.2120\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1440.9937\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 27.9515191264\n",
      "=> Test set loss: 27.1351969727\n",
      "grad Variable containing:\n",
      " 1440.9937\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1465.4238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 27.0727358602\n",
      "=> Test set loss: 26.1822535400\n",
      "grad Variable containing:\n",
      " 1465.4238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1450.9554\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 26.3071310913\n",
      "=> Test set loss: 25.7215403931\n",
      "grad Variable containing:\n",
      " 1450.9554\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1449.2407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 25.9527795288\n",
      "=> Test set loss: 25.4011748535\n",
      "grad Variable containing:\n",
      " 1449.2407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1447.8190\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 25.5303715658\n",
      "=> Test set loss: 25.0132608154\n",
      "grad Variable containing:\n",
      " 1447.8190\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1451.3457\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 25.1336188009\n",
      "=> Test set loss: 24.6006770142\n",
      "grad Variable containing:\n",
      " 1451.3457\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1453.6935\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 24.7693359070\n",
      "=> Test set loss: 24.2196634705\n",
      "grad Variable containing:\n",
      " 1453.6935\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1454.4940\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 24.4913304647\n",
      "=> Test set loss: 24.0438680664\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 without drop lamd =0.01 \n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2310.7456\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 2589.1865\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 44.6964374736\n",
      "=> Test set loss: 34.3524466309\n",
      "grad Variable containing:\n",
      " 2589.1865\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 2675.6182\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 32.3168525004\n",
      "=> Test set loss: 30.5847254883\n",
      "grad Variable containing:\n",
      " 2675.6182\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 2719.4648\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 30.6328585002\n",
      "=> Test set loss: 30.1271101929\n",
      "grad Variable containing:\n",
      " 2719.4648\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 2768.7129\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 29.5340945089\n",
      "=> Test set loss: 28.9078280151\n",
      "grad Variable containing:\n",
      " 2768.7129\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 2830.9885\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 28.9585376058\n",
      "=> Test set loss: 28.0005263306\n",
      "grad Variable containing:\n",
      " 2830.9885\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 2842.5049\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 28.0576729390\n",
      "=> Test set loss: 27.6792846069\n",
      "grad Variable containing:\n",
      " 2842.5049\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 2887.4478\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 27.8610823853\n",
      "=> Test set loss: 27.4323270752\n",
      "grad Variable containing:\n",
      " 2887.4478\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 3099.4985\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 27.5617086589\n",
      "=> Test set loss: 27.0755446533\n",
      "grad Variable containing:\n",
      " 3099.4985\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 3118.1201\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 27.0978923238\n",
      "=> Test set loss: 26.7602699097\n",
      "grad Variable containing:\n",
      " 3118.1201\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 3161.4639\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 26.9969503174\n",
      "=> Test set loss: 26.7552768311\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 without drop lamd =0\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2315.9141\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 257.7109\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 56.3725871623\n",
      "=> Test set loss: 49.2809444824\n",
      "grad Variable containing:\n",
      " 257.7109\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 277.9843\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 48.6047262614\n",
      "=> Test set loss: 47.9669462646\n",
      "grad Variable containing:\n",
      " 277.9843\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 302.8383\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 47.7194173869\n",
      "=> Test set loss: 47.5160375732\n",
      "grad Variable containing:\n",
      " 302.8383\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 344.2684\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 47.4270903788\n",
      "=> Test set loss: 47.1348263428\n",
      "grad Variable containing:\n",
      " 344.2684\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 360.5707\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 46.9757240641\n",
      "=> Test set loss: 46.7329045654\n",
      "grad Variable containing:\n",
      " 360.5707\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 372.4704\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 46.7317227519\n",
      "=> Test set loss: 46.6804273926\n",
      "grad Variable containing:\n",
      " 372.4704\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 386.4529\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 46.6269818115\n",
      "=> Test set loss: 46.5741498535\n",
      "grad Variable containing:\n",
      " 386.4529\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 404.7879\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 46.5663826233\n",
      "=> Test set loss: 46.4758829956\n",
      "grad Variable containing:\n",
      " 404.7879\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 428.7457\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 46.4354734375\n",
      "=> Test set loss: 46.2761492187\n",
      "grad Variable containing:\n",
      " 428.7457\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 445.9696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 46.2978718506\n",
      "=> Test set loss: 46.2475825562\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#6 without drop lamd =1 \n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2196.9106\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1258.3378\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 45.4643422384\n",
      "=> Test set loss: 36.7712294556\n",
      "grad Variable containing:\n",
      " 1258.3378\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1287.1506\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 35.5661980123\n",
      "=> Test set loss: 33.6818182983\n",
      "grad Variable containing:\n",
      " 1287.1506\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1407.0947\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 32.9452833455\n",
      "=> Test set loss: 31.7150201904\n",
      "grad Variable containing:\n",
      " 1407.0947\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1459.5656\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 31.5732136597\n",
      "=> Test set loss: 30.8362505493\n",
      "grad Variable containing:\n",
      " 1459.5656\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1510.6660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 30.7912945618\n",
      "=> Test set loss: 30.0383034424\n",
      "grad Variable containing:\n",
      " 1510.6660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1509.1323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 30.2249559774\n",
      "=> Test set loss: 29.7765101440\n",
      "grad Variable containing:\n",
      " 1509.1323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1510.6093\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 29.9570769084\n",
      "=> Test set loss: 29.5327756714\n",
      "grad Variable containing:\n",
      " 1510.6093\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1517.3496\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 29.7628549377\n",
      "=> Test set loss: 29.3072033936\n",
      "grad Variable containing:\n",
      " 1517.3496\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1522.6534\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 29.6046281311\n",
      "=> Test set loss: 29.1959225586\n",
      "grad Variable containing:\n",
      " 1522.6534\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1525.7759\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 29.4608625488\n",
      "=> Test set loss: 29.1006686157\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Hidden representation size must be equal to 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-bd1e9e12e787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#6 without drop lamd =1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_work\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-22b9a0a87d6c>\u001b[0m in \u001b[0;36mtest_work\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlayers_with_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhid_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhid_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'Hidden representation size must be equal to 20'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrec_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrec_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Reconstruction size must be equal to 784'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_with_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The model must have no more than 6 layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Hidden representation size must be equal to 20"
     ]
    }
   ],
   "source": [
    "#6 without drop lamd =0.01 \n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2206.4917\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 231.6028\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 50.4122389872\n",
      "=> Test set loss: 39.7399684448\n",
      "grad Variable containing:\n",
      " 231.6028\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 243.0682\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 38.0091780741\n",
      "=> Test set loss: 36.0479500488\n",
      "grad Variable containing:\n",
      " 243.0682\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 241.3143\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 35.7221777771\n",
      "=> Test set loss: 35.1394902100\n",
      "grad Variable containing:\n",
      " 241.3143\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 241.4347\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 35.2495640971\n",
      "=> Test set loss: 34.8913871094\n",
      "grad Variable containing:\n",
      " 241.4347\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 242.1694\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 34.9336024434\n",
      "=> Test set loss: 34.5303772827\n",
      "grad Variable containing:\n",
      " 242.1694\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 244.3028\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 34.6947411275\n",
      "=> Test set loss: 34.1537267700\n",
      "grad Variable containing:\n",
      " 244.3028\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 245.8430\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 34.0741532796\n",
      "=> Test set loss: 33.5463441528\n",
      "grad Variable containing:\n",
      " 245.8430\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 242.0541\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 33.7611063741\n",
      "=> Test set loss: 33.4114353760\n",
      "grad Variable containing:\n",
      " 242.0541\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 238.7510\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 33.6292115519\n",
      "=> Test set loss: 33.3044302246\n",
      "grad Variable containing:\n",
      " 238.7510\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 236.7463\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 33.5012349284\n",
      "=> Test set loss: 33.2245626587\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#4 without drop lamd =1 \n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2217.4434\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1427.7234\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 38.3192189596\n",
      "=> Test set loss: 28.8169107788\n",
      "grad Variable containing:\n",
      " 1427.7234\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1317.1708\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 27.3541346252\n",
      "=> Test set loss: 25.4113202637\n",
      "grad Variable containing:\n",
      " 1317.1708\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1279.4215\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 25.1807821635\n",
      "=> Test set loss: 24.1128293335\n",
      "grad Variable containing:\n",
      " 1279.4215\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1268.9510\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 23.8691389140\n",
      "=> Test set loss: 23.0228090149\n",
      "grad Variable containing:\n",
      " 1268.9510\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1245.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 23.0791568939\n",
      "=> Test set loss: 22.5231805603\n",
      "grad Variable containing:\n",
      " 1245.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1241.7831\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 22.6813428335\n",
      "=> Test set loss: 22.1577979675\n",
      "grad Variable containing:\n",
      " 1241.7831\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1235.6682\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 22.3331246206\n",
      "=> Test set loss: 21.8925016052\n",
      "grad Variable containing:\n",
      " 1235.6682\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1229.3718\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 22.2340063599\n",
      "=> Test set loss: 21.8608606506\n",
      "grad Variable containing:\n",
      " 1229.3718\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1258.5763\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 22.1388382863\n",
      "=> Test set loss: 21.6824573547\n",
      "grad Variable containing:\n",
      " 1258.5763\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 1265.2307\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 22.0049349467\n",
      "=> Test set loss: 21.6429316284\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#4 without drop lamd = 0.001\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2210.5491\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 838.8389\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 40.2824123759\n",
      "=> Test set loss: 29.7709755615\n",
      "grad Variable containing:\n",
      " 838.8389\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 743.3848\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 28.6478214172\n",
      "=> Test set loss: 27.3785946655\n",
      "grad Variable containing:\n",
      " 743.3848\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 719.9584\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 27.2106614604\n",
      "=> Test set loss: 26.2273687134\n",
      "grad Variable containing:\n",
      " 719.9584\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 682.5870\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 26.3505672668\n",
      "=> Test set loss: 25.9053831421\n",
      "grad Variable containing:\n",
      " 682.5870\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 665.9402\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 26.1133292542\n",
      "=> Test set loss: 25.7043451416\n",
      "grad Variable containing:\n",
      " 665.9402\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 652.7058\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 25.9005900818\n",
      "=> Test set loss: 25.4283949707\n",
      "grad Variable containing:\n",
      " 652.7058\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 643.1511\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 25.7477730998\n",
      "=> Test set loss: 25.3503513428\n",
      "grad Variable containing:\n",
      " 643.1511\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 635.3937\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 25.6153878174\n",
      "=> Test set loss: 25.2164499756\n",
      "grad Variable containing:\n",
      " 635.3937\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 630.9807\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 25.4852881938\n",
      "=> Test set loss: 25.1505895752\n",
      "grad Variable containing:\n",
      " 630.9807\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 621.2149\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 25.4075766805\n",
      "=> Test set loss: 25.0292617187\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#4 without drop lamb = 0.1\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "grad Variable containing:\n",
      " 2227.6106\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 731.2108\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 0 Average loss: 40.8876158488\n",
      "=> Test set loss: 30.2893124023\n",
      "grad Variable containing:\n",
      " 731.2108\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 667.5630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 1 Average loss: 28.9914867554\n",
      "=> Test set loss: 27.8952964355\n",
      "grad Variable containing:\n",
      " 667.5630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 638.4318\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 2 Average loss: 27.6915644714\n",
      "=> Test set loss: 27.1802191650\n",
      "grad Variable containing:\n",
      " 638.4318\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 612.5133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 3 Average loss: 27.3394573690\n",
      "=> Test set loss: 26.8885466675\n",
      "grad Variable containing:\n",
      " 612.5133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 589.3036\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 4 Average loss: 27.1771882222\n",
      "=> Test set loss: 26.7744967407\n",
      "grad Variable containing:\n",
      " 589.3036\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 569.2354\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 5 Average loss: 27.1097000346\n",
      "=> Test set loss: 26.7967812012\n",
      "grad Variable containing:\n",
      " 569.2354\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 553.4407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 6 Average loss: 27.0764195699\n",
      "=> Test set loss: 26.7263571655\n",
      "grad Variable containing:\n",
      " 553.4407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 540.5255\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 7 Average loss: 27.0394855774\n",
      "=> Test set loss: 26.6710572510\n",
      "grad Variable containing:\n",
      " 540.5255\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 530.3499\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 8 Average loss: 27.0205496236\n",
      "=> Test set loss: 26.6994383423\n",
      "grad Variable containing:\n",
      " 530.3499\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "grad Variable containing:\n",
      " 520.8111\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "=> Epoch: 9 Average loss: 26.9947426371\n",
      "=> Test set loss: 26.6778540283\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "#4 with drop\n",
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-afa637a6eb95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m## gradient should be all one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "#x = torch.rand(3,2,requires_grad=True)\n",
    "x = torch.Tensor([[1., -1.], [1., -1.]] )\n",
    "loss = torch.sum(torch.abs(x))\n",
    "loss.backward()\n",
    "## gradient should be all one\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "-1\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([-2] )\n",
    "print(x)\n",
    "x = Variable(x, requires_grad=True)\n",
    "loss = torch.sum(torch.abs(x))\n",
    "loss.backward()\n",
    "## gradient should be all one\n",
    "x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-ebc3ceaa76d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "torch.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7395,
     "status": "ok",
     "timestamp": 1523809884662,
     "user": {
      "displayName": "Дмитрий Жеглов",
      "photoUrl": "//lh3.googleusercontent.com/-u9_J3lUlUyI/AAAAAAAAAAI/AAAAAAAAAIk/VfpM3DKLmTk/s50-c-k-no/photo.jpg",
      "userId": "100250680410602846653"
     },
     "user_tz": -180
    },
    "id": "v-OUVNmQVPDC",
    "outputId": "1e74cef5-1137-4b6a-c848-44e5d1845aab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:05<00:00, 14654.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "cor_lines = datasets.readCornellData('', max_len=80, fast_preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UZdpe5u1ofHR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:   0%|          | 3/2317 [00:00<01:39, 23.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OpenSubtitles conversations in open/.\n",
      "Skipping file open/Horror/1922/1166_134135_184270_nosferatu_eine_symphonie_des_grauens.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  15%|█▌        | 352/2317 [00:24<02:15, 14.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Drama/2002/3265_149497_204017_unfaithful.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  20%|█▉        | 463/2317 [00:32<02:08, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Drama/2000/179_88528_119102_batoru_rowaiaru.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  22%|██▏       | 515/2317 [00:35<02:03, 14.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Drama/2003/1723_68784_89159_big_fish.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  31%|███       | 716/2317 [00:51<01:54, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Drama/2004/146_206647_272090_eternal_sunshine_of_the_spotless_mind.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  47%|████▋     | 1080/2317 [01:16<01:27, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Action/2003/602_152466_207871_batoru_rowaiaru_ii_rekuiemu.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  59%|█████▉    | 1365/2317 [01:34<01:05, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Action/2004/59_84873_113518_appurushdo.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  75%|███████▍  | 1732/2317 [02:10<00:44, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Comedy/2003/529_124078_171007_how_to_lose_a_guy_in_10_days.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  83%|████████▎ | 1916/2317 [02:35<00:32, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Comedy/2004/2480_226704_299940_little_black_book.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files:  99%|█████████▉| 2302/2317 [03:14<00:01, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file open/Family/2001/3935_19508_22105_cats__dogs.xml.gz with errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files: 100%|██████████| 2317/2317 [03:15<00:00, 11.84it/s]\n",
      "100%|██████████| 1648080/1648080 [00:32<00:00, 50508.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "cor_lines = datasets.readOpensubsData('open/', max_len= 50, fast_preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qyk6vWvdlCPk"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(cor_lines, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1523809905471,
     "user": {
      "displayName": "Дмитрий Жеглов",
      "photoUrl": "//lh3.googleusercontent.com/-u9_J3lUlUyI/AAAAAAAAAAI/AAAAAAAAAIk/VfpM3DKLmTk/s50-c-k-no/photo.jpg",
      "userId": "100250680410602846653"
     },
     "user_tz": -180
    },
    "id": "emJ855XfVkXn",
    "outputId": "f880aa70-c1d9-49bb-b273-3bc7e04e0e32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115967,\n",
       " ('maybe she ran away oh marion',\n",
       "  'maybe she went into the woods marion i m going 60'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cor_lines), train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uFoqLlu1lSyk"
   },
   "outputs": [],
   "source": [
    "#from gensim.models.keyedvectors import KeyedVectors                         \n",
    "#model = KeyedVectors.load_word2vec_format('freebase-vectors-skipgram1000.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qfn1TJOkcymn"
   },
   "outputs": [],
   "source": [
    "start_symbol = '^'\n",
    "end_symbol = '$'\n",
    "padding_symbol = '#'\n",
    "unk_symbol = '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PGGmX6ehbsDz"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words_counts = Counter('^')\n",
    "words_counts.update(Counter('$'))\n",
    "words_counts.update(Counter('#'))\n",
    "words_counts.update(Counter('*'))\n",
    "words_counts.update(Counter(' '))\n",
    "for sequence in train_set:\n",
    "    words_counts.update(Counter(' '.join(sequence).split()))\n",
    "\n",
    "words_counts = dict(words_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MD4pidLSj1iE"
   },
   "outputs": [],
   "source": [
    "word2id = {symbol:i for i, symbol in enumerate('^$#*qwertyuioplkjhgfdsamnbvcxz ')}\n",
    "id2word = {i:symbol for symbol, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nan9Dji4VlLj"
   },
   "outputs": [],
   "source": [
    "word2id = {symbol:i for i, symbol in enumerate(words_counts)}\n",
    "id2word = {i:symbol for symbol, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RfpTvV4Nm-8H"
   },
   "outputs": [],
   "source": [
    "start_id = word2id['^']\n",
    "end_id = word2id['$']\n",
    "padding_id = word2id['#']\n",
    "unk_id = word2id['*']\n",
    "space_id = word2id[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1523803787372,
     "user": {
      "displayName": "Дмитрий Жеглов",
      "photoUrl": "//lh3.googleusercontent.com/-u9_J3lUlUyI/AAAAAAAAAAI/AAAAAAAAAIk/VfpM3DKLmTk/s50-c-k-no/photo.jpg",
      "userId": "100250680410602846653"
     },
     "user_tz": -180
    },
    "id": "ZrhkKOcAkCgC",
    "outputId": "9de3b9c0-4600-4b2d-9ad6-c83a44e4d9cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pJJk5vS7qEkZ"
   },
   "outputs": [],
   "source": [
    "def get_id(x):\n",
    "    try:\n",
    "        return word2id[x]\n",
    "    except:\n",
    "        return padding_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aArceWO-eJL-"
   },
   "outputs": [],
   "source": [
    "def sentence_to_ids(sentence, word2id, padded_len):\n",
    "    \"\"\" Converts a sequence of symbols to a padded sequence of their ids.\n",
    "    \n",
    "      sentence: a string, input/output sequence of symbols.\n",
    "      word2id: a dict, a mapping from original symbols to ids.\n",
    "      padded_len: an integer, a desirable length of the sequence.\n",
    "\n",
    "      result: a tuple of (a list of ids, an actual length of sentence).\n",
    "    \"\"\"\n",
    "    #sentence = sentence.split()\n",
    "    l = len(sentence)\n",
    "    if l  >= padded_len:\n",
    "        sent_ids = [get_id(symb) for symb in sentence[:padded_len-1]]\n",
    "        sent_ids.append(1)\n",
    "        sent_len = padded_len\n",
    "    else:\n",
    "        sent_ids = [get_id(symb) for symb in sentence[:padded_len-1]]\n",
    "        sent_ids.append(1)\n",
    "        sent_ids.extend([2]*(padded_len - l - 1))\n",
    "        sent_len = l + 1\n",
    "    \n",
    "    return sent_ids, sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1523803793353,
     "user": {
      "displayName": "Дмитрий Жеглов",
      "photoUrl": "//lh3.googleusercontent.com/-u9_J3lUlUyI/AAAAAAAAAAI/AAAAAAAAAIk/VfpM3DKLmTk/s50-c-k-no/photo.jpg",
      "userId": "100250680410602846653"
     },
     "user_tz": -180
    },
    "id": "oclKg52MfflY",
    "outputId": "191743c7-97aa-4237-dbed-d276bd9c7f23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([17, 22, 26, 6, 30, 19, 10, 24, 30, 8, 12, 24, 11, 18, 17, 8, 30, 18, 12, 1],\n",
       " 20)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_ids('have fun tonight goood mooornasd', word2id, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7schX8mVfrRQ"
   },
   "outputs": [],
   "source": [
    "def ids_to_sentence(ids, id2word):\n",
    "    \"\"\" Converts a sequence of ids to a sequence of symbols.\n",
    "    \n",
    "          ids: a list, indices for the padded sequence.\n",
    "          id2word:  a dict, a mapping from ids to original symbols.\n",
    "\n",
    "          result: a list of symbols.\n",
    "    \"\"\"\n",
    " \n",
    "    return [id2word[i] for i in ids] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1523802574163,
     "user": {
      "displayName": "Дмитрий Жеглов",
      "photoUrl": "//lh3.googleusercontent.com/-u9_J3lUlUyI/AAAAAAAAAAI/AAAAAAAAAIk/VfpM3DKLmTk/s50-c-k-no/photo.jpg",
      "userId": "100250680410602846653"
     },
     "user_tz": -180
    },
    "id": "I1LqNVs7f-wj",
    "outputId": "9c9f9d88-13dd-49ca-b508-f43715cbb879"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'f',\n",
       " 'u',\n",
       " 'n',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " 'n',\n",
       " 'i',\n",
       " 'g',\n",
       " 'h',\n",
       " 't',\n",
       " ' ',\n",
       " 'g',\n",
       " 'o',\n",
       " '$']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_sentence([17, 22, 26, 6, 30, 19, 10, 24, 30, 8, 12, 24, 11, 18, 17, 8, 30, 18, 12, 1], id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jFOibNSvgOFh"
   },
   "outputs": [],
   "source": [
    "def batch_to_ids(sentences, word2id, max_len):\n",
    "    \"\"\"Prepares batches of indices. \n",
    "    \n",
    "       Sequences are padded to match the longest sequence in the batch,\n",
    "       if it's longer than max_len, then max_len is used instead.\n",
    "\n",
    "        sentences: a list of strings, original sequences.\n",
    "        word2id: a dict, a mapping from original symbols to ids.\n",
    "        max_len: an integer, max len of sequences allowed.\n",
    "\n",
    "        result: a list of lists of ids, a list of actual lengths.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_len_in_batch = min(max(len(s) for s in sentences) + 1, max_len)\n",
    "    batch_ids, batch_ids_len = [], []\n",
    "    for sentence in sentences:\n",
    "        ids, ids_len = sentence_to_ids(sentence, word2id, max_len_in_batch)\n",
    "        batch_ids.append(ids)\n",
    "        batch_ids_len.append(ids_len)\n",
    "    return batch_ids, batch_ids_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cRzmYXpFgWZY"
   },
   "outputs": [],
   "source": [
    "def generate_batches(samples, batch_size=64):\n",
    "    X, Y = [], []\n",
    "    for i, (x, y) in enumerate(samples, 1):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        if i % batch_size == 0:\n",
    "            yield X, Y\n",
    "            X, Y = [], []\n",
    "    if X and Y:\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1523811038921,
     "user": {
      "displayName": "Дмитрий Жеглов",
      "photoUrl": "//lh3.googleusercontent.com/-u9_J3lUlUyI/AAAAAAAAAAI/AAAAAAAAAIk/VfpM3DKLmTk/s50-c-k-no/photo.jpg",
      "userId": "100250680410602846653"
     },
     "user_tz": -180
    },
    "id": "vmAFow3OgZoS",
    "outputId": "57c51cd7-0d7e-46f4-f5f8-1bf7e9658af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ('well i thought wed start with pronunciation if thats okay with you', 'not the hacking and gagging and spitting part please')\n",
      "Ids: [[5, 6, 14, 14, 30, 11, 30, 8, 17, 12, 10, 18, 17, 8, 30, 5, 6, 20, 30, 1], [24, 12, 8, 30, 8, 17, 6, 30, 17, 22, 27, 15, 11, 24, 18, 30, 22, 24, 20, 1]]\n",
      "Sentences lengths: [20, 20]\n"
     ]
    }
   ],
   "source": [
    "sentences = cor_lines[0]\n",
    "ids, sent_lens = batch_to_ids(sentences, word2id, max_len =20)\n",
    "print('Input:', sentences)\n",
    "print('Ids: {}\\nSentences lengths: {}'.format(ids, sent_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xUsJlsBDgmMi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m1YV47eGjm9I"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5OVZ5iYdsnuN"
   },
   "outputs": [],
   "source": [
    "def declare_placeholders(self):\n",
    "    \"\"\"Specifies placeholders for the model.\"\"\"\n",
    "    \n",
    "    # Placeholders for input and its actual lengths.\n",
    "    self.input_batch = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input_batch')\n",
    "    self.input_batch_lengths = tf.placeholder(shape=(None, ), dtype=tf.int32, name='input_batch_lengths')\n",
    "    \n",
    "    # Placeholders for groundtruth and its actual lengths.\n",
    "    self.ground_truth = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'ground_truth')######### YOUR CODE HERE #############\n",
    "    self.ground_truth_lengths = tf.placeholder(shape = (None,), dtype = tf.int32, name = 'ground_truth_lengths')######### YOUR CODE HERE #############\n",
    "        \n",
    "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\n",
    "    self.learning_rate_ph = tf.placeholder(dtype = tf.float32, shape = [])######### YOUR CODE HERE ############# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2KPys5VcsrPg"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__declare_placeholders = classmethod(declare_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "swLoclOlst3I"
   },
   "outputs": [],
   "source": [
    "def create_embeddings(self, vocab_size, embeddings_size):\n",
    "    \"\"\"Specifies embeddings layer and embeds an input batch.\"\"\"\n",
    "     \n",
    "    random_initializer = tf.random_uniform((vocab_size, embeddings_size), -1.0, 1.0)\n",
    "    self.embeddings = tf.Variable(initial_value = random_initializer, dtype = tf.float32, name = 'embeddings')######### YOUR CODE HERE ############# \n",
    "    \n",
    "    # Perform embeddings lookup for self.input_batch. \n",
    "    self.input_batch_embedded = tf.nn.embedding_lookup(self.embeddings, self.input_batch, name = 'input_batched_embed')######### YOUR CODE HERE ############# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZjVf79MWsw2B"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__create_embeddings = classmethod(create_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2By5fx4-sywe"
   },
   "outputs": [],
   "source": [
    "def build_encoder(self, hidden_size):\n",
    "    \"\"\"Specifies encoder architecture and computes its output.\"\"\"\n",
    "    \n",
    "    # Create GRUCell with dropout.\n",
    "    #last tf.nn.rnn_cell.GRUCell(num_units = hidden_size, name = 'GRU')\n",
    "    encoder_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units = hidden_size, name = 'LSTM'), input_keep_prob = self.dropout_ph, dtype = tf.float32)######### YOUR CODE HERE #############\n",
    "    \n",
    "    # Create RNN with the predefined cell.\n",
    "    self.final_encoder_out, self.final_encoder_state = tf.nn.dynamic_rnn(encoder_cell, inputs = self.input_batch_embedded, sequence_length = self.input_batch_lengths, dtype = tf.float32)######### YOUR CODE HERE #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BqcThPdxs1t-"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__build_encoder = classmethod(build_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(self, hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id):\n",
    "    \"\"\"Specifies decoder architecture and computes the output.\n",
    "    \n",
    "        Uses different helpers:\n",
    "          - for train: feeding ground truth\n",
    "          - for inference: feeding generated output\n",
    "\n",
    "        As a result, self.train_outputs and self.infer_outputs are created. \n",
    "        Each of them contains two fields:\n",
    "          rnn_output (predicted logits)\n",
    "          sample_id (predictions).\n",
    "\n",
    "    \"\"\"\n",
    "    # Use start symbols as the decoder inputs at the first time step.\n",
    "    batch_size = tf.shape(self.input_batch)[0]\n",
    "    start_tokens = tf.fill([batch_size], start_symbol_id)\n",
    "    ground_truth_as_input = tf.concat([tf.expand_dims(start_tokens, 1), self.ground_truth], 1)\n",
    "    \n",
    "    # Use the embedding layer defined before to lookup embedings for ground_truth_as_input. \n",
    "    self.ground_truth_embedded = tf.nn.embedding_lookup(self.embeddings, ground_truth_as_input, name = 'input_ground_truth_embed')######### YOUR CODE HERE #############\n",
    "     \n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(num_units = hidden_size, memory = self.final_encoder_out, memory_sequence_length=self.input_batch_lengths)\n",
    "    # Create TrainingHelper for the train stage.\n",
    "    train_helper = tf.contrib.seq2seq.TrainingHelper(self.ground_truth_embedded, \n",
    "                                                     self.ground_truth_lengths, name = 'trainer_helper')\n",
    "    \n",
    "    # Create GreedyEmbeddingHelper for the inference stage.\n",
    "    # You should provide the embedding layer, start_tokens and index of the end symbol.\n",
    "    infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(self.embeddings, start_tokens, end_symbol_id)######### YOUR CODE HERE #############\n",
    "    \n",
    "     \n",
    "    def decode(helper, scope, reuse=None):\n",
    "        \"\"\"Creates decoder and return the results of the decoding with a given helper.\"\"\"\n",
    "        \n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            decoder_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_units = hidden_size, reuse = reuse, name = 'lstm_decoder'), input_keep_prob = self.dropout_ph, dtype = tf.float32)######### YOUR CODE HERE #############\n",
    "            #decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism, attention_layer_size=hidden_size,name = 'AttenWrap')\n",
    "            # Create a projection wrapper.\n",
    "            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism, attention_layer_size=hidden_size,name = 'AttenWrap')\n",
    "            \n",
    "            # Create a projection wrapper.\n",
    "            decoder_cell = tf.contrib.rnn.OutputProjectionWrapper(decoder_cell, vocab_size, reuse = reuse)#reuse\n",
    "            \n",
    "            # Create BasicDecoder, pass the defined cell, a helper, and initial state.\n",
    "            # The initial state should be equal to the final state of the encoder!\n",
    "            init = decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=self.final_encoder_state)\n",
    "            #init = tf.wrapper.zero_state().clone(cell_state = self.final_encoder_state)\n",
    "            #decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism, attention_layer_size=hidden_size,name = 'AttenWrap')\n",
    "            decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, initial_state =  init)######### YOUR CODE HERE #############\n",
    "            \n",
    "            # The first returning argument of dynamic_decode contains two fields:\n",
    "            #   rnn_output (predicted logits)\n",
    "            #   sample_id (predictions)\n",
    "            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder, maximum_iterations=max_iter, \n",
    "                                                              output_time_major=False, impute_finished=True)\n",
    "\n",
    "            return outputs\n",
    "        \n",
    "    self.train_outputs = decode(train_helper, 'decode')\n",
    "    self.infer_outputs = decode(infer_helper, 'decode', reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2SeqModel.__build_decoder = classmethod(build_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iqizwE6ss-No"
   },
   "outputs": [],
   "source": [
    "def compute_loss(self):\n",
    "    \"\"\"Computes sequence loss (masked cross-entopy loss with logits).\"\"\"\n",
    "    weights = tf.cast(tf.sequence_mask(self.ground_truth_lengths), dtype=tf.float32)\n",
    "    self.loss = tf.contrib.seq2seq.sequence_loss(logits = self.train_outputs.rnn_output, targets = self.ground_truth, weights = weights)######### YOUR CODE HERE #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NIf8ePeytBBI"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__compute_loss = classmethod(compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pJaL3GvJtC-f"
   },
   "outputs": [],
   "source": [
    "def perform_optimization(self):\n",
    "    \"\"\"Specifies train_op that optimizes self.loss.\"\"\"\n",
    "    params = tf.trainable_variables()\n",
    "    gradients = tf.gradients(self.loss, params)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "    self.train_op = tf.train.AdamOptimizer().apply_gradients(zip(clipped_gradients, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9g5AGg23tGrs"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__perform_optimization = classmethod(perform_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vn544EPbtJpy"
   },
   "outputs": [],
   "source": [
    "def init_model(self, vocab_size, embeddings_size, hidden_size, \n",
    "               max_iter, start_symbol_id, end_symbol_id, padding_symbol_id):\n",
    "    \n",
    "    self.__declare_placeholders()\n",
    "    self.__create_embeddings(vocab_size, embeddings_size)\n",
    "    self.__build_encoder(hidden_size)\n",
    "    self.__build_decoder(hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id)\n",
    "    \n",
    "    # Compute loss and back-propagate.\n",
    "    self.__compute_loss()\n",
    "    self.__perform_optimization()\n",
    "    \n",
    "    # Get predictions for evaluation.\n",
    "    self.train_predictions = self.train_outputs.sample_id\n",
    "    self.infer_predictions = self.infer_outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NV40lOjGtLuE"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__init__ = classmethod(init_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VjysX6M5tNNq"
   },
   "outputs": [],
   "source": [
    "def train_on_batch(self, session, X, X_seq_len, Y, Y_seq_len, learning_rate, dropout_keep_probability):\n",
    "    feed_dict = {\n",
    "            self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len,\n",
    "            self.ground_truth: Y,\n",
    "            self.ground_truth_lengths: Y_seq_len,\n",
    "            self.learning_rate_ph: learning_rate,\n",
    "            self.dropout_ph: dropout_keep_probability\n",
    "        }\n",
    "    pred, loss, _ = session.run([\n",
    "            self.train_predictions,\n",
    "            self.loss,\n",
    "            self.train_op], feed_dict=feed_dict)\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xYj61BhjtQBH"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.train_on_batch = classmethod(train_on_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BMJ6EoqTtSpO"
   },
   "outputs": [],
   "source": [
    "def predict_for_batch(self, session, X, X_seq_len):\n",
    "    feed_dict = { self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len}######### YOUR CODE HERE #############\n",
    "    pred = session.run([\n",
    "            self.infer_predictions\n",
    "        ], feed_dict=feed_dict)[0]\n",
    "    return pred\n",
    "\n",
    "def predict_for_batch_with_loss(self, session, X, X_seq_len, Y, Y_seq_len):\n",
    "    feed_dict = {self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len,\n",
    "            self.ground_truth: Y,\n",
    "            self.ground_truth_lengths: Y_seq_len}######### YOUR CODE HERE #############\n",
    "    pred, loss = session.run([\n",
    "            self.infer_predictions,\n",
    "            self.loss,\n",
    "        ], feed_dict=feed_dict)\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eKA_6XxgtVGx"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.predict_for_batch = classmethod(predict_for_batch)\n",
    "Seq2SeqModel.predict_for_batch_with_loss = classmethod(predict_for_batch_with_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qE3e0hKPtXUT"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = Seq2SeqModel(vocab_size = len(word2id), embeddings_size = 100, max_iter = 50, hidden_size = 500, start_symbol_id = word2id['^'], end_symbol_id = word2id['$'], padding_symbol_id = word2id['#'])######### YOUR CODE HERE #############\n",
    "\n",
    "batch_size = 60######### YOUR CODE HERE #############\n",
    "n_epochs = 10######### YOUR CODE HERE #############\n",
    "learning_rate = 0.001######### YOUR CODE HERE #############\n",
    "dropout_keep_probability = 0.5######### YOUR CODE HERE #############\n",
    "max_len = 50######### YOUR CODE HERE #############\n",
    "\n",
    "n_step = int(len(train_set) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rAZ3YgpBtaPh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 384412,
     "status": "ok",
     "timestamp": 1523802996559,
     "user": {
      "displayName": "Дмитрий Жеглов",
      "photoUrl": "//lh3.googleusercontent.com/-u9_J3lUlUyI/AAAAAAAAAAI/AAAAAAAAAIk/VfpM3DKLmTk/s50-c-k-no/photo.jpg",
      "userId": "100250680410602846653"
     },
     "user_tz": -180
    },
    "id": "n7aKWij6tc7l",
    "outputId": "a8861289-1d48-43c5-d863-6cef3ff648e4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training... \n",
      "\n",
      "Train: epoch 1\n",
      "Epoch: [1/10], step: [1/1998], loss: 3.440839\n",
      "Epoch: [1/10], step: [201/1998], loss: 1.720613\n",
      "Epoch: [1/10], step: [401/1998], loss: 1.543447\n",
      "Epoch: [1/10], step: [601/1998], loss: 1.513597\n",
      "Epoch: [1/10], step: [801/1998], loss: 1.398102\n",
      "Epoch: [1/10], step: [1001/1998], loss: 1.413745\n",
      "Epoch: [1/10], step: [1201/1998], loss: 1.330769\n",
      "Epoch: [1/10], step: [1401/1998], loss: 1.416018\n",
      "Epoch: [1/10], step: [1601/1998], loss: 1.337224\n",
      "Epoch: [1/10], step: [1801/1998], loss: 1.382533\n",
      "Test: epoch 1 loss: 1.3547747\n",
      "X: frank uh you know ill try to contribute but uhfre$\n",
      "Y: i dont care what it costs this is when ya come to$\n",
      "O: i dont know what i said i dont know what i said$^^\n",
      "\n",
      "X: its saturday arnie you work too hard$#############\n",
      "Y: carl im running late im coming right now$#########\n",
      "O: i dont know what i said i dont know what i said$^^\n",
      "\n",
      "X: its battle i want not talk$#######################\n",
      "Y: but now that i am here will you speak with a woma$\n",
      "O: what do you want to do to me$^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: hold on give us half a chance to count it$########\n",
      "Y: what about all the gear$##########################\n",
      "O: what do you mean the same the police to the pol$^^\n",
      "\n",
      "X: fuck off back to essex$###########################\n",
      "Y: fucking mad$######################################\n",
      "O: what do you mean the same the same the police to t\n",
      "\n",
      "X: id hate to get lost on that freeway$##############\n",
      "Y: they all lead to the same place the lungs$########\n",
      "O: what do you mean the same the police to the pol$^^\n",
      "\n",
      "X: you have to use the steering wheel to turn the pe$\n",
      "Y: got it ejection seat$#############################\n",
      "O: i dont think so$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: i know it wasnt a nice thing to do but$###########\n",
      "Y: yeah no shit$#####################################\n",
      "O: what do you want to do to me$^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: have i ever let you down before$##################\n",
      "Y: you stand there and tell me it is my duty after a$\n",
      "O: i dont know what i dont know what i dont know whe$\n",
      "\n",
      "X: they said thats not such a good idea the shock al$\n",
      "Y: give me the god damn mirror$######################\n",
      "O: what do you want to say that$^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 2\n",
      "Epoch: [2/10], step: [1/1998], loss: 1.312112\n",
      "Epoch: [2/10], step: [201/1998], loss: 1.269554\n",
      "Epoch: [2/10], step: [401/1998], loss: 1.231049\n",
      "Epoch: [2/10], step: [601/1998], loss: 1.355225\n",
      "Epoch: [2/10], step: [801/1998], loss: 1.228127\n",
      "Epoch: [2/10], step: [1001/1998], loss: 1.262420\n",
      "Epoch: [2/10], step: [1201/1998], loss: 1.270234\n",
      "Epoch: [2/10], step: [1401/1998], loss: 1.366638\n",
      "Epoch: [2/10], step: [1601/1998], loss: 1.271411\n",
      "Epoch: [2/10], step: [1801/1998], loss: 1.306328\n",
      "Test: epoch 2 loss: 1.2101367\n",
      "X: what$#############################################\n",
      "Y: then he called me a faggot$#######################\n",
      "O: i dont know what i do this is the statue$^^^^^^^^^\n",
      "\n",
      "X: excuse me$########################################\n",
      "Y: thats what you want isnt it$######################\n",
      "O: i dont know what i do that was a lot of thing$^^^^\n",
      "\n",
      "X: thank you for seeing us we just felt that it was $\n",
      "Y: what i think is going on with your son$###########\n",
      "O: i dont know what i do that was a little bit i$^^^^\n",
      "\n",
      "X: yah$##############################################\n",
      "Y: yah how are you doon$#############################\n",
      "O: i dont know what i do that was a lot of thing$^^^^\n",
      "\n",
      "X: you are a criminal$###############################\n",
      "Y: why you gotta go and do that im trying to make a $\n",
      "O: i dont know i dont know what i am$^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: yeah$#############################################\n",
      "Y: whats wrong$######################################\n",
      "O: i dont know what i do that was a lot of thing$^^^^\n",
      "\n",
      "X: under the circumstances mother didnt see fit but $\n",
      "Y: well i cant possibly go like this$################\n",
      "O: i didnt know what i did the car is that a litt$^^^\n",
      "\n",
      "X: yeah$#############################################\n",
      "Y: rick march who the hell are you$##################\n",
      "O: i dont know what i do that was a lot of thing$^^^^\n",
      "\n",
      "X: its a post all vienna seeks if you want it for yo$\n",
      "Y: but im a married woman$###########################\n",
      "O: i dont know what i wanted to do with you$^^^^^^^^^\n",
      "\n",
      "X: what$#############################################\n",
      "Y: dont throw that out$##############################\n",
      "O: i dont know what i do this is the statue$^^^^^^^^^\n",
      "\n",
      "Train: epoch 3\n",
      "Epoch: [3/10], step: [1/1998], loss: 1.257398\n",
      "Epoch: [3/10], step: [201/1998], loss: 1.208873\n",
      "Epoch: [3/10], step: [401/1998], loss: 1.264041\n",
      "Epoch: [3/10], step: [601/1998], loss: 1.222312\n",
      "Epoch: [3/10], step: [801/1998], loss: 1.244974\n",
      "Epoch: [3/10], step: [1001/1998], loss: 1.277192\n",
      "Epoch: [3/10], step: [1201/1998], loss: 1.264604\n",
      "Epoch: [3/10], step: [1401/1998], loss: 1.207772\n",
      "Epoch: [3/10], step: [1601/1998], loss: 1.197184\n",
      "Epoch: [3/10], step: [1801/1998], loss: 1.301487\n",
      "Test: epoch 3 loss: 1.2939839\n",
      "X: i didnt want to bother you during your racquetbal$\n",
      "Y: thanks who are you$###############################\n",
      "O: i dont want to better than the bottom of the col$^\n",
      "\n",
      "X: father$###########################################\n",
      "Y: these are priceless artifacts theyre ruining the $\n",
      "O: what are you doing here$^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: nice of him$######################################\n",
      "Y: he knew the immigration officer he eased himself $\n",
      "O: i dont want to go to him$^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: what are you driving at you want me to get him to$\n",
      "Y: yes$##############################################\n",
      "O: i want to get a lot of things and i want to get $^\n",
      "\n",
      "X: theres no question youll be friends of course you$\n",
      "Y: so this break is a breakup$#######################\n",
      "O: i dont want to be a course i want to get out of $^\n",
      "\n",
      "X: if we wrote a story that said haldeman controlled$\n",
      "Y: let me put it this way id have no problem if you $\n",
      "O: what are you doing here$^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: enough with the clothes$##########################\n",
      "Y: just cause you went to catholic school and wore a$\n",
      "O: i dont know what i want to do to you the clothes$^\n",
      "\n",
      "X: someone else$#####################################\n",
      "Y: maybe you bumped into someone who took it and you$\n",
      "O: i dont want to see you and i want to get out of $^\n",
      "\n",
      "X: hes doing the interview with the lady$############\n",
      "Y: i need you to interupt him i need to get him on t$\n",
      "O: i dont know what i mean the lady doesnt he want$^^\n",
      "\n",
      "X: my goodness artoo why did you have to be so brave$\n",
      "Y: well i suppose i could hotwire this thing$########\n",
      "O: i dont know i dont know what i mean i want to get \n",
      "\n",
      "Train: epoch 4\n",
      "Epoch: [4/10], step: [1/1998], loss: 1.272145\n",
      "Epoch: [4/10], step: [201/1998], loss: 1.224816\n",
      "Epoch: [4/10], step: [401/1998], loss: 1.186207\n",
      "Epoch: [4/10], step: [601/1998], loss: 1.242919\n",
      "Epoch: [4/10], step: [801/1998], loss: 1.217520\n",
      "Epoch: [4/10], step: [1001/1998], loss: 1.270188\n",
      "Epoch: [4/10], step: [1201/1998], loss: 1.243904\n",
      "Epoch: [4/10], step: [1401/1998], loss: 1.269434\n",
      "Epoch: [4/10], step: [1601/1998], loss: 1.220064\n",
      "Epoch: [4/10], step: [1801/1998], loss: 1.204521\n",
      "Test: epoch 4 loss: 1.2499118\n",
      "X: how are you is it joe$############################\n",
      "Y: jeff sorry i didnt even know this was your house $\n",
      "O: i dont know i want to kill you i want to know i wa\n",
      "\n",
      "X: whatre you doing$#################################\n",
      "Y: im looking for a phone$###########################\n",
      "O: i dont know i dont know i dont know i dont know wh\n",
      "\n",
      "X: me i can only take it up to fifteen minutes cause$\n",
      "Y: yeah i get bored$#################################\n",
      "O: what are you doing here$^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: instruct thy son and he shall refresh thee and sh$\n",
      "Y: amen they cross themselves$#######################\n",
      "O: what about the and shall we go to the company i do\n",
      "\n",
      "X: how much farther$#################################\n",
      "Y: just a little ways up to those trees$#############\n",
      "O: the boys got a little boy thats a lot of people to\n",
      "\n",
      "X: thats right dad they did a great job on my gulliv$\n",
      "Y: aye$##############################################\n",
      "O: what did you think i was thinking$^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: how is it now$####################################\n",
      "Y: seems to be back to normal sir$###################\n",
      "O: i dont know i want to kill him i want to know wher\n",
      "\n",
      "X: your daughters been taken$########################\n",
      "Y: what$#############################################\n",
      "O: i dont know i want to know what i want to know wha\n",
      "\n",
      "X: huh you turned him into a liability didnt you kno$\n",
      "Y: nice way to help a colleague in trouble$##########\n",
      "O: i dont know what i did to do with the subject i do\n",
      "\n",
      "X: yeah$#############################################\n",
      "Y: thats fuckin combat the man in the black pyjamas $\n",
      "O: what are you doing here$^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/10], step: [1/1998], loss: 1.168151\n",
      "Epoch: [5/10], step: [201/1998], loss: 1.152520\n",
      "Epoch: [5/10], step: [401/1998], loss: 1.228279\n",
      "Epoch: [5/10], step: [601/1998], loss: 1.240051\n",
      "Epoch: [5/10], step: [801/1998], loss: 1.187684\n",
      "Epoch: [5/10], step: [1001/1998], loss: 1.215816\n",
      "Epoch: [5/10], step: [1201/1998], loss: 1.210794\n",
      "Epoch: [5/10], step: [1401/1998], loss: 1.230243\n",
      "Epoch: [5/10], step: [1601/1998], loss: 1.224180\n",
      "Epoch: [5/10], step: [1801/1998], loss: 1.204566\n",
      "Test: epoch 5 loss: 1.1848286\n",
      "X: kristen what happened$############################\n",
      "Y: youll hear all kinds of stories theyll tell you i$\n",
      "O: i dont know i know i know i know i know i know i$^\n",
      "\n",
      "X: i need an exit fast$##############################\n",
      "Y: cypher$###########################################\n",
      "O: i dont know what you want to do with me$^^^^^^^^^^\n",
      "\n",
      "X: but i just got here$##############################\n",
      "Y: youve been here longer than you think$############\n",
      "O: i dont know what you just want to go to the couc$^\n",
      "\n",
      "X: uh my watch stopped$##############################\n",
      "Y: i bet theyre asleep in new york ill bet theyre as$\n",
      "O: i dont know what you want to say$^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: did you really say that$##########################\n",
      "Y: just a little joke miss farmer$###################\n",
      "O: i didnt say that i didnt say that i didnt say that\n",
      "\n",
      "X: sixty four thousand eight hundred$################\n",
      "Y: theres over eighty thousand here$#################\n",
      "O: i dont know what i mean$^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: shit i wonder what these kids did to bring this m$\n",
      "Y: just in the wrong place at the wrong time$########\n",
      "O: i dont know what you want to do with me$^^^^^^^^^^\n",
      "\n",
      "X: yes leon$#########################################\n",
      "Y: what is it my boy$################################\n",
      "O: i dont know what you want$^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: right in there pal$###############################\n",
      "Y: if im not out in a half hour send for the paramed$\n",
      "O: i dont know what i think$^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: yeah and theyre your mates are they$##############\n",
      "Y: yeah$#############################################\n",
      "O: i dont know what i mean$^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 6\n",
      "Epoch: [6/10], step: [1/1998], loss: 1.088558\n",
      "Epoch: [6/10], step: [201/1998], loss: 1.227958\n",
      "Epoch: [6/10], step: [401/1998], loss: 1.203078\n",
      "Epoch: [6/10], step: [601/1998], loss: 1.231926\n",
      "Epoch: [6/10], step: [801/1998], loss: 1.211487\n",
      "Epoch: [6/10], step: [1001/1998], loss: 1.207763\n",
      "Epoch: [6/10], step: [1201/1998], loss: 1.139631\n",
      "Epoch: [6/10], step: [1401/1998], loss: 1.204738\n",
      "Epoch: [6/10], step: [1601/1998], loss: 1.166281\n",
      "Epoch: [6/10], step: [1801/1998], loss: 1.143953\n",
      "Test: epoch 6 loss: 1.258356\n",
      "X: scout$############################################\n",
      "Y: marmalade$########################################\n",
      "O: she was a second they can tell you that i dont kno\n",
      "\n",
      "X: yes$##############################################\n",
      "Y: you havent seen it$###############################\n",
      "O: what do you mean$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: the drugstore$####################################\n",
      "Y: miz cooper i never went to sewin lessons all them$\n",
      "O: the drugstore is the drugstore$^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: i know you areonly it aint goin to be that wayshe$\n",
      "Y: livin with comanches aint bein alive$#############\n",
      "O: i dont know what you do to that way$^^^^^^^^^^^^^^\n",
      "\n",
      "X: im fine thanks$###################################\n",
      "Y: no thanks honey$##################################\n",
      "O: you dont have to be a little bit of the store$^^^^\n",
      "\n",
      "X: ill take care of my end$##########################\n",
      "Y: stay clean$#######################################\n",
      "O: you dont know what you were going to do that wa$^^\n",
      "\n",
      "X: my god youve got one$#############################\n",
      "Y: i will when youre finished writing it$############\n",
      "O: i dont know what you do that was the only way$^^^^\n",
      "\n",
      "X: the answer is no quick enough for you$############\n",
      "Y: dont you want to hear the details$################\n",
      "O: i dont know what i mean$^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: hey shitforbrains be careful not to scratch that $\n",
      "Y: what$#############################################\n",
      "O: i dont know what you do to scratch$^^^^^^^^^^^^^^^\n",
      "\n",
      "X: i asked you a question youre writing a tract h$###\n",
      "Y: thats how journalists answer questions$###########\n",
      "O: i dont know what you do to me$^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 7\n",
      "Epoch: [7/10], step: [1/1998], loss: 1.174548\n",
      "Epoch: [7/10], step: [201/1998], loss: 1.173692\n",
      "Epoch: [7/10], step: [401/1998], loss: 1.135483\n",
      "Epoch: [7/10], step: [601/1998], loss: 1.156853\n",
      "Epoch: [7/10], step: [801/1998], loss: 1.164366\n",
      "Epoch: [7/10], step: [1001/1998], loss: 1.209801\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "            \n",
    "invalid_number_prediction_counts = []\n",
    "all_model_predictions = []\n",
    "all_ground_truth = []\n",
    "\n",
    "print('Start training... \\n')\n",
    "for epoch in range(n_epochs):  \n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    \n",
    "    print('Train: epoch', epoch + 1)\n",
    "    for n_iter, (X_batch, Y_batch) in enumerate(generate_batches(train_set, batch_size=batch_size)):\n",
    "        ######################################\n",
    "        ######### YOUR CODE HERE #############\n",
    "        ######################################\n",
    "        # prepare the data (X_batch and Y_batch) for training\n",
    "        # using function batch_to_ids\n",
    "        xtr = batch_to_ids(X_batch, word2id, max_len)\n",
    "        ytr = batch_to_ids(Y_batch, word2id, max_len)\n",
    "        X_batchh = np.array(xtr[0])\n",
    "        Y_batchh = np.array(ytr[0])\n",
    "        X_batch_len = np.array(xtr[1])\n",
    "        Y_batch_len = np.array(ytr[1])\n",
    "        predictions, loss = model.train_on_batch(session, X_batchh, X_batch_len, Y_batchh, Y_batch_len, learning_rate, dropout_keep_probability )\n",
    "        \n",
    "        #model.predict_for_batch_with_loss(session=session,X =  X_batchh, X_seq_len=X_batch_len, Y=Y_batchh, Y_seq_len=Y_batch_len)######### YOUR CODE HERE #############\n",
    "        \n",
    "        if n_iter % 200 == 0:\n",
    "            print(\"Epoch: [%d/%d], step: [%d/%d], loss: %f\" % (epoch + 1, n_epochs, n_iter + 1, n_step, loss))\n",
    "                \n",
    "    X_sent, Y_sent = next(generate_batches(test_set, batch_size=batch_size))\n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    # prepare test data (X_sent and Y_sent) for predicting \n",
    "    # quality and computing value of the loss function\n",
    "    # using function batch_to_ids\n",
    "    xs = batch_to_ids(X_sent, word2id, max_len)\n",
    "    ys = batch_to_ids(Y_sent, word2id, max_len)\n",
    "    X_batchhs = np.array(xs[0])\n",
    "    Y_batchhs = np.array(ys[0])\n",
    "    X_batch_lens = np.array(xs[1])\n",
    "    Y_batch_lens = np.array(ys[1])\n",
    "    predictions, loss = model.predict_for_batch_with_loss(session, X_batchhs, X_batch_lens, Y_batchhs, Y_batch_lens)######### YOUR CODE HERE #############\n",
    "    print('Test: epoch', epoch + 1, 'loss:', loss,)\n",
    "    for x, y, p  in list(zip(X_batchhs, Y_batchhs, predictions))[:10]:\n",
    "        print('X:',''.join(ids_to_sentence(x, id2word)))\n",
    "        print('Y:',''.join(ids_to_sentence(y, id2word)))\n",
    "        print('O:',''.join(ids_to_sentence(p, id2word)))\n",
    "        print('')\n",
    "\n",
    "    # ground-truth value to the arrays.\n",
    "print('\\n...training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 694,
     "status": "ok",
     "timestamp": 1523803677339,
     "user": {
      "displayName": "Дмитрий Жеглов",
      "photoUrl": "//lh3.googleusercontent.com/-u9_J3lUlUyI/AAAAAAAAAAI/AAAAAAAAAIk/VfpM3DKLmTk/s50-c-k-no/photo.jpg",
      "userId": "100250680410602846653"
     },
     "user_tz": -180
    },
    "id": "1ge07i_atyHD",
    "outputId": "6154ebad-10bf-4d7f-80eb-182b7713f126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: idontknow$\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq = ['what is your name']\n",
    "seq_ids = batch_to_ids(seq, word2id, max_len = 5)\n",
    "predictions= model.predict_for_batch(session, np.array(seq_ids[0][0]).reshape(1, -1), np.array(seq_ids[1]))\n",
    "#print('X:',''.join(ids_to_sentence(np.array(seq_ids[0][0]).reshape(1, -1), id2word)))\n",
    "print('O:',''.join(ids_to_sentence(predictions[0], id2word)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-txjg5Q143CQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Chat.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
